{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ce8457ed-c0b1-4a74-abbd-9d3d2211270f",
      "metadata": {},
      "source": [
        "# 从 ConversationBufferMemory 或 ConversationStringBufferMemory 迁移\n\n[ConversationBufferMemory](https://python.langchain.com/api_reference/langchain/memory/langchain.memory.buffer.ConversationBufferMemory.html) 和 [ConversationStringBufferMemory](https://python.langchain.com/api_reference/langchain/memory/langchain.memory.buffer.ConversationStringBufferMemory.html) 用于在没有任何额外处理的情况下跟踪人类和 AI 助手之间的对话。\n\n:::note\n`ConversationStringBufferMemory` 等同于 `ConversationBufferMemory`，但它是针对非聊天模型的 LLM 设计的。\n:::\n\n使用现有现代方法处理对话历史的方法有：\n\n1. 使用 [LangGraph persistence](https://langchain-ai.github.io/langgraph/how-tos/persistence/) 并对消息历史进行适当处理\n2. 使用 LCEL 结合 [RunnableWithMessageHistory](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html#) 并对消息历史进行适当处理。\n\n对于大多数用户来说，[LangGraph persistence](https://langchain-ai.github.io/langgraph/how-tos/persistence/) 比等效的 LCEL 更易于使用和配置，尤其是在更复杂的用例中。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d07f9459-9fb6-4942-99c9-64558aedd7d4",
      "metadata": {},
      "source": [
        "## 设置"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b99b47ec",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --upgrade --quiet langchain-openai langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "717c8673",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3621b62-a037-42b8-8faa-59575608bb8b",
      "metadata": {},
      "source": [
        "## 与 LLMChain / ConversationChain 的用法\n\n本节将展示如何迁移与 `LLMChain` 或 `ConversationChain` 结合使用的 `ConversationBufferMemory` 或 `ConversationStringBufferMemory`。\n\n### 旧用法\n\n下面是 `ConversationBufferMemory` 与 `LLMChain` 或等效的 `ConversationChain` 一起使用的示例。\n\n<details open>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8b6e1063-cf3a-456a-bf7d-830e5c1d2864",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'text': 'Hello Bob! How can I assist you today?', 'chat_history': [HumanMessage(content='my name is bob', additional_kwargs={}, response_metadata={}), AIMessage(content='Hello Bob! How can I assist you today?', additional_kwargs={}, response_metadata={})]}\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_core.messages import SystemMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    MessagesPlaceholder,\n",
        ")\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "prompt = ChatPromptTemplate(\n",
        "    [\n",
        "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# highlight-start\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "# highlight-end\n",
        "\n",
        "legacy_chain = LLMChain(\n",
        "    llm=ChatOpenAI(),\n",
        "    prompt=prompt,\n",
        "    # highlight-next-line\n",
        "    memory=memory,\n",
        ")\n",
        "\n",
        "legacy_result = legacy_chain.invoke({\"text\": \"my name is bob\"})\n",
        "print(legacy_result)\n",
        "\n",
        "legacy_result = legacy_chain.invoke({\"text\": \"what was my name\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c7fa1618",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Your name is Bob. How can I assist you today, Bob?'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "legacy_result[\"text\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3599774f-b56e-4ba3-876c-624f0270b8ac",
      "metadata": {},
      "source": [
        ":::note\n请注意，不支持在单个内存对象中分离对话线程\n:::"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdc3b527-c09e-4c77-9711-c3cc4506cd95",
      "metadata": {},
      "source": [
        "</details>\n\n### LangGraph\n\n下面的示例展示了如何使用 LangGraph 实现带有 `ConversationBufferMemory` 的 `ConversationChain` 或 `LLMChain`。\n\n本示例假设您已经对 `LangGraph` 有一定的了解。如果您还不了解，请参阅 [LangGraph Quickstart Guide](https://langchain-ai.github.io/langgraph/tutorials/introduction/) 获取更多详细信息。\n\n`LangGraph` 提供了许多额外的功能（例如，时间旅行和中断），并且非常适合其他更复杂（也更实际）的架构。\n\n<details open>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e591965c-c4d7-4df7-966d-4d14bd46e157",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "hi! I'm bob\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hello Bob! How can I assist you today?\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "what was my name?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Your name is Bob. How can I help you today, Bob?\n"
          ]
        }
      ],
      "source": [
        "import uuid\n",
        "\n",
        "from IPython.display import Image, display\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import START, MessagesState, StateGraph\n",
        "\n",
        "# Define a new graph\n",
        "workflow = StateGraph(state_schema=MessagesState)\n",
        "\n",
        "# Define a chat model\n",
        "model = ChatOpenAI()\n",
        "\n",
        "\n",
        "# Define the function that calls the model\n",
        "def call_model(state: MessagesState):\n",
        "    response = model.invoke(state[\"messages\"])\n",
        "    # We return a list, because this will get added to the existing list\n",
        "    return {\"messages\": response}\n",
        "\n",
        "\n",
        "# Define the two nodes we will cycle between\n",
        "workflow.add_edge(START, \"model\")\n",
        "workflow.add_node(\"model\", call_model)\n",
        "\n",
        "\n",
        "# Adding memory is straight forward in langgraph!\n",
        "# highlight-next-line\n",
        "memory = MemorySaver()\n",
        "\n",
        "app = workflow.compile(\n",
        "    # highlight-next-line\n",
        "    checkpointer=memory\n",
        ")\n",
        "\n",
        "\n",
        "# The thread id is a unique key that identifies\n",
        "# this particular conversation.\n",
        "# We'll just generate a random uuid here.\n",
        "# This enables a single application to manage conversations among multiple users.\n",
        "thread_id = uuid.uuid4()\n",
        "# highlight-next-line\n",
        "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
        "\n",
        "\n",
        "input_message = HumanMessage(content=\"hi! I'm bob\")\n",
        "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
        "    event[\"messages\"][-1].pretty_print()\n",
        "\n",
        "# Here, let's confirm that the AI remembers our name!\n",
        "input_message = HumanMessage(content=\"what was my name?\")\n",
        "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
        "    event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "9893029f-43f3-4703-89bf-e0e8fa18aff3",
      "metadata": {},
      "source": [
        "</details>\n\n### LCEL RunnableWithMessageHistory\n\n或者，如果你有一个简单的链，可以将链的聊天模型包装在 [RunnableWithMessageHistory](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html) 中。\n\n有关更多信息，请参阅以下[迁移指南](/docs/versions/migrating_chains/conversation_chain/)。\n\n\n## 用法示例（预构建代理）\n\n此示例展示了如何将 Agent Executor 与使用 [create_tool_calling_agent](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.tool_calling_agent.base.create_tool_calling_agent.html) 函数构建的预构建代理一起使用。\n\n如果你正在使用一个[旧的 LangChain 预构建代理](https://python.langchain.com/v0.1/docs/modules/agents/agent_types/)，你应该能够用新的 [langgraph 预构建代理](https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/) 替换该代码。新的代理利用了聊天模型的原生工具调用功能，并且开箱即用效果可能更好。\n\n### 旧版用法\n\n<details open>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "dc2928de-d7a4-4f87-ab96-59bde9a3829f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input': 'hi! my name is bob what is my age?', 'chat_history': [HumanMessage(content='hi! my name is bob what is my age?', additional_kwargs={}, response_metadata={}), AIMessage(content='Bob, you are 42 years old.', additional_kwargs={}, response_metadata={})], 'output': 'Bob, you are 42 years old.'}\n",
            "\n",
            "{'input': 'do you remember my name?', 'chat_history': [HumanMessage(content='hi! my name is bob what is my age?', additional_kwargs={}, response_metadata={}), AIMessage(content='Bob, you are 42 years old.', additional_kwargs={}, response_metadata={}), HumanMessage(content='do you remember my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Yes, your name is Bob.', additional_kwargs={}, response_metadata={})], 'output': 'Yes, your name is Bob.'}\n"
          ]
        }
      ],
      "source": [
        "from langchain import hub\n",
        "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_core.tools import tool\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(temperature=0)\n",
        "\n",
        "\n",
        "@tool\n",
        "def get_user_age(name: str) -> str:\n",
        "    \"\"\"Use this tool to find the user's age.\"\"\"\n",
        "    # This is a placeholder for the actual implementation\n",
        "    if \"bob\" in name.lower():\n",
        "        return \"42 years old\"\n",
        "    return \"41 years old\"\n",
        "\n",
        "\n",
        "tools = [get_user_age]\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"placeholder\", \"{chat_history}\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Construct the Tools agent\n",
        "agent = create_tool_calling_agent(model, tools, prompt)\n",
        "# Instantiate memory\n",
        "# highlight-start\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "# highlight-end\n",
        "\n",
        "# Create an agent\n",
        "agent = create_tool_calling_agent(model, tools, prompt)\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=agent,\n",
        "    tools=tools,\n",
        "    # highlight-next-line\n",
        "    memory=memory,  # Pass the memory to the executor\n",
        ")\n",
        "\n",
        "# Verify that the agent can use tools\n",
        "print(agent_executor.invoke({\"input\": \"hi! my name is bob what is my age?\"}))\n",
        "print()\n",
        "# Verify that the agent has access to conversation history.\n",
        "# The agent should be able to answer that the user's name is bob.\n",
        "print(agent_executor.invoke({\"input\": \"do you remember my name?\"}))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4866ae9-e683-44dc-a77b-da1737d3a645",
      "metadata": {},
      "source": [
        "</details>\n\n### LangGraph\n\n你可以遵循 LangChain 的标准教程来[构建一个代理](/docs/tutorials/agents/)，其中有关于此工作原理的深入解释。\n\n此处展示这个示例是为了让用户更容易地比较遗留实现与对应的 LangGraph 实现。\n\n此示例展示了如何在 LangGraph 的[预构建 React 代理](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.chat_agent_executor.create_react_agent) 中添加内存。\n\n更多详情，请参阅 LangGraph 中关于[如何为预构建 ReAct 代理添加内存](https://langchain-ai.github.io/langgraph/how-tos/create-react-agent-memory/)的指南。\n\n<details open>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "bdb29c9b-bc57-4512-9430-c5d5e3f91e3c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "hi! I'm bob. What is my age?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  get_user_age (call_oEDwEbIDNdokwqhAV6Azn47c)\n",
            " Call ID: call_oEDwEbIDNdokwqhAV6Azn47c\n",
            "  Args:\n",
            "    name: bob\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: get_user_age\n",
            "\n",
            "42 years old\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Bob, you are 42 years old! If you need any more assistance or information, feel free to ask.\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "do you remember my name?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Yes, your name is Bob. If you have any other questions or need assistance, feel free to ask!\n"
          ]
        }
      ],
      "source": [
        "import uuid\n",
        "\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_core.tools import tool\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "\n",
        "@tool\n",
        "def get_user_age(name: str) -> str:\n",
        "    \"\"\"Use this tool to find the user's age.\"\"\"\n",
        "    # This is a placeholder for the actual implementation\n",
        "    if \"bob\" in name.lower():\n",
        "        return \"42 years old\"\n",
        "    return \"41 years old\"\n",
        "\n",
        "\n",
        "# highlight-next-line\n",
        "memory = MemorySaver()\n",
        "model = ChatOpenAI()\n",
        "app = create_react_agent(\n",
        "    model,\n",
        "    tools=[get_user_age],\n",
        "    # highlight-next-line\n",
        "    checkpointer=memory,\n",
        ")\n",
        "\n",
        "# highlight-start\n",
        "# The thread id is a unique key that identifies\n",
        "# this particular conversation.\n",
        "# We'll just generate a random uuid here.\n",
        "# This enables a single application to manage conversations among multiple users.\n",
        "thread_id = uuid.uuid4()\n",
        "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
        "# highlight-end\n",
        "\n",
        "# Tell the AI that our name is Bob, and ask it to use a tool to confirm\n",
        "# that it's capable of working like an agent.\n",
        "input_message = HumanMessage(content=\"hi! I'm bob. What is my age?\")\n",
        "\n",
        "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
        "    event[\"messages\"][-1].pretty_print()\n",
        "\n",
        "# Confirm that the chat bot has access to previous conversation\n",
        "# and can respond to the user saying that the user's name is Bob.\n",
        "input_message = HumanMessage(content=\"do you remember my name?\")\n",
        "\n",
        "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
        "    event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87d14cef-a51e-44be-b376-f31b723caaf8",
      "metadata": {},
      "source": [
        "如果我们使用不同的 thread ID，它将开启一个新的对话，机器人将不知道我们的名字！"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "fe63e424-1111-4f6a-a9c9-0887eb150ab0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "hi! do you remember my name?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hello! Yes, I remember your name. It's great to see you again! How can I assist you today?\n"
          ]
        }
      ],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"123456789\"}}\n",
        "\n",
        "input_message = HumanMessage(content=\"hi! do you remember my name?\")\n",
        "\n",
        "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
        "    event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2717810",
      "metadata": {},
      "source": [
        "</details>\n\n## 后续步骤\n\n使用 LangGraph 探索持久化：\n\n* [LangGraph 快速入门教程](https://langchain-ai.github.io/langgraph/tutorials/introduction/)\n* [如何为图添加持久化（“内存”）](https://langchain-ai.github.io/langgraph/how-tos/persistence/)\n* [如何管理对话历史](https://langchain-ai.github.io/langgraph/how-tos/memory/manage-conversation-history/)\n* [如何添加对话历史摘要](https://langchain-ai.github.io/langgraph/how-tos/memory/add-summary-conversation-history/)\n\n通过简单的 LCEL 添加持久化（对于更复杂的用例，建议使用 langgraph）：\n\n* [如何添加消息历史](/docs/how_to/message_history/)\n\n处理消息历史：\n\n* [如何修剪消息](/docs/how_to/trim_messages)\n* [如何过滤消息](/docs/how_to/filter_messages/)\n* [如何合并消息运行](/docs/how_to/merge_message_runs/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce4c48e1-b613-4aab-bc2b-617c811fad1d",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}