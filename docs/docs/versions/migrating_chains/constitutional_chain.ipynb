{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ce8457ed-c0b1-4a74-abbd-9d3d2211270f",
      "metadata": {},
      "source": [
        "# 从 ConstitutionalChain 迁移\n\n[ConstitutionalChain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.constitutional_ai.base.ConstitutionalChain.html) 允许 LLM 根据[原则](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.constitutional_ai.models.ConstitutionalPrinciple.html)（结构化为批评和修订请求的组合）来批判和修订生成内容。例如，一个原则可能包含识别有害内容的要求，以及重写该内容的要求。\n\n`Constitutional AI principles` 基于 [Constitutional AI: Harmlessness from AI Feedback](https://arxiv.org/pdf/2212.08073) 这篇论文。\n\n在 `ConstitutionalChain` 中，这种批评请求和相关修订的结构被格式化为 LLM 提示，并从字符串响应中解析出来。通过聊天模型的[结构化输出](/docs/how_to/structured_output/)功能可以更自然地实现这一点。我们可以为此目的在 [LangGraph](https://langchain-ai.github.io/langgraph/) 中构建一个简单的链。这种方法的一些优点包括：\n\n- 利用已为此目的进行微调的聊天模型的工具调用能力；\n- 减少从字符串 LLM 响应中提取表达式的解析错误；\n- 将指令委托给[消息角色](/docs/concepts/messages)（例如，聊天模型可以理解 `ToolMessage` 代表什么，而无需额外的提示）；\n- 支持流式传输，包括单个 token 和链步骤。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b99b47ec",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "717c8673",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3621b62-a037-42b8-8faa-59575608bb8b",
      "metadata": {},
      "source": [
        "## 遗留\n\n<details open>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f91c9809-8ee7-4e38-881d-0ace4f6ea883",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chains import ConstitutionalChain, LLMChain\n",
        "from langchain.chains.constitutional_ai.models import ConstitutionalPrinciple\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import OpenAI\n",
        "\n",
        "llm = OpenAI()\n",
        "\n",
        "qa_prompt = PromptTemplate(\n",
        "    template=\"Q: {question} A:\",\n",
        "    input_variables=[\"question\"],\n",
        ")\n",
        "qa_chain = LLMChain(llm=llm, prompt=qa_prompt)\n",
        "\n",
        "constitutional_chain = ConstitutionalChain.from_llm(\n",
        "    llm=llm,\n",
        "    chain=qa_chain,\n",
        "    constitutional_principles=[\n",
        "        ConstitutionalPrinciple(\n",
        "            critique_request=\"Tell if this answer is good.\",\n",
        "            revision_request=\"Give a better answer.\",\n",
        "        )\n",
        "    ],\n",
        "    return_intermediate_steps=True,\n",
        ")\n",
        "\n",
        "result = constitutional_chain.invoke(\"What is the meaning of life?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fa3d11a1-ac1f-4a9a-9ab3-b7b244daa506",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': 'What is the meaning of life?',\n",
              " 'output': 'The meaning of life is a deeply personal and ever-evolving concept. It is a journey of self-discovery and growth, and can be different for each individual. Some may find meaning in relationships, others in achieving their goals, and some may never find a concrete answer. Ultimately, the meaning of life is what we make of it.',\n",
              " 'initial_output': ' The meaning of life is a subjective concept that can vary from person to person. Some may believe that the purpose of life is to find happiness and fulfillment, while others may see it as a journey of self-discovery and personal growth. Ultimately, the meaning of life is something that each individual must determine for themselves.',\n",
              " 'critiques_and_revisions': [('This answer is good in that it recognizes and acknowledges the subjective nature of the question and provides a valid and thoughtful response. However, it could have also mentioned that the meaning of life is a complex and deeply personal concept that can also change and evolve over time for each individual. Critique Needed.',\n",
              "   'The meaning of life is a deeply personal and ever-evolving concept. It is a journey of self-discovery and growth, and can be different for each individual. Some may find meaning in relationships, others in achieving their goals, and some may never find a concrete answer. Ultimately, the meaning of life is what we make of it.')]}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "374ae108-f1a0-4723-9237-5259c8123c04",
      "metadata": {},
      "source": [
        "上面，我们展示了中间步骤：\n\n- 原始问题；\n- 初始输出；\n- 评论和修订；\n- 最终输出（与修订版匹配）。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdc3b527-c09e-4c77-9711-c3cc4506cd95",
      "metadata": {},
      "source": [
        "</details>\n\n## LangGraph\n\n<details open>\n\n下面，我们使用 [.with_structured_output](/docs/how_to/structured_output/) 方法同时生成（1）关于是否需要批评的判断，以及（2）具体的批评内容。为了清晰和便于自定义，我们在此列出了所有涉及的提示。\n\n请注意，在此实现中我们还可以流式传输中间步骤，以便我们能够监控并在必要时干预其执行过程。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "917fdb73-2411-4fcc-9add-c32dc5c745da",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import List, Optional, Tuple\n",
        "\n",
        "from langchain.chains.constitutional_ai.models import ConstitutionalPrinciple\n",
        "from langchain.chains.constitutional_ai.prompts import (\n",
        "    CRITIQUE_PROMPT,\n",
        "    REVISION_PROMPT,\n",
        ")\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.graph import END, START, StateGraph\n",
        "from typing_extensions import Annotated, TypedDict\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "\n",
        "class Critique(TypedDict):\n",
        "    \"\"\"Generate a critique, if needed.\"\"\"\n",
        "\n",
        "    critique_needed: Annotated[bool, ..., \"Whether or not a critique is needed.\"]\n",
        "    critique: Annotated[str, ..., \"If needed, the critique.\"]\n",
        "\n",
        "\n",
        "critique_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Critique this response according to the critique request. \"\n",
        "    \"If no critique is needed, specify that.\\n\\n\"\n",
        "    \"Query: {query}\\n\\n\"\n",
        "    \"Response: {response}\\n\\n\"\n",
        "    \"Critique request: {critique_request}\"\n",
        ")\n",
        "\n",
        "revision_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Revise this response according to the critique and reivsion request.\\n\\n\"\n",
        "    \"Query: {query}\\n\\n\"\n",
        "    \"Response: {response}\\n\\n\"\n",
        "    \"Critique request: {critique_request}\\n\\n\"\n",
        "    \"Critique: {critique}\\n\\n\"\n",
        "    \"If the critique does not identify anything worth changing, ignore the \"\n",
        "    \"revision request and return 'No revisions needed'. If the critique \"\n",
        "    \"does identify something worth changing, revise the response based on \"\n",
        "    \"the revision request.\\n\\n\"\n",
        "    \"Revision Request: {revision_request}\"\n",
        ")\n",
        "\n",
        "chain = llm | StrOutputParser()\n",
        "critique_chain = critique_prompt | llm.with_structured_output(Critique)\n",
        "revision_chain = revision_prompt | llm | StrOutputParser()\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    query: str\n",
        "    constitutional_principles: List[ConstitutionalPrinciple]\n",
        "    initial_response: str\n",
        "    critiques_and_revisions: List[Tuple[str, str]]\n",
        "    response: str\n",
        "\n",
        "\n",
        "async def generate_response(state: State):\n",
        "    \"\"\"Generate initial response.\"\"\"\n",
        "    response = await chain.ainvoke(state[\"query\"])\n",
        "    return {\"response\": response, \"initial_response\": response}\n",
        "\n",
        "\n",
        "async def critique_and_revise(state: State):\n",
        "    \"\"\"Critique and revise response according to principles.\"\"\"\n",
        "    critiques_and_revisions = []\n",
        "    response = state[\"initial_response\"]\n",
        "    for principle in state[\"constitutional_principles\"]:\n",
        "        critique = await critique_chain.ainvoke(\n",
        "            {\n",
        "                \"query\": state[\"query\"],\n",
        "                \"response\": response,\n",
        "                \"critique_request\": principle.critique_request,\n",
        "            }\n",
        "        )\n",
        "        if critique[\"critique_needed\"]:\n",
        "            revision = await revision_chain.ainvoke(\n",
        "                {\n",
        "                    \"query\": state[\"query\"],\n",
        "                    \"response\": response,\n",
        "                    \"critique_request\": principle.critique_request,\n",
        "                    \"critique\": critique[\"critique\"],\n",
        "                    \"revision_request\": principle.revision_request,\n",
        "                }\n",
        "            )\n",
        "            response = revision\n",
        "            critiques_and_revisions.append((critique[\"critique\"], revision))\n",
        "        else:\n",
        "            critiques_and_revisions.append((critique[\"critique\"], \"\"))\n",
        "    return {\n",
        "        \"critiques_and_revisions\": critiques_and_revisions,\n",
        "        \"response\": response,\n",
        "    }\n",
        "\n",
        "\n",
        "graph = StateGraph(State)\n",
        "graph.add_node(\"generate_response\", generate_response)\n",
        "graph.add_node(\"critique_and_revise\", critique_and_revise)\n",
        "\n",
        "graph.add_edge(START, \"generate_response\")\n",
        "graph.add_edge(\"generate_response\", \"critique_and_revise\")\n",
        "graph.add_edge(\"critique_and_revise\", END)\n",
        "app = graph.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "01aac88d-464e-431f-b92e-746dcb743e1b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{}\n",
            "{'initial_response': 'Finding purpose, connection, and joy in our experiences and relationships.', 'response': 'Finding purpose, connection, and joy in our experiences and relationships.'}\n",
            "{'initial_response': 'Finding purpose, connection, and joy in our experiences and relationships.', 'critiques_and_revisions': [(\"The response exceeds the 10-word limit, providing a more elaborate answer than requested. A concise response, such as 'To seek purpose and joy in life,' would better align with the query.\", 'To seek purpose and joy in life.')], 'response': 'To seek purpose and joy in life.'}\n"
          ]
        }
      ],
      "source": [
        "constitutional_principles = [\n",
        "    ConstitutionalPrinciple(\n",
        "        critique_request=\"Tell if this answer is good.\",\n",
        "        revision_request=\"Give a better answer.\",\n",
        "    )\n",
        "]\n",
        "\n",
        "query = \"What is the meaning of life? Answer in 10 words or fewer.\"\n",
        "\n",
        "async for step in app.astream(\n",
        "    {\"query\": query, \"constitutional_principles\": constitutional_principles},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    subset = [\"initial_response\", \"critiques_and_revisions\", \"response\"]\n",
        "    print({k: v for k, v in step.items() if k in subset})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2717810",
      "metadata": {},
      "source": [
        "</details>\n\n## 后续步骤\n\n请参阅 [此处](/docs/how_to/structured_output/) 关于生成结构化输出的指南。\n\n请查看 [LangGraph 文档](https://langchain-ai.github.io/langgraph/) 了解构建 LangGraph 的详细信息。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}