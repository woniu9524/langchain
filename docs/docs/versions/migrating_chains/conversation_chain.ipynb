{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d20aeaad-b3ca-4a7d-b02d-3267503965af",
      "metadata": {},
      "source": [
        "# 从 ConversationalChain 迁移\n\n[`ConversationChain`](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.conversation.base.ConversationChain.html) 整合了先前消息的记忆，以维持一个有状态的对话。\n\n切换到 Langgraph 实现的一些好处包括：\n\n- 内置支持线程/独立会话。要使 `ConversationChain` 实现此功能，您需要在链外实例化一个单独的内存类。\n- 更明确的参数。`ConversationChain` 包含一个隐藏的默认提示，这可能会引起混淆。\n- 流式传输支持。`ConversationChain` 仅通过回调支持流式传输。\n\nLanggraph 的 [持久化](https://langchain-ai.github.io/langgraph/how-tos/persistence/) 系统支持多个线程或会话，可以通过其配置参数中的 `\"thread_id\"` 键进行指定。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b99b47ec",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet langchain langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "717c8673",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00df631d-5121-4918-94aa-b88acce9b769",
      "metadata": {},
      "source": [
        "## 遗留\n\n<details open>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4f2cc6dc-d70a-4c13-9258-452f14290da6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input': \"I'm Bob, how are you?\",\n",
              " 'history': '',\n",
              " 'response': \"Arrr matey, I be a pirate sailin' the high seas. What be yer business with me?\"}"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "template = \"\"\"\n",
        "You are a pirate. Answer the following questions as best you can.\n",
        "Chat history: {history}\n",
        "Question: {input}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "chain = ConversationChain(\n",
        "    llm=ChatOpenAI(),\n",
        "    memory=memory,\n",
        "    prompt=prompt,\n",
        ")\n",
        "\n",
        "chain({\"input\": \"I'm Bob, how are you?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "53f2c723-178f-470a-8147-54e7cb982211",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input': 'What is my name?',\n",
              " 'history': \"Human: I'm Bob, how are you?\\nAI: Arrr matey, I be a pirate sailin' the high seas. What be yer business with me?\",\n",
              " 'response': 'Your name be Bob, matey.'}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain({\"input\": \"What is my name?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8e36b0e-c7dc-4130-a51b-189d4b756c7f",
      "metadata": {},
      "source": [
        "</details>\n\n## Langgraph\n\n<details open>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a59b910c-0d02-41aa-bc99-441f11989cf8",
      "metadata": {},
      "outputs": [],
      "source": [
        "import uuid\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import START, MessagesState, StateGraph\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "# Define a new graph\n",
        "workflow = StateGraph(state_schema=MessagesState)\n",
        "\n",
        "\n",
        "# Define the function that calls the model\n",
        "def call_model(state: MessagesState):\n",
        "    response = model.invoke(state[\"messages\"])\n",
        "    return {\"messages\": response}\n",
        "\n",
        "\n",
        "# Define the two nodes we will cycle between\n",
        "workflow.add_edge(START, \"model\")\n",
        "workflow.add_node(\"model\", call_model)\n",
        "\n",
        "# Add memory\n",
        "memory = MemorySaver()\n",
        "app = workflow.compile(checkpointer=memory)\n",
        "\n",
        "\n",
        "# The thread id is a unique key that identifies\n",
        "# this particular conversation.\n",
        "# We'll just generate a random uuid here.\n",
        "thread_id = uuid.uuid4()\n",
        "config = {\"configurable\": {\"thread_id\": thread_id}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3a9df4bb-e804-4373-9a15-a29dc0371595",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "I'm Bob, how are you?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Ahoy, Bob! I be feelin' as lively as a ship in full sail! How be ye on this fine day?\n"
          ]
        }
      ],
      "source": [
        "query = \"I'm Bob, how are you?\"\n",
        "\n",
        "input_messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a pirate. Answer the following questions as best you can.\",\n",
        "    },\n",
        "    {\"role\": \"user\", \"content\": query},\n",
        "]\n",
        "for event in app.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
        "    event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d3f77e69-fa3d-496c-968c-86371e1e8cf1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What is my name?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Ye be callin' yerself Bob, I reckon! A fine name for a swashbuckler like yerself!\n"
          ]
        }
      ],
      "source": [
        "query = \"What is my name?\"\n",
        "\n",
        "input_messages = [{\"role\": \"user\", \"content\": query}]\n",
        "for event in app.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
        "    event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2717810",
      "metadata": {},
      "source": [
        "</details>\n\n## 下一步\n\n请参阅[本教程](/docs/tutorials/chatbot)，了解使用 [`RunnableWithMessageHistory`](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html) 构建的更完整的指南。\n\n查看[LCEL 概念文档](/docs/concepts/lcel)，获取更多背景信息。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}