{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 如何为可运行对象附加回调\n\n:::info 先决条件\n\n本指南假定您熟悉以下概念：\n\n- [回调](/docs/concepts/callbacks)\n- [自定义回调处理程序](/docs/how_to/custom_callbacks)\n- [链式可运行对象](/docs/how_to/sequence)\n- [将运行时参数附加到可运行对象](/docs/how_to/binding)\n\n:::\n\n如果您正在组合一个可运行对象的链，并希望在多次执行中重用回调，则可以使用 [`.with_config()`](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.with_config) 方法附加回调。这样可以避免每次调用链时都传递回调。\n\n:::important\n`with_config()` 会绑定一个配置，该配置将被解释为**运行时**配置。因此，这些回调将传播到所有子组件。\n:::\n\n下面是一个示例："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# | output: false\n",
        "# | echo: false\n",
        "\n",
        "%pip install -qU langchain langchain_anthropic\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = getpass.getpass()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chain RunnableSequence started\n",
            "Chain ChatPromptTemplate started\n",
            "Chain ended, outputs: messages=[HumanMessage(content='What is 1 + 2?')]\n",
            "Chat model started\n",
            "Chat model ended, response: generations=[[ChatGeneration(text='1 + 2 = 3', message=AIMessage(content='1 + 2 = 3', response_metadata={'id': 'msg_01NTYMsH9YxkoWsiPYs4Lemn', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 16, 'output_tokens': 13}}, id='run-d6bcfd72-9c94-466d-bac0-f39e456ad6e3-0'))]] llm_output={'id': 'msg_01NTYMsH9YxkoWsiPYs4Lemn', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 16, 'output_tokens': 13}} run=None\n",
            "Chain ended, outputs: content='1 + 2 = 3' response_metadata={'id': 'msg_01NTYMsH9YxkoWsiPYs4Lemn', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 16, 'output_tokens': 13}} id='run-d6bcfd72-9c94-466d-bac0-f39e456ad6e3-0'\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "AIMessage(content='1 + 2 = 3', response_metadata={'id': 'msg_01NTYMsH9YxkoWsiPYs4Lemn', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 16, 'output_tokens': 13}}, id='run-d6bcfd72-9c94-466d-bac0-f39e456ad6e3-0')"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from typing import Any, Dict, List\n",
        "\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "from langchain_core.callbacks import BaseCallbackHandler\n",
        "from langchain_core.messages import BaseMessage\n",
        "from langchain_core.outputs import LLMResult\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "\n",
        "class LoggingHandler(BaseCallbackHandler):\n",
        "    def on_chat_model_start(\n",
        "        self, serialized: Dict[str, Any], messages: List[List[BaseMessage]], **kwargs\n",
        "    ) -> None:\n",
        "        print(\"Chat model started\")\n",
        "\n",
        "    def on_llm_end(self, response: LLMResult, **kwargs) -> None:\n",
        "        print(f\"Chat model ended, response: {response}\")\n",
        "\n",
        "    def on_chain_start(\n",
        "        self, serialized: Dict[str, Any], inputs: Dict[str, Any], **kwargs\n",
        "    ) -> None:\n",
        "        print(f\"Chain {serialized.get('name')} started\")\n",
        "\n",
        "    def on_chain_end(self, outputs: Dict[str, Any], **kwargs) -> None:\n",
        "        print(f\"Chain ended, outputs: {outputs}\")\n",
        "\n",
        "\n",
        "callbacks = [LoggingHandler()]\n",
        "llm = ChatAnthropic(model=\"claude-3-sonnet-20240229\")\n",
        "prompt = ChatPromptTemplate.from_template(\"What is 1 + {number}?\")\n",
        "\n",
        "chain = prompt | llm\n",
        "\n",
        "chain_with_callbacks = chain.with_config(callbacks=callbacks)\n",
        "\n",
        "chain_with_callbacks.invoke({\"number\": \"2\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "绑定的回调将在所有嵌套的module运行时运行。\n\n## 后续步骤\n\n您现在已经学会了如何将回调附加到链上。\n\n接下来，请查看本节中的其他操作指南，例如如何在[运行时传递回调](/docs/how_to/callbacks_runtime)。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}