{
  "cells": [
    {
      "cell_type": "raw",
      "id": "27598444",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "sidebar_position: 3\n",
        "keywords: [structured output, json, information extraction, with_structured_output]\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e3f0f72",
      "metadata": {},
      "source": [
        "# 如何从模型中返回结构化数据\n\n:::info 先决条件\n\n本指南假设您熟悉以下概念：\n- [聊天模型](/docs/concepts/chat_models)\n- [函数/工具调用](/docs/concepts/tool_calling)\n:::\n\n让模型返回与特定[模式](/docs/concepts/structured_outputs/)匹配的输出通常很有用。一个常见的用例是从文本中提取数据以插入数据库或用于其他下游系统。本指南涵盖了从模型中获取结构化输出的几种策略。\n\n## `.with_structured_output()` 方法\n\n<span data-heading-keywords=\"with_structured_output\"></span>\n\n:::info 支持的模型\n\n您可以在此处找到[支持此方法模型的列表](/docs/integrations/chat/)。\n\n:::\n\n这是获取结构化输出的最简单、最可靠的方法。`with_structured_output()` 是为[提供结构化输出原生 API 的模型](/docs/ অর্থনীতির/chat/)（例如工具/函数调用或 JSON 模式）实现的，并在后台利用这些功能。\n\n此方法以模式为输入，该模式指定所需输出属性的名称、类型和描述。该方法返回一个类似模型的 Runnable，但它不会输出字符串或[消息](/docs/concepts/messages/)，而是输出与给定模式对应的对象。模式可以指定为 TypedDict 类、[JSON Schema](https://json-schema.org/) 或 Pydantic 类。如果使用 TypedDict 或 JSON Schema，Runnable 将返回一个字典；如果使用 Pydantic 类，则返回一个 Pydantic 对象。\n\n例如，让我们让模型生成一个笑话，并将铺垫与笑点分开：\n\nimport ChatModelTabs from \"@theme/ChatModelTabs\";\n\n<ChatModelTabs\n  customVarName=\"llm\"\n/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6d55008f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# | output: false\n",
        "# | echo: false\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a808a401-be1f-49f9-ad13-58dd68f7db5f",
      "metadata": {},
      "source": [
        "### Pydantic 类\n\n如果我们希望模型返回一个 Pydantic 对象，只需传入所需的 Pydantic 类即可。使用 Pydantic 的主要优点是模型生成的输出将经过验证。如果缺少任何必需的字段或字段类型不正确，Pydantic 将引发错误。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "070bf702",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Joke(setup='Why was the cat sitting on the computer?', punchline='Because it wanted to keep an eye on the mouse!', rating=7)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from typing import Optional\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "\n",
        "# Pydantic\n",
        "class Joke(BaseModel):\n",
        "    \"\"\"Joke to tell user.\"\"\"\n",
        "\n",
        "    setup: str = Field(description=\"The setup of the joke\")\n",
        "    punchline: str = Field(description=\"The punchline to the joke\")\n",
        "    rating: Optional[int] = Field(\n",
        "        default=None, description=\"How funny the joke is, from 1 to 10\"\n",
        "    )\n",
        "\n",
        "\n",
        "structured_llm = llm.with_structured_output(Joke)\n",
        "\n",
        "structured_llm.invoke(\"Tell me a joke about cats\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00890a47-3cdf-4805-b8f1-6d110f0633d3",
      "metadata": {},
      "source": [
        ":::tip\n除了 Pydantic 类的结构之外，Pydantic 类的名称、文档字符串以及参数的名称和提供的描述也非常重要。大多数时候 `with_structured_output` 使用的是模型的函数/工具调用 API，你可以有效地将所有这些信息视为添加到模型的提示中。\n:::"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "deddb6d3",
      "metadata": {},
      "source": [
        "### TypedDict 或 JSON Schema\n\n如果你不想使用 Pydantic，明确不想验证参数，或者希望能够流式传输模型输出，你可以使用 TypedDict 类来定义你的 schema。我们可以选择性地使用 LangChain 支持的一种特殊 `Annotated` 语法，它允许你指定字段的默认值和描述。请注意，如果模型没有生成默认值，它不会自动填充，它仅用于定义传递给模型的 schema。\n\n:::info 要求\n\n- Core: `langchain-core>=0.2.26`\n- Typing extensions: 强烈建议从 `typing_extensions` 而不是 `typing` 导入 `Annotated` 和 `TypedDict`，以确保在不同 Python 版本之间的行为一致。\n\n:::"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "70d82891-42e8-424a-919e-07d83bcfec61",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'setup': 'Why was the cat sitting on the computer?',\n",
              " 'punchline': 'Because it wanted to keep an eye on the mouse!',\n",
              " 'rating': 7}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from typing import Optional\n",
        "\n",
        "from typing_extensions import Annotated, TypedDict\n",
        "\n",
        "\n",
        "# TypedDict\n",
        "class Joke(TypedDict):\n",
        "    \"\"\"Joke to tell user.\"\"\"\n",
        "\n",
        "    setup: Annotated[str, ..., \"The setup of the joke\"]\n",
        "\n",
        "    # Alternatively, we could have specified setup as:\n",
        "\n",
        "    # setup: str                    # no default, no description\n",
        "    # setup: Annotated[str, ...]    # no default, no description\n",
        "    # setup: Annotated[str, \"foo\"]  # default, no description\n",
        "\n",
        "    punchline: Annotated[str, ..., \"The punchline of the joke\"]\n",
        "    rating: Annotated[Optional[int], None, \"How funny the joke is, from 1 to 10\"]\n",
        "\n",
        "\n",
        "structured_llm = llm.with_structured_output(Joke)\n",
        "\n",
        "structured_llm.invoke(\"Tell me a joke about cats\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4d7b4dc-f617-4ea8-aa58-847c228791b4",
      "metadata": {},
      "source": [
        "同理，我们也可以传入一个 [JSON Schema](https://json-schema.org/) 字典。这不需要导入或类，并且能非常清晰地展示每个参数的文档记录方式，缺点是会稍微冗长一些。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6700994a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'setup': 'Why was the cat sitting on the computer?',\n",
              " 'punchline': 'Because it wanted to keep an eye on the mouse!',\n",
              " 'rating': 7}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "json_schema = {\n",
        "    \"title\": \"joke\",\n",
        "    \"description\": \"Joke to tell user.\",\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "        \"setup\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"The setup of the joke\",\n",
        "        },\n",
        "        \"punchline\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"The punchline to the joke\",\n",
        "        },\n",
        "        \"rating\": {\n",
        "            \"type\": \"integer\",\n",
        "            \"description\": \"How funny the joke is, from 1 to 10\",\n",
        "            \"default\": None,\n",
        "        },\n",
        "    },\n",
        "    \"required\": [\"setup\", \"punchline\"],\n",
        "}\n",
        "structured_llm = llm.with_structured_output(json_schema)\n",
        "\n",
        "structured_llm.invoke(\"Tell me a joke about cats\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3da57988",
      "metadata": {},
      "source": [
        "### 在多个 Schema 中进行选择\n\n让模型从多个 Schema 中进行选择的最简单方法是创建一个父 Schema，该 Schema 具有一个 Union 类型属性。\n\n#### 使用 Pydantic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9194bcf2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FinalResponse(final_output=Joke(setup='Why was the cat sitting on the computer?', punchline='Because it wanted to keep an eye on the mouse!', rating=7))"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from typing import Union\n",
        "\n",
        "\n",
        "class Joke(BaseModel):\n",
        "    \"\"\"Joke to tell user.\"\"\"\n",
        "\n",
        "    setup: str = Field(description=\"The setup of the joke\")\n",
        "    punchline: str = Field(description=\"The punchline to the joke\")\n",
        "    rating: Optional[int] = Field(\n",
        "        default=None, description=\"How funny the joke is, from 1 to 10\"\n",
        "    )\n",
        "\n",
        "\n",
        "class ConversationalResponse(BaseModel):\n",
        "    \"\"\"Respond in a conversational manner. Be kind and helpful.\"\"\"\n",
        "\n",
        "    response: str = Field(description=\"A conversational response to the user's query\")\n",
        "\n",
        "\n",
        "class FinalResponse(BaseModel):\n",
        "    final_output: Union[Joke, ConversationalResponse]\n",
        "\n",
        "\n",
        "structured_llm = llm.with_structured_output(FinalResponse)\n",
        "\n",
        "structured_llm.invoke(\"Tell me a joke about cats\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "84d86132",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FinalResponse(final_output=ConversationalResponse(response=\"I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with whatever you need!\"))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "structured_llm.invoke(\"How are you today?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b087112c23bafcd",
      "metadata": {},
      "source": [
        "#### 使用 TypedDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "eb0d5855-feba-48fb-84ea-9acb0edb238b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'final_output': {'setup': 'Why was the cat sitting on the computer?',\n",
              "  'punchline': 'Because it wanted to keep an eye on the mouse!',\n",
              "  'rating': 7}}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from typing import Optional, Union\n",
        "\n",
        "from typing_extensions import Annotated, TypedDict\n",
        "\n",
        "\n",
        "class Joke(TypedDict):\n",
        "    \"\"\"Joke to tell user.\"\"\"\n",
        "\n",
        "    setup: Annotated[str, ..., \"The setup of the joke\"]\n",
        "    punchline: Annotated[str, ..., \"The punchline of the joke\"]\n",
        "    rating: Annotated[Optional[int], None, \"How funny the joke is, from 1 to 10\"]\n",
        "\n",
        "\n",
        "class ConversationalResponse(TypedDict):\n",
        "    \"\"\"Respond in a conversational manner. Be kind and helpful.\"\"\"\n",
        "\n",
        "    response: Annotated[str, ..., \"A conversational response to the user's query\"]\n",
        "\n",
        "\n",
        "class FinalResponse(TypedDict):\n",
        "    final_output: Union[Joke, ConversationalResponse]\n",
        "\n",
        "\n",
        "structured_llm = llm.with_structured_output(FinalResponse)\n",
        "\n",
        "structured_llm.invoke(\"Tell me a joke about cats\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ec753809-c2c1-41c0-a3c5-69855d65475b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'final_output': {'response': \"I'm just a computer program, so I don't have feelings, but I'm here and ready to help you with whatever you need!\"}}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "structured_llm.invoke(\"How are you today?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd22149ac9d41d57",
      "metadata": {},
      "source": [
        "响应应与Pydantic示例中显示的相同。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e28c14d3",
      "metadata": {},
      "source": [
        "或者，您也可以直接使用工具调用，让模型在选项之间进行选择，前提是您[选择的模型支持它](/docs/integrations/chat/)。这需要更多的解析和设置，但在某些情况下可以获得更好的性能，因为您不必使用嵌套模式。有关更多详细信息，请参阅[此操作指南](/docs/how_to/tool_calling)。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a40f703-7fd2-4fe0-ab2a-fa2d711ba009",
      "metadata": {},
      "source": [
        "### 流式输出\n\n当输出类型为字典时（即 schema 被指定为 TypedDict 类或 JSON Schema 字典），我们可以从结构化模型流式输出。\n\n:::info\n\n请注意，yield 的是已聚合的块，而非增量。\n\n:::"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "aff89877-28a3-472f-a1aa-eff893fe7736",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{}\n",
            "{'setup': ''}\n",
            "{'setup': 'Why'}\n",
            "{'setup': 'Why was'}\n",
            "{'setup': 'Why was the'}\n",
            "{'setup': 'Why was the cat'}\n",
            "{'setup': 'Why was the cat sitting'}\n",
            "{'setup': 'Why was the cat sitting on'}\n",
            "{'setup': 'Why was the cat sitting on the'}\n",
            "{'setup': 'Why was the cat sitting on the computer'}\n",
            "{'setup': 'Why was the cat sitting on the computer?'}\n",
            "{'setup': 'Why was the cat sitting on the computer?', 'punchline': ''}\n",
            "{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because'}\n",
            "{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it'}\n",
            "{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it wanted'}\n",
            "{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it wanted to'}\n",
            "{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it wanted to keep'}\n",
            "{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it wanted to keep an'}\n",
            "{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it wanted to keep an eye'}\n",
            "{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it wanted to keep an eye on'}\n",
            "{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it wanted to keep an eye on the'}\n",
            "{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it wanted to keep an eye on the mouse'}\n",
            "{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it wanted to keep an eye on the mouse!'}\n",
            "{'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it wanted to keep an eye on the mouse!', 'rating': 7}\n"
          ]
        }
      ],
      "source": [
        "from typing_extensions import Annotated, TypedDict\n",
        "\n",
        "\n",
        "# TypedDict\n",
        "class Joke(TypedDict):\n",
        "    \"\"\"Joke to tell user.\"\"\"\n",
        "\n",
        "    setup: Annotated[str, ..., \"The setup of the joke\"]\n",
        "    punchline: Annotated[str, ..., \"The punchline of the joke\"]\n",
        "    rating: Annotated[Optional[int], None, \"How funny the joke is, from 1 to 10\"]\n",
        "\n",
        "\n",
        "structured_llm = llm.with_structured_output(Joke)\n",
        "\n",
        "for chunk in structured_llm.stream(\"Tell me a joke about cats\"):\n",
        "    print(chunk)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a526cdf-e736-451b-96be-22e8986d3863",
      "metadata": {},
      "source": [
        "### 少样本提示（Few-shot prompting）\n\n对于更复杂的模式，在提示中添加少样本示例非常有帮助。这可以通过几种方式完成。\n\n最简单和最通用的方法是在提示的系统消息中添加示例："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "283ba784-2072-47ee-9b2c-1119e3c69e8e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'setup': 'Woodpecker',\n",
              " 'punchline': \"Woodpecker you a joke, but I'm afraid it might be too 'hole-some'!\",\n",
              " 'rating': 7}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "system = \"\"\"You are a hilarious comedian. Your specialty is knock-knock jokes. \\\n",
        "Return a joke which has the setup (the response to \"Who's there?\") and the final punchline (the response to \"<setup> who?\").\n",
        "\n",
        "Here are some examples of jokes:\n",
        "\n",
        "example_user: Tell me a joke about planes\n",
        "example_assistant: {{\"setup\": \"Why don't planes ever get tired?\", \"punchline\": \"Because they have rest wings!\", \"rating\": 2}}\n",
        "\n",
        "example_user: Tell me another joke about planes\n",
        "example_assistant: {{\"setup\": \"Cargo\", \"punchline\": \"Cargo 'vroom vroom', but planes go 'zoom zoom'!\", \"rating\": 10}}\n",
        "\n",
        "example_user: Now about caterpillars\n",
        "example_assistant: {{\"setup\": \"Caterpillar\", \"punchline\": \"Caterpillar really slow, but watch me turn into a butterfly and steal the show!\", \"rating\": 5}}\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", \"{input}\")])\n",
        "\n",
        "few_shot_structured_llm = prompt | structured_llm\n",
        "few_shot_structured_llm.invoke(\"what's something funny about woodpeckers\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c12b389-153d-44d1-af34-37e5b926d3db",
      "metadata": {},
      "source": [
        "当用于构建输出的基础方法是工具调用时，我们可以将示例作为显式工具调用传递。您可以在 API 参考中检查您使用的模型是否使用了工具调用。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "d7381cb0-b2c3-4302-a319-ed72d0b9e43f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'setup': 'Crocodile',\n",
              " 'punchline': 'Crocodile be seeing you later, alligator!',\n",
              " 'rating': 6}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
        "\n",
        "examples = [\n",
        "    HumanMessage(\"Tell me a joke about planes\", name=\"example_user\"),\n",
        "    AIMessage(\n",
        "        \"\",\n",
        "        name=\"example_assistant\",\n",
        "        tool_calls=[\n",
        "            {\n",
        "                \"name\": \"joke\",\n",
        "                \"args\": {\n",
        "                    \"setup\": \"Why don't planes ever get tired?\",\n",
        "                    \"punchline\": \"Because they have rest wings!\",\n",
        "                    \"rating\": 2,\n",
        "                },\n",
        "                \"id\": \"1\",\n",
        "            }\n",
        "        ],\n",
        "    ),\n",
        "    # Most tool-calling models expect a ToolMessage(s) to follow an AIMessage with tool calls.\n",
        "    ToolMessage(\"\", tool_call_id=\"1\"),\n",
        "    # Some models also expect an AIMessage to follow any ToolMessages,\n",
        "    # so you may need to add an AIMessage here.\n",
        "    HumanMessage(\"Tell me another joke about planes\", name=\"example_user\"),\n",
        "    AIMessage(\n",
        "        \"\",\n",
        "        name=\"example_assistant\",\n",
        "        tool_calls=[\n",
        "            {\n",
        "                \"name\": \"joke\",\n",
        "                \"args\": {\n",
        "                    \"setup\": \"Cargo\",\n",
        "                    \"punchline\": \"Cargo 'vroom vroom', but planes go 'zoom zoom'!\",\n",
        "                    \"rating\": 10,\n",
        "                },\n",
        "                \"id\": \"2\",\n",
        "            }\n",
        "        ],\n",
        "    ),\n",
        "    ToolMessage(\"\", tool_call_id=\"2\"),\n",
        "    HumanMessage(\"Now about caterpillars\", name=\"example_user\"),\n",
        "    AIMessage(\n",
        "        \"\",\n",
        "        tool_calls=[\n",
        "            {\n",
        "                \"name\": \"joke\",\n",
        "                \"args\": {\n",
        "                    \"setup\": \"Caterpillar\",\n",
        "                    \"punchline\": \"Caterpillar really slow, but watch me turn into a butterfly and steal the show!\",\n",
        "                    \"rating\": 5,\n",
        "                },\n",
        "                \"id\": \"3\",\n",
        "            }\n",
        "        ],\n",
        "    ),\n",
        "    ToolMessage(\"\", tool_call_id=\"3\"),\n",
        "]\n",
        "system = \"\"\"You are a hilarious comedian. Your specialty is knock-knock jokes. \\\n",
        "Return a joke which has the setup (the response to \"Who's there?\") \\\n",
        "and the final punchline (the response to \"<setup> who?\").\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system), (\"placeholder\", \"{examples}\"), (\"human\", \"{input}\")]\n",
        ")\n",
        "few_shot_structured_llm = prompt | structured_llm\n",
        "few_shot_structured_llm.invoke({\"input\": \"crocodiles\", \"examples\": examples})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "498d893b-ceaa-47ff-a9d8-4faa60702715",
      "metadata": {},
      "source": [
        "有关使用工具调用的少样本提示的更多信息，请参阅[此处](/docs/how_to/tools_few_shot/)。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39d7a555",
      "metadata": {},
      "source": [
        "### (高级) 指定输出结构化方法\n\n对于支持多种输出结构化方式的模型（即同时支持工具调用和 JSON 模式），您可以使用 `method=` 参数来指定使用哪种方式。\n\n:::info JSON 模式\n\n如果使用 JSON 模式，您仍然需要在模型提示中指定所需的 schema。您传递给 `with_structured_output` 的 schema 将仅用于解析模型输出，它不会像工具调用那样传递给模型。\n\n要查看您正在使用的模型是否支持 JSON 模式，请在其在[API 参考](https://python.langchain.com/api_reference/langchain/index.html)中的条目进行检查。\n\n:::"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "df0370e3",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'setup': 'Why was the cat sitting on the computer?',\n",
              " 'punchline': 'Because it wanted to keep an eye on the mouse!'}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "structured_llm = llm.with_structured_output(None, method=\"json_mode\")\n",
        "\n",
        "structured_llm.invoke(\n",
        "    \"Tell me a joke about cats, respond in JSON with `setup` and `punchline` keys\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91e95aa2",
      "metadata": {},
      "source": [
        "### （高级）原始输出\n\n大型语言模型在生成结构化输出方面并不完美，尤其是在模式变得复杂时。通过传递 `include_raw=True`，您可以避免引发异常并自行处理原始输出。这将输出格式更改为包含原始消息输出、`parsed` 值（如果成功）以及任何产生的错误："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "10ed2842",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'raw': AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_f25ZRmh8u5vHlOWfTUw8sJFZ', 'function': {'arguments': '{\"setup\":\"Why was the cat sitting on the computer?\",\"punchline\":\"Because it wanted to keep an eye on the mouse!\",\"rating\":7}', 'name': 'Joke'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 93, 'total_tokens': 126}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_4e2b2da518', 'finish_reason': 'stop', 'logprobs': None}, id='run-d880d7e2-df08-4e9e-ad92-dfc29f2fd52f-0', tool_calls=[{'name': 'Joke', 'args': {'setup': 'Why was the cat sitting on the computer?', 'punchline': 'Because it wanted to keep an eye on the mouse!', 'rating': 7}, 'id': 'call_f25ZRmh8u5vHlOWfTUw8sJFZ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 93, 'output_tokens': 33, 'total_tokens': 126}),\n",
              " 'parsed': {'setup': 'Why was the cat sitting on the computer?',\n",
              "  'punchline': 'Because it wanted to keep an eye on the mouse!',\n",
              "  'rating': 7},\n",
              " 'parsing_error': None}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "structured_llm = llm.with_structured_output(Joke, include_raw=True)\n",
        "\n",
        "structured_llm.invoke(\"Tell me a joke about cats\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e92a98a",
      "metadata": {},
      "source": [
        "## 直接提示和解析模型输出\n\n并非所有模型都支持 `.with_structured_output()`，因为并非所有模型都支持工具调用或 JSON 模式。对于这些模型，您需要直接提示模型使用特定格式，并使用输出解析器从原始模型输出中提取结构化响应。\n\n### 使用 `PydanticOutputParser`\n\n下面的示例使用内置的 [`PydanticOutputParser`](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.pydantic.PydanticOutputParser.html) 来解析聊天模型输出，该模型被提示以匹配给定的 Pydantic 模式。请注意，我们直接从解析器的方法中将 `format_instructions` 添加到提示中："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "6e514455",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "\n",
        "class Person(BaseModel):\n",
        "    \"\"\"Information about a person.\"\"\"\n",
        "\n",
        "    name: str = Field(..., description=\"The name of the person\")\n",
        "    height_in_meters: float = Field(\n",
        "        ..., description=\"The height of the person expressed in meters.\"\n",
        "    )\n",
        "\n",
        "\n",
        "class People(BaseModel):\n",
        "    \"\"\"Identifying information about all people in a text.\"\"\"\n",
        "\n",
        "    people: List[Person]\n",
        "\n",
        "\n",
        "# Set up a parser\n",
        "parser = PydanticOutputParser(pydantic_object=People)\n",
        "\n",
        "# Prompt\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"Answer the user query. Wrap the output in `json` tags\\n{format_instructions}\",\n",
        "        ),\n",
        "        (\"human\", \"{query}\"),\n",
        "    ]\n",
        ").partial(format_instructions=parser.get_format_instructions())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "082fa166",
      "metadata": {},
      "source": [
        "让我们看看发送给模型的信息："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "3d73d33d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "System: Answer the user query. Wrap the output in `json` tags\n",
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"description\": \"Identifying information about all people in a text.\", \"properties\": {\"people\": {\"title\": \"People\", \"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Person\"}}}, \"required\": [\"people\"], \"definitions\": {\"Person\": {\"title\": \"Person\", \"description\": \"Information about a person.\", \"type\": \"object\", \"properties\": {\"name\": {\"title\": \"Name\", \"description\": \"The name of the person\", \"type\": \"string\"}, \"height_in_meters\": {\"title\": \"Height In Meters\", \"description\": \"The height of the person expressed in meters.\", \"type\": \"number\"}}, \"required\": [\"name\", \"height_in_meters\"]}}}\n",
            "```\n",
            "Human: Anna is 23 years old and she is 6 feet tall\n"
          ]
        }
      ],
      "source": [
        "query = \"Anna is 23 years old and she is 6 feet tall\"\n",
        "\n",
        "print(prompt.invoke({\"query\": query}).to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "081956b9",
      "metadata": {},
      "source": [
        "现在来调用它："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8d6b3d17",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "People(people=[Person(name='Anna', height_in_meters=1.8288)])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain = prompt | llm | parser\n",
        "\n",
        "chain.invoke({\"query\": query})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6732dd87",
      "metadata": {},
      "source": [
        "要深入了解如何结合使用输出解析器和提示技术来获取结构化输出，请参阅 [此指南](/docs/how_to/output_parser_structured)。\n\n### 自定义解析\n\n您还可以使用 [LangChain Expression Language (LCEL)](/docs/concepts/lcel) 创建自定义提示和解析器，使用普通函数来解析模型输出："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e8d37e15",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "from typing import List\n",
        "\n",
        "from langchain_core.messages import AIMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "\n",
        "class Person(BaseModel):\n",
        "    \"\"\"Information about a person.\"\"\"\n",
        "\n",
        "    name: str = Field(..., description=\"The name of the person\")\n",
        "    height_in_meters: float = Field(\n",
        "        ..., description=\"The height of the person expressed in meters.\"\n",
        "    )\n",
        "\n",
        "\n",
        "class People(BaseModel):\n",
        "    \"\"\"Identifying information about all people in a text.\"\"\"\n",
        "\n",
        "    people: List[Person]\n",
        "\n",
        "\n",
        "# Prompt\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"Answer the user query. Output your answer as JSON that  \"\n",
        "            \"matches the given schema: ```json\\n{schema}\\n```. \"\n",
        "            \"Make sure to wrap the answer in ```json and ``` tags\",\n",
        "        ),\n",
        "        (\"human\", \"{query}\"),\n",
        "    ]\n",
        ").partial(schema=People.schema())\n",
        "\n",
        "\n",
        "# Custom parser\n",
        "def extract_json(message: AIMessage) -> List[dict]:\n",
        "    \"\"\"Extracts JSON content from a string where JSON is embedded between ```json and ``` tags.\n",
        "\n",
        "    Parameters:\n",
        "        text (str): The text containing the JSON content.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of extracted JSON strings.\n",
        "    \"\"\"\n",
        "    text = message.content\n",
        "    # Define the regular expression pattern to match JSON blocks\n",
        "    pattern = r\"```json(.*?)```\"\n",
        "\n",
        "    # Find all non-overlapping matches of the pattern in the string\n",
        "    matches = re.findall(pattern, text, re.DOTALL)\n",
        "\n",
        "    # Return the list of matched JSON strings, stripping any leading or trailing whitespace\n",
        "    try:\n",
        "        return [json.loads(match.strip()) for match in matches]\n",
        "    except Exception:\n",
        "        raise ValueError(f\"Failed to parse: {message}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f1bc8f7",
      "metadata": {},
      "source": [
        "Here is the prompt sent to the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c8a30d0e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "System: Answer the user query. Output your answer as JSON that  matches the given schema: ```json\n",
            "{'title': 'People', 'description': 'Identifying information about all people in a text.', 'type': 'object', 'properties': {'people': {'title': 'People', 'type': 'array', 'items': {'$ref': '#/definitions/Person'}}}, 'required': ['people'], 'definitions': {'Person': {'title': 'Person', 'description': 'Information about a person.', 'type': 'object', 'properties': {'name': {'title': 'Name', 'description': 'The name of the person', 'type': 'string'}, 'height_in_meters': {'title': 'Height In Meters', 'description': 'The height of the person expressed in meters.', 'type': 'number'}}, 'required': ['name', 'height_in_meters']}}}\n",
            "```. Make sure to wrap the answer in ```json and ``` tags\n",
            "Human: Anna is 23 years old and she is 6 feet tall\n"
          ]
        }
      ],
      "source": [
        "query = \"Anna is 23 years old and she is 6 feet tall\"\n",
        "\n",
        "print(prompt.format_prompt(query=query).to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec018893",
      "metadata": {},
      "source": [
        "然后，当我们调用它时，它的外观如下："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e1e7baf6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'people': [{'name': 'Anna', 'height_in_meters': 1.8288}]}]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain = prompt | llm | extract_json\n",
        "\n",
        "chain.invoke({\"query\": query})"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}