{
  "cells": [
    {
      "cell_type": "raw",
      "id": "8165bd4c",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "keywords: [memory]\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f47033eb",
      "metadata": {},
      "source": [
        "# 如何添加消息历史记录\n\n:::info 先决条件\n\n本指南假定您熟悉以下概念：\n- [链接 runnable](/docs/how_to/sequence/)\n- [Prompt 模板](/docs/concepts/prompt_templates)\n- [Chat Messages](/docs/concepts/messages)\n- [LangGraph 持久化](https://langchain-ai.github.io/langgraph/how-tos/persistence/)\n\n:::\n\n:::note\n\n本指南之前涵盖了 [RunnableWithMessageHistory](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html) 抽象。您可以在 [v0.2 文档](https://python.langchain.com/v0.2/docs/how_to/message_history/) 中访问此版本的指南。\n\n自 LangChain v0.3 版本发布以来，我们建议 LangChain 用户利用 [LangGraph 持久化](https://langchain-ai.github.io/langgraph/concepts/persistence/) 将 `memory` 整合到新的 LangChain 应用程序中。\n\n如果您现有的代码已经依赖于 `RunnableWithMessageHistory` 或 `BaseChatMessageHistory`，您 **无需** 进行任何更改。我们不打算在短期内弃用此功能，因为它适用于简单的聊天应用程序，并且任何使用 `RunnableWithMessageHistory` 的代码将继续按预期工作。\n\n有关更多详细信息，请参阅 [如何迁移到 LangGraph Memory](/docs/versions/migrating_memory/)。\n:::\n\n在构建聊天机器人时，将对话状态传入和传出链至关重要。LangGraph 实现了内置的持久化层，允许链状态自动持久化到内存或外部后端，例如 SQLite、Postgres 或 Redis。详细信息可在 LangGraph [持久化文档](https://langchain-ai.github.io/langgraph/how-tos/persistence/) 中找到。\n\n在本指南中，我们将通过将任意 LangChain runnable 包装在一个最小的 LangGraph 应用程序中来演示如何为其添加持久化。这使我们能够持久化消息历史记录和其他链状态元素，从而简化多轮应用程序的开发。它还支持多线程，使单个应用程序能够与多个用户单独交互。\n\n## 设置\n\n让我们初始化一个聊天模型：\n\nimport ChatModelTabs from \"@theme/ChatModelTabs\";\n\n<ChatModelTabs\n  customVarName=\"llm\"\n/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ca50d084-ae4b-4aea-9eb7-2ebc699df9bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# | output: false\n",
        "# | echo: false\n",
        "\n",
        "# import os\n",
        "# from getpass import getpass\n",
        "\n",
        "# os.environ[\"ANTHROPIC_API_KEY\"] = getpass()\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "\n",
        "llm = ChatAnthropic(model=\"claude-3-haiku-20240307\", temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f6121bc-2080-4ccc-acf0-f77de4bc951d",
      "metadata": {},
      "source": [
        "## 示例：消息输入\n\n为 [聊天模型](/docs/concepts/chat_models) 添加记忆是一个简单的例子。聊天模型接受消息列表作为输入并输出消息。LangGraph 提供了一个内置的 `MessagesState`，我们可以为此目的使用。\n\n下面，我们：\n1. 将图状态定义为消息列表；\n2. 向图中添加一个调用聊天模型的节点；\n3. 使用内存中的 checkpointer 编译图，以在运行之间存储消息。\n\n:::info\n\nLangGraph 应用程序的输出是其 [状态](https://langchain-ai.github.io/langgraph/concepts/low_level/)。这可以是任何 Python 类型，但在这种情况下，它通常会是与你的可运行对象模式匹配的 `TypedDict`。\n\n:::"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f691a73a-a866-4354-9fff-8315605e2b8f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import START, MessagesState, StateGraph\n",
        "\n",
        "# Define a new graph\n",
        "workflow = StateGraph(state_schema=MessagesState)\n",
        "\n",
        "\n",
        "# Define the function that calls the model\n",
        "def call_model(state: MessagesState):\n",
        "    response = llm.invoke(state[\"messages\"])\n",
        "    # Update message history with response:\n",
        "    return {\"messages\": response}\n",
        "\n",
        "\n",
        "# Define the (single) node in the graph\n",
        "workflow.add_edge(START, \"model\")\n",
        "workflow.add_node(\"model\", call_model)\n",
        "\n",
        "# Add memory\n",
        "memory = MemorySaver()\n",
        "app = workflow.compile(checkpointer=memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0b396a8-f81e-4139-b4b2-75adf61d8179",
      "metadata": {},
      "source": [
        "当我们运行应用程序时，我们会传入一个配置 `dict`，其中指定了一个 `thread_id`。此 ID 用于区分会话线程（例如，不同用户之间的会话）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e4309511-2140-4d91-8f5f-ea3661e6d179",
      "metadata": {},
      "outputs": [],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "108c45a2-4971-4120-ba64-9a4305a414bb",
      "metadata": {},
      "source": [
        "然后，我们可以调用该应用程序："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "72a5ff6c-501f-4151-8dd9-f600f70554be",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "It's nice to meet you, Bob! I'm Claude, an AI assistant created by Anthropic. How can I help you today?\n"
          ]
        }
      ],
      "source": [
        "query = \"Hi! I'm Bob.\"\n",
        "\n",
        "input_messages = [HumanMessage(query)]\n",
        "output = app.invoke({\"messages\": input_messages}, config)\n",
        "output[\"messages\"][-1].pretty_print()  # output contains all messages in state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5931fb35-0fac-40e7-8ac6-b14cb4e926cd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Your name is Bob, as you introduced yourself at the beginning of our conversation.\n"
          ]
        }
      ],
      "source": [
        "query = \"What's my name?\"\n",
        "\n",
        "input_messages = [HumanMessage(query)]\n",
        "output = app.invoke({\"messages\": input_messages}, config)\n",
        "output[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91de6d12-881d-4d23-a421-f2e3bf829b79",
      "metadata": {},
      "source": [
        "请注意，状态是针对不同线程分开的。如果我们向具有新的 `thread_id` 的线程发出相同的查询，模型会表明它不知道答案："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6f12c26f-8913-4484-b2c5-b49eda2e6d7d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "I'm afraid I don't actually know your name. As an AI assistant, I don't have personal information about you unless you provide it to me directly.\n"
          ]
        }
      ],
      "source": [
        "query = \"What's my name?\"\n",
        "config = {\"configurable\": {\"thread_id\": \"abc234\"}}\n",
        "\n",
        "input_messages = [HumanMessage(query)]\n",
        "output = app.invoke({\"messages\": input_messages}, config)\n",
        "output[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6749ea95-3382-4843-bb96-cfececb9e4e5",
      "metadata": {},
      "source": [
        "## 示例：字典输入\n\nLangChain 的 runnables 通常通过单个`dict`参数中的不同键接受多个输入。一个常见的例子是带有多个参数的提示模板。\n\n虽然之前我们的 runnable 是一个聊天模型，但在这里我们组合了提示模板和聊天模型。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6e7a402a-0994-4fc5-a607-fb990a248aa4",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"Answer in {language}.\"),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "runnable = prompt | llm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f83107bd-ae61-45e1-a57e-94ab043aad4b",
      "metadata": {},
      "source": [
        "对于此场景，我们将图状态定义为包含这些参数（除了消息历史记录）。然后，我们以与之前相同的方式定义一个单节点图。\n\n请注意，在下面的状态中：\n- 对 `messages` 列表的更新将追加消息；\n- 对 `language` 字符串的更新将覆盖该字符串。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "267429ea-be0f-4f80-8daf-c63d881a1436",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Sequence\n",
        "\n",
        "from langchain_core.messages import BaseMessage\n",
        "from langgraph.graph.message import add_messages\n",
        "from typing_extensions import Annotated, TypedDict\n",
        "\n",
        "\n",
        "# highlight-next-line\n",
        "class State(TypedDict):\n",
        "    # highlight-next-line\n",
        "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
        "    # highlight-next-line\n",
        "    language: str\n",
        "\n",
        "\n",
        "workflow = StateGraph(state_schema=State)\n",
        "\n",
        "\n",
        "def call_model(state: State):\n",
        "    response = runnable.invoke(state)\n",
        "    # Update message history with response:\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "\n",
        "workflow.add_edge(START, \"model\")\n",
        "workflow.add_node(\"model\", call_model)\n",
        "\n",
        "memory = MemorySaver()\n",
        "app = workflow.compile(checkpointer=memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f3844fb4-58d7-43c8-b427-6d9f64d7411b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "¡Hola, Bob! Es un placer conocerte.\n"
          ]
        }
      ],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"abc345\"}}\n",
        "\n",
        "input_dict = {\n",
        "    \"messages\": [HumanMessage(\"Hi, I'm Bob.\")],\n",
        "    \"language\": \"Spanish\",\n",
        "}\n",
        "output = app.invoke(input_dict, config)\n",
        "output[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7df47824-ef18-4a6e-a416-345ec9203f88",
      "metadata": {},
      "source": [
        "## 管理消息历史记录\n\n消息历史记录（以及应用程序状态的其他元素）可以通过 `.get_state` 访问："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "1cbd6d82-43c1-4d11-98af-5c3ad9cd9b3b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Language: Spanish\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Hi, I'm Bob.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "¡Hola, Bob! Es un placer conocerte.\n"
          ]
        }
      ],
      "source": [
        "state = app.get_state(config).values\n",
        "\n",
        "print(f'Language: {state[\"language\"]}')\n",
        "for message in state[\"messages\"]:\n",
        "    message.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acfbccda-0bd6-4c4d-ae6e-8118520314e1",
      "metadata": {},
      "source": [
        "我们也可以通过 `.update_state` 来更新 state。例如，我们可以手动添加一条新消息："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e98310d7-8ab1-461d-94a7-dd419494ab8d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "_ = app.update_state(config, {\"messages\": [HumanMessage(\"Test\")]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "74ab3691-6f3b-49c5-aad0-2a90fc2a1e6a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Language: Spanish\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Hi, I'm Bob.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "¡Hola, Bob! Es un placer conocerte.\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Test\n"
          ]
        }
      ],
      "source": [
        "state = app.get_state(config).values\n",
        "\n",
        "print(f'Language: {state[\"language\"]}')\n",
        "for message in state[\"messages\"]:\n",
        "    message.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4a1ea00-d7ff-4f18-b9ec-9aec5909d027",
      "metadata": {},
      "source": [
        "有关管理状态的详细信息，包括删除消息，请参阅 LangGraph 文档：\n- [如何删除消息](https://langchain-ai.github.io/langgraph/how-tos/memory/delete-messages/)\n- [如何查看和更新过去的图状态](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/time-travel/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "870c9c5b-c859-4c0e-9cbd-3555e6ed11e4",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}