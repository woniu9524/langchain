---
sidebar_position: 0
sidebar_class_name: hidden
---

# 操作指南

在这里，您可以找到“我该如何……？”这类问题的答案。
这些指南是*以目标为导向*并且*具体*的；它们旨在帮助您完成特定任务。
有关概念性解释，请参阅[概念指南](/docs/concepts/)。
有关端到端演练，请参阅[教程](/docs/tutorials)。
有关每个类和函数的详尽描述，请参阅[API 参考](https://python.langchain.com/api_reference/)。

## 安装

- [操作指南：安装 LangChain 包](/docs/how_to/installation/)
- [操作指南：使用不同 Pydantic 版本的 LangChain](/docs/how_to/pydantic_compatibility)

## 核心功能

此处重点介绍使用 LangChain 的核心功能。

- [操作指南：从模型返回结构化数据](/docs/how_to/structured_output/)
- [操作指南：使用模型调用工具](/docs/how_to/tool_calling)
- [操作指南：流式传输可运行对象](/docs/how_to/streaming)
- [操作指南：调试您的 LLM 应用](/docs/how_to/debugging/)

## 组件

这些是构建应用程序时可以使用核心构建块。

### 聊天模型

[聊天模型](/docs/concepts/chat_models)是较新形式的语言模型，它们接收消息并输出消息。
有关从特定提供者开始使用聊天模型的详细信息，请参阅[支持的集成](/docs/integrations/chat/)。

- [操作指南：进行函数/工具调用](/docs/how_to/tool_calling)
- [操作指南：让模型返回结构化输出](/docs/how_to/structured_output)
- [操作指南：缓存模型响应](/docs/how_to/chat_model_caching)
- [操作指南：获取对数概率](/docs/how_to/logprobs)
- [操作指南：创建自定义聊天模型类](/docs/how_to/custom_chat_model)
- [操作指南：将响应流式回传](/docs/how_to/chat_streaming)
- [操作指南：跟踪令牌使用情况](/docs/how_to/chat_token_usage_tracking)
- [操作指南：跟踪不同提供商的响应元数据](/docs/how_to/response_metadata)
- [操作指南：使用聊天模型调用工具](/docs/how_to/tool_calling)
- [操作指南：流式传输工具调用](/docs/how_to/tool_streaming)
- [操作指南：处理速率限制](/docs/how_to/chat_model_rate_limiting)
- [操作指南：示例提示工具行为](/docs/how_to/tools_few_shot)
- [操作指南：绑定特定于模型的格式化工具](/docs/how_to/tools_model_specific)
- [操作指南：强制进行特定的工具调用](/docs/how_to/tool_choice)
- [操作指南：处理本地模型](/docs/how_to/local_llms)
- [操作指南：一行初始化任何模型](/docs/how_to/chat_models_universal_init/)
- [操作指南：直接将多模态数据传递给模型](/docs/how_to/multimodal_inputs/)

### 消息

[消息](/docs/concepts/messages)是聊天模型的输入和输出。它们具有一些 `content` 和一个 `role`，用于描述消息的来源。

- [操作指南：修剪消息](/docs/how_to/trim_messages/)
- [操作指南：过滤消息](/docs/how_to/filter_messages/)
- [操作指南：合并连续相同类型的消息](/docs/how_to/merge_message_runs/)

### 提示模板

[提示模板](/docs/concepts/prompt_templates)负责将用户输入格式化为可以传递给语言模型的格式。

- [操作指南：使用少样本示例](/docs/how_to/few_shot_examples)
- [操作指南：在聊天模型中使用少样本示例](/docs/how_to/few_shot_examples_chat/)
- [操作指南：部分格式化提示模板](/docs/how_to/prompts_partial)
- [操作指南：组合提示](/docs/how_to/prompts_composition)
- [操作指南：使用多模态提示](/docs/how_to/multimodal_prompts/)

### 示例选择器

[示例选择器](/docs/concepts/example_selectors)负责选择要传递给提示的正确少样本示例。

- [操作指南：使用示例选择器](/docs/how_to/example_selectors)
- [操作指南：按长度选择示例](/docs/how_to/example_selectors_length_based)
- [操作指南：按语义相似性选择示例](/docs/how_to/example_selectors_similarity)
- [操作指南：按语义 n-gram 重叠选择示例](/docs/how_to/example_selectors_ngram)
- [操作指南：按最大边际相关性选择示例](/docs/how_to/example_selectors_mmr)
- [操作指南：从 LangSmith 少样本数据集选择示例](/docs/how_to/example_selectors_langsmith/)

### LLMs

LangChain 所谓的[LLMs](/docs/concepts/text_llms)是较早形式的语言模型，它们接收字符串并输出字符串。

- [操作指南：缓存模型响应](/docs/how_to/llm_caching)
- [操作指南：创建自定义 LLM 类](/docs/how_to/custom_llm)
- [操作指南：将响应流式回传](/docs/how_to/streaming_llm)
- [操作指南：跟踪令牌使用情况](/docs/how_to/llm_token_usage_tracking)
- [操作指南：处理本地模型](/docs/how_to/local_llms)

### 输出解析器

[输出解析器](/docs/concepts/output_parsers)负责获取 LLM 的输出并将其解析为更结构化的格式。

- [操作指南：从消息对象解析文本](/docs/how_to/output_parser_string)
- [操作指南：使用输出解析器将 LLM 响应解析为结构化格式](/docs/how_to/output_parser_structured)
- [操作指南：解析 JSON 输出](/docs/how_to/output_parser_json)
- [操作指南：解析 XML 输出](/docs/how_to/output_parser_xml)
- [操作指南：解析 YAML 输出](/docs/how_to/output_parser_yaml)
- [操作指南：在输出解析错误发生时重试](/docs/how_to/output_parser_retry)
- [操作指南：尝试修复输出解析中的错误](/docs/how_to/output_parser_fixing)
- [操作指南：编写自定义输出解析器类](/docs/how_to/output_parser_custom)

### 文档加载器

[文档加载器](/docs/concepts/document_loaders)负责从各种来源加载文档。

- [操作指南：加载 PDF 文件](/docs/how_to/document_loader_pdf)
- [操作指南：加载网页](/docs/how_to/document_loader_web)
- [操作指南：加载 CSV 数据](/docs/how_to/document_loader_csv)
- [操作指南：从目录加载数据](/docs/how_to/document_loader_directory)
- [操作指南：加载 HTML 数据](/docs/how_to/document_loader_html)
- [操作指南：加载 JSON 数据](/docs/how_to/document_loader_json)
- [操作指南：加载 Markdown 数据](/docs/how_to/document_loader_markdown)
- [操作指南：加载 Microsoft Office 文件](/docs/how_to/document_loader_office_file)
- [操作指南：编写自定义文档加载器](/docs/how_to/document_loader_custom)

### 文本分割器

[文本分割器](/docs/concepts/text_splitters)接收一个文档并将其分割成可用于检索的块。

- [操作指南：递归分割文本](/docs/how_to/recursive_text_splitter)
- [操作指南：分割 HTML](/docs/how_to/split_html)
- [操作指南：按字符分割](/docs/how_to/character_text_splitter)
- [操作指南：分割代码](/docs/how_to/code_splitter)
- [操作指南：按标题分割 Markdown](/docs/how_to/markdown_header_metadata_splitter)
- [操作指南：递归分割 JSON](/docs/how_to/recursive_json_splitter)
- [操作指南：将文本分割成语义块](/docs/how_to/semantic-chunker)
- [操作指南：按令牌分割](/docs/how_to/split_by_token)

### 嵌入模型

[嵌入模型](/docs/concepts/embedding_models)接收一段文本并为其创建一个数值表示。
有关从特定提供者开始使用嵌入模型的详细信息，请参阅[支持的集成](/docs/integrations/text_embedding/)。

- [操作指南：嵌入文本数据](/docs/how_to/embed_text)
- [操作指南：缓存嵌入结果](/docs/how_to/caching_embeddings)
- [操作指南：创建自定义嵌入类](/docs/how_to/custom_embeddings)

### 向量存储

[向量存储](/docs/concepts/vectorstores)是能够高效存储和检索嵌入的数据库。
有关从特定提供者开始使用向量存储的详细信息，请参阅[支持的集成](/docs/integrations/vectorstores/)。

- [操作指南：使用向量存储检索数据](/docs/how_to/vectorstores)

### 检索器

[检索器](/docs/concepts/retrievers)负责接收查询并返回相关文档。

- [操作指南：使用向量存储检索数据](/docs/how_to/vectorstore_retriever)
- [操作指南：生成多个查询以检索数据](/docs/how_to/MultiQueryRetriever)
- [操作指南：使用上下文压缩来压缩检索到的数据](/docs/how_to/contextual_compression)
- [操作指南：编写自定义检索器类](/docs/how_to/custom_retriever)
- [操作指南：为检索结果添加相似度分数](/docs/how_to/add_scores_retriever)
- [操作指南：合并来自多个检索器的结果](/docs/how_to/ensemble_retriever)
- [操作指南：重新排序检索到的结果以减轻“中间丢失”效应](/docs/how_to/long_context_reorder)
- [操作指南：为每个文档生成多个嵌入](/docs/how_to/multi_vector)
- [操作指南：检索块的整个文档](/docs/how_to/parent_document_retriever)
- [操作指南：生成元数据过滤器](/docs/how_to/self_query)
- [操作指南：创建时间加权检索器](/docs/how_to/time_weighted_vectorstore)
- [操作指南：使用混合向量和关键字检索](/docs/how_to/hybrid)

### 索引

索引是使向量存储与底层数据源保持同步的过程。

- [操作指南：重新索引数据以使向量存储与底层数据源保持同步](/docs/how_to/indexing)

### 工具

LangChain [工具](/docs/concepts/tools)包含工具的描述（用于传递给语言模型）以及要调用的函数实现。有关预构建工具的列表，请参阅[此处](/docs/integrations/tools/)。

- [操作指南：创建工具](/docs/how_to/custom_tools)
- [操作指南：使用内置工具和工具包](/docs/how_to/tools_builtin)
- [操作指南：使用聊天模型调用工具](/docs/how_to/tool_calling)
- [操作指南：将工具输出传递给聊天模型](/docs/how_to/tool_results_pass_to_model)
- [操作指南：将运行时值传递给工具](/docs/how_to/tool_runtime)
- [操作指南：为工具添加人工干预](/docs/how_to/tools_human)
- [操作指南：处理工具错误](/docs/how_to/tools_error)
- [操作指南：强制模型调用工具](/docs/how_to/tool_choice)
- [操作指南：禁用并行工具调用](/docs/how_to/tool_calling_parallel)
- [操作指南：从工具访问 `RunnableConfig`](/docs/how_to/tool_configure)
- [操作指南：从工具流式传输事件](/docs/how_to/tool_stream_events)
- [操作指南：从工具返回工件](/docs/how_to/tool_artifacts/)
- [操作指南：将可运行对象转换为工具](/docs/how_to/convert_runnable_to_tool)
- [操作指南：为模型添加临时工具调用功能](/docs/how_to/tools_prompting)
- [操作指南：传入运行时密钥](/docs/how_to/runnable_runtime_secrets)

### 多模态

- [操作指南：直接将多模态数据传递给模型](/docs/how_to/multimodal_inputs/)
- [操作指南：使用多模态提示](/docs/how_to/multimodal_prompts/)


### 智能体 (Agents)

:::note

有关智能体的深入操作指南，请查看[LangGraph](https://langchain-ai.github.io/langgraph/)文档。

:::

- [操作指南：使用旧版 LangChain 智能体 (AgentExecutor)](/docs/how_to/agent_executor)
- [操作指南：从旧版 LangChain 智能体迁移到 LangGraph](/docs/how_to/migrate_agent)

### 回调

[回调](/docs/concepts/callbacks)允许您挂钩到 LLM 应用程序执行的各个阶段。

- [操作指南：在运行时传入回调](/docs/how_to/callbacks_runtime)
- [操作指南：将回调附加到模块](/docs/how_to/callbacks_attach)
- [操作指南：将回调传递到模块构造函数中](/docs/how_to/callbacks_constructor)
- [操作指南：创建自定义回调处理程序](/docs/how_to/custom_callbacks)
- [操作指南：在异步环境中使用回调](/docs/how_to/callbacks_async)
- [操作指南：分派自定义回调事件](/docs/how_to/callbacks_custom_events)

### 自定义

LangChain 的所有组件都可以轻松扩展以支持您自己的版本。

- [操作指南：创建自定义聊天模型类](/docs/how_to/custom_chat_model)
- [操作指南：创建自定义 LLM 类](/docs/how_to/custom_llm)
- [操作指南：创建自定义嵌入类](/docs/how_to/custom_embeddings)
- [操作指南：编写自定义检索器类](/docs/how_to/custom_retriever)
- [操作指南：编写自定义文档加载器](/docs/how_to/document_loader_custom)
- [操作指南：编写自定义输出解析器类](/docs/how_to/output_parser_custom)
- [操作指南：创建自定义回调处理程序](/docs/how_to/custom_callbacks)
- [操作指南：定义自定义工具](/docs/how_to/custom_tools)
- [操作指南：分派自定义回调事件](/docs/how_to/callbacks_custom_events)

### 序列化
- [操作指南：保存和加载 LangChain 对象](/docs/how_to/serialization)

## 用例

这些指南涵盖了特定用例的详细信息。

### RAG 问答

检索增强生成 (RAG) 是一种将 LLM 连接到外部数据源的方法。
有关 RAG 的高级教程，请查看[本指南](/docs/tutorials/rag/)。

- [操作指南：添加聊天历史记录](/docs/how_to/qa_chat_history_how_to/)
- [操作指南：流式传输](/docs/how_to/qa_streaming/)
- [操作指南：返回来源](/docs/how_to/qa_sources/)
- [操作指南：返回引用](/docs/how_to/qa_citations/)
- [操作指南：进行按用户检索](/docs/how_to/qa_per_user/)


### 提取

提取是指使用 LLM 从非结构化文本中提取结构化信息。
有关提取的高级教程，请查看[本指南](/docs/tutorials/extraction/)。

- [操作指南：使用参考示例](/docs/how_to/extraction_examples/)
- [操作指南：处理长文本](/docs/how_to/extraction_long_text/)
- [操作指南：在不使用函数调用的情况下进行提取](/docs/how_to/extraction_parse)

### 聊天机器人

聊天机器人涉及使用 LLM 进行对话。
有关构建聊天机器人的高级教程，请查看[本指南](/docs/tutorials/chatbot/)。

- [操作指南：管理内存](/docs/how_to/chatbots_memory)
- [操作指南：进行检索](/docs/how_to/chatbots_retrieval)
- [操作指南：使用工具](/docs/how_to/chatbots_tools)
- [操作指南：管理大量聊天历史记录](/docs/how_to/trim_messages/)

### 查询分析

查询分析是指使用 LLM 生成要发送给检索器的查询的任务。
有关查询分析的高级教程，请查看[本指南](/docs/tutorials/rag/#query-analysis)。

- [操作指南：向提示添加示例](/docs/how_to/query_few_shot)
- [操作指南：处理未生成任何查询的情况](/docs/how_to/query_no_queries)
- [操作指南：处理多个查询](/docs/how_to/query_multiple_queries)
- [操作指南：处理多个检索器](/docs/how_to/query_multiple_retrievers)
- [操作指南：构建过滤器](/docs/how_to/query_constructing_filters)
- [操作指南：处理高基数分类变量](/docs/how_to/query_high_cardinality)

### SQL + CSV 上的问答

您可以使用 LLM 来对表格数据进行问答。
有关高级教程，请查看[本指南](/docs/tutorials/sql_qa/)。

- [操作指南：使用提示来改进结果](/docs/how_to/sql_prompting)
- [操作指南：进行查询验证](/docs/how_to/sql_query_checking)
- [操作指南：处理大型数据库](/docs/how_to/sql_large_db)
- [操作指南：处理 CSV 文件](/docs/how_to/sql_csv)

### 图数据库上的问答

您可以使用 LLM 来对图数据库进行问答。
有关高级教程，请查看[本指南](/docs/tutorials/graph/)。

- [操作指南：在数据库之上添加语义层](/docs/how_to/graph_semantic)
- [操作指南：构建知识图谱](/docs/how_to/graph_constructing)

### 摘要

LLM 可以对文本进行摘要并以其他方式提炼所需信息，包括
大量文本。有关高级教程，请查看[本指南](/docs/tutorials/summarization)。

- [操作指南：单次 LLM 调用中摘要文本](/docs/how_to/summarize_stuff)
- [操作指南：通过并行化摘要文本](/docs/how_to/summarize_map_reduce)
- [操作指南：通过迭代改进摘要文本](/docs/how_to/summarize_refine)

## LangChain 表达式语言 (LCEL)

:::note 我应该使用 LCEL 吗？

LCEL 是一个编排解决方案。有关何时使用 LCEL 的建议，请参阅我们的
[概念页面](/docs/concepts/lcel/#should-i-use-lcel)。

:::

[LangChain 表达式语言](/docs/concepts/lcel)是一种创建任意自定义链的方法。它建立在[Runnable](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html)协议之上。

[**LCEL 速查表**](/docs/how_to/lcel_cheatsheet/)：快速概览主要 LCEL 原语的使用方法。

[**迁移指南**](/docs/versions/migrating_chains)：有关将旧版链抽象迁移到 LCEL 的说明。

- [操作指南：链接可运行对象](/docs/how_to/sequence)
- [操作指南：流式传输可运行对象](/docs/how_to/streaming)
- [操作指南：并行调用可运行对象](/docs/how_to/parallel/)
- [操作指南：为可运行对象添加默认调用参数](/docs/how_to/binding/)
- [操作指南：将任何函数转换为可运行对象](/docs/how_to/functions)
- [操作指南：将输入从一个链步骤传递到下一个](/docs/how_to/passthrough)
- [操作指南：在运行时配置可运行对象的行为](/docs/how_to/configure)
- [操作指南：向链添加消息历史记录（内存）](/docs/how_to/message_history)
- [操作指南：在子链之间进行路由](/docs/how_to/routing)
- [操作指南：创建动态（自构建）链](/docs/how_to/dynamic_chain/)
- [操作指南：检查可运行对象](/docs/how_to/inspect)
- [操作指南：为可运行对象添加回退选项](/docs/how_to/fallbacks)
- [操作指南：将运行时密钥传递给可运行对象](/docs/how_to/runnable_runtime_secrets)

## [LangGraph](https://langchain-ai.github.io/langgraph)

LangGraph 是 LangChain 的一个扩展，旨在通过将步骤建模为图中的边和节点来构建健壮且有状态的多角色 LLM 应用程序。

LangGraph 文档目前托管在单独的站点上。
您可以在此处浏览[LangGraph 操作指南](https://langchain-ai.github.io/langgraph/how-tos/)。

## [LangSmith](https://docs.smith.langchain.com/)

LangSmith 允许您密切跟踪、监控和评估您的 LLM 应用程序。
它与 LangChain 和 LangGraph 无缝集成，您可以将其用于在构建过程中检查和调试链和智能体的各个步骤。

LangSmith 文档托管在单独的站点上。
您可以浏览[LangSmith 操作指南](https://docs.smith.langchain.com/)，但我们将重点介绍一些与 LangChain 特别相关的部分：

### 评估
<span data-heading-keywords="evaluation,evaluate"></span>

评估性能是构建 LLM 驱动型应用程序的重要组成部分。
LangSmith 帮助完成从创建数据集到定义指标再到运行评估器的所有步骤。

要了解更多信息，请查看[LangSmith 评估操作指南](https://docs.smith.langchain.com/how_to_guides#evaluation)。

### 跟踪
<span data-heading-keywords="trace,tracing"></span>

跟踪使您能够深入了解链和智能体的内部工作原理，对于诊断问题至关重要。

- [操作指南：使用 LangChain 进行跟踪](https://docs.smith.langchain.com/how_to_guides/tracing/trace_with_langchain)
- [操作指南：为跟踪添加元数据和标签](https://docs.smith.langchain.com/how_to_guides/tracing/trace_with_langchain#add-metadata-and-tags-to-traces)

您可以在[LangSmith 文档的此部分](https://docs.smith.langchain.com/how_to_guides/tracing)中找到与跟踪相关的常规操作指南。