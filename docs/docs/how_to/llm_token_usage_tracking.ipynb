{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "90dff237-bc28-4185-a2c0-d5203bbdeacd",
      "metadata": {},
      "source": [
        "# 如何追踪大语言模型的 token 使用量\n\n追踪 [token](/docs/concepts/tokens/) 使用量以计算成本，是将应用投入生产的重要环节。本指南将介绍如何从 LangChain 模型调用中获取此信息。\n\n:::info 先决条件\n\n本指南假定您熟悉以下概念：\n\n- [大语言模型](/docs/concepts/text_llms)\n:::\n\n## 使用 LangSmith\n\n您可以使用 [LangSmith](https://www.langchain.com/langsmith) 来帮助追踪大语言模型应用中的 token 使用量。请参阅 [LangSmith 入门指南](https://docs.smith.langchain.com/)。\n\n## 使用回调\n\n有一些 API 特定的回调上下文管理器，允许您跨多次调用追踪 token 使用量。您需要检查您的特定模型是否支持此类集成。\n\n如果您的模型不支持此类集成，您可以创建一个自定义回调管理器，方法是借鉴 [OpenAI 回调管理器](https://python.langchain.com/api_reference/community/callbacks/langchain_community.callbacks.openai_info.OpenAICallbackHandler.html) 的实现。\n\n### OpenAI\n\n我们首先来看一个追踪单一聊天模型调用的 token 使用量的极其简单的示例。\n\n:::danger\n\n回调处理器目前不支持旧版语言模型（例如 `langchain_openai.OpenAI`）的流式 token 计数。有关在流式处理上下文中的支持，请参阅此处关于聊天模型的相应指南：[/docs/how_to/chat_token_usage_tracking](/docs/how_to/chat_token_usage_tracking)。\n\n:::"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f790edd9-823e-4bc5-befa-e9529c7237a0",
      "metadata": {},
      "source": [
        "### 单次调用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2eebbee2-6ca1-4fa8-a3aa-0376888ceefb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Why don't scientists trust atoms?\n",
            "\n",
            "Because they make up everything.\n",
            "---\n",
            "\n",
            "Total Tokens: 18\n",
            "Prompt Tokens: 4\n",
            "Completion Tokens: 14\n",
            "Total Cost (USD): $3.4e-05\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.callbacks import get_openai_callback\n",
        "from langchain_openai import OpenAI\n",
        "\n",
        "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\")\n",
        "\n",
        "with get_openai_callback() as cb:\n",
        "    result = llm.invoke(\"Tell me a joke\")\n",
        "    print(result)\n",
        "    print(\"---\")\n",
        "print()\n",
        "\n",
        "print(f\"Total Tokens: {cb.total_tokens}\")\n",
        "print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
        "print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
        "print(f\"Total Cost (USD): ${cb.total_cost}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7df3be35-dd97-4e3a-bd51-52434ab2249d",
      "metadata": {},
      "source": [
        "### 多次调用\n\n上下文管理器内的所有内容都将被跟踪。下面是一个示例，展示了如何使用它来跟踪链式调用中的多次调用。这也适用于可能使用多个步骤的 Agent。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3ec10419-294c-44bf-af85-86aabf457cb6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Why did the chicken go to the seance?\n",
            "\n",
            "To talk to the other side of the road!\n",
            "--\n",
            "\n",
            "\n",
            "Why did the fish need a lawyer?\n",
            "\n",
            "Because it got caught in a net!\n",
            "\n",
            "---\n",
            "Total Tokens: 50\n",
            "Prompt Tokens: 12\n",
            "Completion Tokens: 38\n",
            "Total Cost (USD): $9.400000000000001e-05\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.callbacks import get_openai_callback\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import OpenAI\n",
        "\n",
        "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\")\n",
        "\n",
        "template = PromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
        "chain = template | llm\n",
        "\n",
        "with get_openai_callback() as cb:\n",
        "    response = chain.invoke({\"topic\": \"birds\"})\n",
        "    print(response)\n",
        "    response = chain.invoke({\"topic\": \"fish\"})\n",
        "    print(\"--\")\n",
        "    print(response)\n",
        "\n",
        "\n",
        "print()\n",
        "print(\"---\")\n",
        "print(f\"Total Tokens: {cb.total_tokens}\")\n",
        "print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
        "print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
        "print(f\"Total Cost (USD): ${cb.total_cost}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad7a3fba-9fac-4222-8f87-d1d276d27d6e",
      "metadata": {
        "tags": []
      },
      "source": [
        "## 流式输出\n\n:::danger\n\n`get_openai_callback` 目前不支持流式输出的 token 计数（例如 `langchain_openai.OpenAI` 等旧版语言模型）。如果您希望在流式输出的上下文中正确计算 token 数量，有以下几种选择：\n\n- 按照[此指南](/docs/how_to/chat_token_usage_tracking)中的说明使用聊天模型；\n- 实现一个[自定义回调处理器](/docs/how_to/custom_callbacks/)，该处理器使用适当的 token 分割器来计算 token；\n- 使用 LangSmith 等监控平台[LangSmith](https://www.langchain.com/langsmith)。\n:::\n\n请注意，在使用旧版语言模型进行流式输出时，token 计数不会更新："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "cd61ed79-7858-49bb-afb5-d41291f597ba",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Why don't scientists trust atoms?\n",
            "\n",
            "Because they make up everything!\n",
            "\n",
            "Why don't scientists trust atoms?\n",
            "\n",
            "Because they make up everything.\n",
            "---\n",
            "\n",
            "Total Tokens: 0\n",
            "Prompt Tokens: 0\n",
            "Completion Tokens: 0\n",
            "Total Cost (USD): $0.0\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.callbacks import get_openai_callback\n",
        "from langchain_openai import OpenAI\n",
        "\n",
        "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\")\n",
        "\n",
        "with get_openai_callback() as cb:\n",
        "    for chunk in llm.stream(\"Tell me a joke\"):\n",
        "        print(chunk, end=\"\", flush=True)\n",
        "    print(result)\n",
        "    print(\"---\")\n",
        "print()\n",
        "\n",
        "print(f\"Total Tokens: {cb.total_tokens}\")\n",
        "print(f\"Prompt Tokens: {cb.prompt_tokens}\")\n",
        "print(f\"Completion Tokens: {cb.completion_tokens}\")\n",
        "print(f\"Total Cost (USD): ${cb.total_cost}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}