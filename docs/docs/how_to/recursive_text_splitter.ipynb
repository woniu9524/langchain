{
  "cells": [
    {
      "cell_type": "raw",
      "id": "52976910",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "keywords: [recursivecharactertextsplitter]\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a678d550",
      "metadata": {},
      "source": [
        "# 如何按字符递归拆分文本\n\n此[文本拆分器](/docs/concepts/text_splitters/)是推荐的通用文本拆分器。它由一个字符列表进行参数化。它会按顺序尝试拆分，直到块足够小为止。默认列表为 `[\"\\n\\n\", \"\\n\", \" \", \"\"]`。此方式的效果是尽可能地将所有段落（然后是句子，然后是单词）保持在一起，因为这些通常被认为是语义上最相关的文本片段。\n\n1. 文本的拆分方式：通过字符列表。\n2. 块大小的测量方式：通过字符数。\n\n下面我们展示了示例用法。\n\n要直接获取字符串内容，请使用 `.split_text`。\n\n要创建 LangChain [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) 对象（例如用于下游任务），请使用 `.create_documents`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c16167c-1e56-4e11-9b8b-60f93044498e",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -qU langchain-text-splitters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3390ae1d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and'\n",
            "page_content='of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.'\n"
          ]
        }
      ],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Load example document\n",
        "with open(\"state_of_the_union.txt\") as f:\n",
        "    state_of_the_union = f.read()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set a really small chunk size, just to show.\n",
        "    chunk_size=100,\n",
        "    chunk_overlap=20,\n",
        "    length_function=len,\n",
        "    is_separator_regex=False,\n",
        ")\n",
        "texts = text_splitter.create_documents([state_of_the_union])\n",
        "print(texts[0])\n",
        "print(texts[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0839f4f0",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and',\n",
              " 'of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.']"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_splitter.split_text(state_of_the_union)[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60336622-b9d0-4172-816a-6cd1bb9ec481",
      "metadata": {},
      "source": [
        "让我们回顾一下上面为 `RecursiveCharacterTextSplitter` 设置的参数：\n- `chunk_size`:‘‘一个分块的最大大小，大小由 `length_function` 确定。\n- `chunk_overlap`: ‘‘分块之间的目标重叠量。重叠的分块有助于在上下文被分割到不同分块时，减轻信息丢失。\n- `length_function`: ‘‘用于确定分块大小的函数。\n- `is_separator_regex`: ‘‘分隔符列表（默认为 `[\"\\n\\n\", \"\\n\", \" \", \"\"]`）是否应被解释为正则表达式。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b74939c",
      "metadata": {},
      "source": [
        "## 分割无词边界语言的文本\n\n一些书写系统没有[词边界](https://en.wikipedia.org/wiki/Category:Writing_systems_without_word_boundaries)，例如中文、日文和泰文。使用默认分隔符列表 `[\"\\n\\n\", \"\\n\", \" \", \"\"]` 分割文本可能会导致单词在块之间被拆分。为了保持单词的完整性，您可以覆盖分隔符列表以包含其他标点符号：\n\n* 添加 ASCII 句号“`.`”，[全角句号](https://en.wikipedia.org/wiki/Halfwidth_and_Fullwidth_Forms_(Unicode_block))“`．`”（用于中文文本），以及[中文日文句号](https://en.wikipedia.org/wiki/CJK_Symbols_and_Punctuation)“`。`”（用于日文和中文）\n* 添加用于泰文、缅甸文、高棉文和日文的[零宽空格](https://en.wikipedia.org/wiki/Zero-width_space)。\n* 添加 ASCII 逗号“`,`”，全角逗号“`，`”，以及中文日文逗号“`、`”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d48a8ef",
      "metadata": {},
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    separators=[\n",
        "        \"\\n\\n\",\n",
        "        \"\\n\",\n",
        "        \" \",\n",
        "        \".\",\n",
        "        \",\",\n",
        "        \"\\u200b\",  # Zero-width space\n",
        "        \"\\uff0c\",  # Fullwidth comma\n",
        "        \"\\u3001\",  # Ideographic comma\n",
        "        \"\\uff0e\",  # Fullwidth full stop\n",
        "        \"\\u3002\",  # Ideographic full stop\n",
        "        \"\",\n",
        "    ],\n",
        "    # Existing args\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}