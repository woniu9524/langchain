{
  "cells": [
    {
      "cell_type": "raw",
      "id": "beba2e0e",
      "metadata": {},
      "source": [
        "---\n",
        "sidebar_position: 2\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb0735c0",
      "metadata": {},
      "source": [
        "# å¦‚ä½•åœ¨èŠå¤©æ¨¡å‹ä¸­ä½¿ç”¨å°‘æ ·æœ¬ç¤ºä¾‹\n\n:::info å…ˆå†³æ¡ä»¶\n\næœ¬æŒ‡å—å‡å®šæ‚¨å·²ç†Ÿæ‚‰ä»¥ä¸‹æ¦‚å¿µï¼š\n- [Prompt æ¨¡æ¿](/docs/concepts/prompt_templates)\n- [ç¤ºä¾‹é€‰æ‹©å™¨](/docs/concepts/example_selectors)\n- [èŠå¤©æ¨¡å‹](/docs/concepts/chat_models)\n- [å‘é‡å­˜å‚¨](/docs/concepts/vectorstores)\n\n:::\n\næœ¬æŒ‡å—ä»‹ç»å¦‚ä½•ä½¿ç”¨ç¤ºä¾‹è¾“å…¥å’Œè¾“å‡ºæ¥æç¤ºèŠå¤©æ¨¡å‹ã€‚å‘æ¨¡å‹æä¾›å‡ ä¸ªè¿™æ ·çš„ç¤ºä¾‹ç§°ä¸º[å°‘æ ·æœ¬æç¤º](/docs/concepts/few_shot_prompting/)ï¼Œè¿™æ˜¯ä¸€ç§ç®€å•è€Œå¼ºå¤§çš„æŒ‡å¯¼ç”Ÿæˆçš„æ–¹æ³•ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹å¯ä»¥æ˜¾è‘—æé«˜æ¨¡å‹æ€§èƒ½ã€‚\n\nå¯¹äºå¦‚ä½•è¿›è¡Œå°‘æ ·æœ¬æç¤ºï¼Œä¼¼ä¹è¿˜æ²¡æœ‰è¾¾æˆå¹¿æ³›å…±è¯†ï¼Œå¹¶ä¸”æœ€ä¼˜çš„æç¤ºç¼–è¯‘å¾ˆå¯èƒ½å› æ¨¡å‹è€Œå¼‚ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æä¾›ç±»ä¼¼ [FewShotChatMessagePromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.few_shot.FewShotChatMessagePromptTemplate.html?highlight=fewshot#langchain_core.prompts.few_shot.FewShotChatMessagePromptTemplate) çš„å°‘æ ·æœ¬æç¤ºæ¨¡æ¿ï¼Œå°†å…¶ä½œä¸ºä¸€ä¸ªçµæ´»çš„èµ·ç‚¹ï¼Œæ‚¨å¯ä»¥æ ¹æ®éœ€è¦å¯¹å…¶è¿›è¡Œä¿®æ”¹æˆ–æ›¿æ¢ã€‚\n\nå°‘æ ·æœ¬æç¤ºæ¨¡æ¿çš„ç›®æ ‡æ˜¯æ ¹æ®è¾“å…¥åŠ¨æ€é€‰æ‹©ç¤ºä¾‹ï¼Œç„¶åå°†è¿™äº›ç¤ºä¾‹æ ¼å¼åŒ–åˆ°æœ€ç»ˆçš„æç¤ºä¸­æä¾›ç»™æ¨¡å‹ã€‚\n\n**æ³¨æ„ï¼š** ä»¥ä¸‹ä»£ç ç¤ºä¾‹ä»…é€‚ç”¨äºèŠå¤©æ¨¡å‹ï¼Œå› ä¸º `FewShotChatMessagePromptTemplates` è¢«è®¾è®¡ä¸ºè¾“å‡ºæ ¼å¼åŒ–çš„[èŠå¤©æ¶ˆæ¯](/docs/concepts/messages)ï¼Œè€Œä¸æ˜¯çº¯æ–‡æœ¬å­—ç¬¦ä¸²ã€‚å¯¹äºä¸å…¼å®¹å®Œæˆæ¨¡å‹ (LLM) çš„çº¯æ–‡æœ¬æ¨¡æ¿ç±»ä¼¼çš„å°‘æ ·æœ¬æç¤ºç¤ºä¾‹ï¼Œè¯·å‚é˜…[å°‘æ ·æœ¬æç¤ºæ¨¡æ¿](/docs/how_to/few_shot_examples/)æŒ‡å—ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d716f2de-cc29-4823-9360-a808c7bfdb86",
      "metadata": {
        "tags": []
      },
      "source": [
        "## å›ºå®šç¤ºä¾‹\n\næœ€åŸºæœ¬ï¼ˆä¹Ÿæ˜¯æœ€å¸¸ç”¨ï¼‰çš„å°‘æ ·æœ¬æç¤ºæŠ€æœ¯æ˜¯ä½¿ç”¨å›ºå®šæç¤ºç¤ºä¾‹ã€‚è¿™æ ·æ‚¨å°±å¯ä»¥é€‰æ‹©ä¸€ä¸ªé“¾ï¼Œå¯¹å…¶è¿›è¡Œè¯„ä¼°ï¼Œè€Œæ— éœ€æ‹…å¿ƒç”Ÿäº§ç¯å¢ƒä¸­çš„å…¶ä»–æ´»åŠ¨éƒ¨ä»¶ã€‚\n\næ¨¡æ¿çš„åŸºæœ¬ç»„æˆéƒ¨åˆ†æ˜¯ï¼š\n- `examples`: è¦åŒ…å«åœ¨æœ€ç»ˆæç¤ºä¸­çš„å­—å…¸ç¤ºä¾‹åˆ—è¡¨ã€‚\n- `example_prompt`: é€šè¿‡å…¶ [`format_messages`](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html?highlight=format_messages#langchain_core.prompts.chat.ChatPromptTemplate.format_messages) æ–¹æ³•å°†æ¯ä¸ªç¤ºä¾‹è½¬æ¢ä¸ºä¸€ä¸ªæˆ–å¤šä¸ªæ¶ˆæ¯ã€‚å¸¸è§çš„ç¤ºä¾‹æ˜¯å°†æ¯ä¸ªç¤ºä¾‹è½¬æ¢ä¸ºä¸€æ¡äººç±»æ¶ˆæ¯å’Œä¸€æ¡ AI å›å¤æ¶ˆæ¯ï¼Œæˆ–è€…æ˜¯ä¸€æ¡äººç±»æ¶ˆæ¯åè·Ÿä¸€æ¡å‡½æ•°è°ƒç”¨æ¶ˆæ¯ã€‚\n\nä¸‹é¢æ˜¯ä¸€ä¸ªç®€å•çš„æ¼”ç¤ºã€‚é¦–å…ˆï¼Œå®šä¹‰æ‚¨å¸Œæœ›åŒ…å«çš„ç¤ºä¾‹ã€‚è®©æˆ‘ä»¬ç»™ LLM ä¸€ä¸ªä¸ç†Ÿæ‚‰çš„æ•°å­¦è¿ç®—ç¬¦ï¼Œç”¨â€œğŸ¦œâ€ç¬¦å·è¡¨ç¤ºï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5b79e400",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -qU langchain langchain-openai langchain-chroma\n",
        "\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30856d92",
      "metadata": {},
      "source": [
        "å¦‚æœæˆ‘ä»¬é—®æ¨¡å‹è¿™ä¸ªè¡¨è¾¾å¼çš„ç»“æœæ˜¯ä»€ä¹ˆï¼Œå®ƒä¼šå¤±è´¥ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "174dec5b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='The expression \"2 ğŸ¦œ 9\" is not a standard mathematical operation or equation. It appears to be a combination of the number 2 and the parrot emoji ğŸ¦œ followed by the number 9. It does not have a specific mathematical meaning.', response_metadata={'token_usage': {'completion_tokens': 54, 'prompt_tokens': 17, 'total_tokens': 71}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-aad12dda-5c47-4a1e-9949-6fe94e03242a-0', usage_metadata={'input_tokens': 17, 'output_tokens': 54, 'total_tokens': 71})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
        "\n",
        "model.invoke(\"What is 2 ğŸ¦œ 9?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6d58385",
      "metadata": {},
      "source": [
        "ç°åœ¨æˆ‘ä»¬æ¥çœ‹çœ‹ï¼Œå¦‚æœæˆ‘ä»¬ç»™ LLM ä¸€äº›ç¤ºä¾‹æ¥è®©å®ƒå·¥ä½œï¼Œä¼šå‘ç”Ÿä»€ä¹ˆã€‚æˆ‘ä»¬å°†åœ¨ä¸‹é¢å®šä¹‰ä¸€äº›ç¤ºä¾‹ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0fc5a02a-6249-4e92-95c3-30fff9671e8b",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
        "\n",
        "examples = [\n",
        "    {\"input\": \"2 ğŸ¦œ 2\", \"output\": \"4\"},\n",
        "    {\"input\": \"2 ğŸ¦œ 3\", \"output\": \"5\"},\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8710ecc-2aa0-4172-a74c-250f6bc3d9e2",
      "metadata": {},
      "source": [
        "æ¥ä¸‹æ¥ï¼Œå°†å®ƒä»¬ç»„åˆæˆ few-shot prompt æ¨¡æ¿ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "65e72ad1-9060-47d0-91a1-bc130c8b98ac",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[HumanMessage(content='2 ğŸ¦œ 2'), AIMessage(content='4'), HumanMessage(content='2 ğŸ¦œ 3'), AIMessage(content='5')]\n"
          ]
        }
      ],
      "source": [
        "# This is a prompt template used to format each individual example.\n",
        "example_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"human\", \"{input}\"),\n",
        "        (\"ai\", \"{output}\"),\n",
        "    ]\n",
        ")\n",
        "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
        "    example_prompt=example_prompt,\n",
        "    examples=examples,\n",
        ")\n",
        "\n",
        "print(few_shot_prompt.invoke({}).to_messages())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5490bd59-b28f-46a4-bbdf-0191802dd3c5",
      "metadata": {},
      "source": [
        "æœ€åï¼Œæˆ‘ä»¬ç»„è£…æœ€ç»ˆçš„æç¤ºï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼Œå°† `few_shot_prompt` ç›´æ¥ä¼ é€’ç»™ `from_messages` å·¥å‚æ–¹æ³•ï¼Œå¹¶å°†å…¶ä¸æ¨¡å‹ä¸€èµ·ä½¿ç”¨ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9f86d6d9-50de-41b6-b6c7-0f9980cc0187",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "final_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a wondrous wizard of math.\"),\n",
        "        few_shot_prompt,\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd8029c5",
      "metadata": {},
      "source": [
        "ç°åœ¨ï¼Œè®©æˆ‘ä»¬å‘æ¨¡å‹æå‡ºåˆå§‹é—®é¢˜ï¼Œçœ‹çœ‹å®ƒçš„è¡¨ç°å¦‚ä½•ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "97d443b1-6fae-4b36-bede-3ff7306288a3",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='11', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 60, 'total_tokens': 61}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5ec4e051-262f-408e-ad00-3f2ebeb561c3-0', usage_metadata={'input_tokens': 60, 'output_tokens': 1, 'total_tokens': 61})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chain = final_prompt | model\n",
        "\n",
        "chain.invoke({\"input\": \"What is 2 ğŸ¦œ 9?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70ab7114-f07f-46be-8874-3705a25aba5f",
      "metadata": {},
      "source": [
        "æˆ‘ä»¬çœ‹åˆ°æ¨¡å‹å·²ç»æ ¹æ®ç»™å®šçš„å°‘æ ·æœ¬ç¤ºä¾‹æ¨æ–­å‡ºé¹¦é¹‰è¡¨æƒ…ç¬¦å·ä»£è¡¨åŠ æ³•ï¼\n\n## åŠ¨æ€å°‘æ ·æœ¬æç¤º\n\næœ‰æ—¶ï¼Œæ‚¨å¯èƒ½å¸Œæœ›æ ¹æ®è¾“å…¥ä»…ä»æ•´ä½“é›†åˆä¸­é€‰æ‹©å°‘é‡ç¤ºä¾‹è¿›è¡Œå±•ç¤ºã€‚ä¸ºæ­¤ï¼Œæ‚¨å¯ä»¥å°†ä¼ é€’ç»™ `FewShotChatMessagePromptTemplate` çš„ `examples` æ›¿æ¢ä¸º `example_selector`ã€‚å…¶ä»–ç»„ä»¶ä¸ä¸Šè¿°ç›¸åŒï¼æˆ‘ä»¬çš„åŠ¨æ€å°‘æ ·æœ¬æç¤ºæ¨¡æ¿å°†å¦‚ä¸‹æ‰€ç¤ºï¼š\n\n- `example_selector`ï¼šè´Ÿè´£ä¸ºç»™å®šè¾“å…¥é€‰æ‹©å°‘æ ·æœ¬ç¤ºä¾‹ï¼ˆä»¥åŠè¿”å›å®ƒä»¬çš„é¡ºåºï¼‰ã€‚è¿™äº›å®ç°äº† [BaseExampleSelector](https://python.langchain.com/api_reference/core/example_selectors/langchain_core.example_selectors.base.BaseExampleSelector.html?highlight=baseexampleselector#langchain_core.example_selectors.base.BaseExampleSelector) æ¥å£ã€‚ä¸€ä¸ªå¸¸è§çš„ä¾‹å­æ˜¯åŸºäºå‘é‡å­˜å‚¨çš„ [SemanticSimilarityExampleSelector](https://python.langchain.com/api_reference/core/example_selectors/langchain_core.example_selectors.semantic_similarity.SemanticSimilarityExampleSelector.html?highlight=semanticsimilarityexampleselector#langchain_core.example_selectors.semantic_similarity.SemanticSimilarityExampleSelector)\n- `example_prompt`ï¼šé€šè¿‡å…¶ [`format_messages`](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html?highlight=chatprompttemplate#langchain_core.prompts.chat.ChatPromptTemplate.format_messages) æ–¹æ³•å°†æ¯ä¸ªç¤ºä¾‹è½¬æ¢ä¸ºä¸€ä¸ªæˆ–å¤šä¸ªæ¶ˆæ¯ã€‚ä¸€ä¸ªå¸¸è§çš„ä¾‹å­æ˜¯å°†æ¯ä¸ªç¤ºä¾‹è½¬æ¢ä¸ºä¸€æ¡äººç±»æ¶ˆæ¯å’Œä¸€æ¡ AI å›å¤æ¶ˆæ¯ï¼Œæˆ–è€…ä¸€æ¡äººç±»æ¶ˆæ¯åè·Ÿä¸€æ¡å‡½æ•°è°ƒç”¨æ¶ˆæ¯ã€‚\n\nè¿™äº›åŒæ ·å¯ä»¥ä¸å…¶ä»–æ¶ˆæ¯å’ŒèŠå¤©æ¨¡æ¿ç»„åˆï¼Œä»¥ç»„è£…æ‚¨çš„æœ€ç»ˆæç¤ºã€‚\n\nè®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªä½¿ç”¨ `SemanticSimilarityExampleSelector` çš„ç¤ºä¾‹è¿›è¡Œæ¢è®¨ã€‚ç”±äºæ­¤å®ç°ä½¿ç”¨å‘é‡å­˜å‚¨æ ¹æ®è¯­ä¹‰ç›¸ä¼¼æ€§é€‰æ‹©ç¤ºä¾‹ï¼Œå› æ­¤æˆ‘ä»¬é¦–å…ˆéœ€è¦å¡«å……è¯¥å­˜å‚¨ã€‚è¿™é‡Œçš„åŸºæœ¬æ€æƒ³æ˜¯ï¼Œæˆ‘ä»¬å¸Œæœ›æœç´¢å¹¶è¿”å›ä¸æ–‡æœ¬è¾“å…¥æœ€ç›¸ä¼¼çš„ç¤ºä¾‹ï¼Œå› æ­¤æˆ‘ä»¬åµŒå…¥æç¤ºç¤ºä¾‹çš„ `values` è€Œä¸æ˜¯è€ƒè™‘é”®ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ad66f06a-66fd-4fcc-8166-5d0e3c801e57",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma\n",
        "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "examples = [\n",
        "    {\"input\": \"2 ğŸ¦œ 2\", \"output\": \"4\"},\n",
        "    {\"input\": \"2 ğŸ¦œ 3\", \"output\": \"5\"},\n",
        "    {\"input\": \"2 ğŸ¦œ 4\", \"output\": \"6\"},\n",
        "    {\"input\": \"What did the cow say to the moon?\", \"output\": \"nothing at all\"},\n",
        "    {\n",
        "        \"input\": \"Write me a poem about the moon\",\n",
        "        \"output\": \"One for the moon, and one for me, who are we to talk about the moon?\",\n",
        "    },\n",
        "]\n",
        "\n",
        "to_vectorize = [\" \".join(example.values()) for example in examples]\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vectorstore = Chroma.from_texts(to_vectorize, embeddings, metadatas=examples)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f7e384a-2031-432b-951c-7ea8cf9262f1",
      "metadata": {},
      "source": [
        "### åˆ›å»º `example_selector`\n\nåˆ›å»ºäº† vectorstore åï¼Œæˆ‘ä»¬å°±å¯ä»¥åˆ›å»º `example_selector`ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†å•ç‹¬è°ƒç”¨å®ƒï¼Œå¹¶è®¾ç½®å…¶ `k` å€¼ä»¥ä»…æ£€ç´¢æœ€æ¥è¿‘è¾“å…¥çš„ä¸¤ä¸ªç¤ºä¾‹ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7790303a-f722-452e-8921-b14bdf20bdff",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'input': 'What did the cow say to the moon?', 'output': 'nothing at all'},\n",
              " {'input': '2 ğŸ¦œ 4', 'output': '6'}]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_selector = SemanticSimilarityExampleSelector(\n",
        "    vectorstore=vectorstore,\n",
        "    k=2,\n",
        ")\n",
        "\n",
        "# The prompt template will load examples by passing the input do the `select_examples` method\n",
        "example_selector.select_examples({\"input\": \"horse\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc77c40f-3f58-40a2-b757-a2a2ea43f24a",
      "metadata": {},
      "source": [
        "### åˆ›å»º Prompt æ¨¡æ¿\n\nç°åœ¨ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸Šé¢åˆ›å»ºçš„ `example_selector` æ¥ç»„è£… Prompt æ¨¡æ¿ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "253c255e-41d7-45f6-9d88-c7a0ced4b1bd",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[HumanMessage(content='2 ğŸ¦œ 3'), AIMessage(content='5'), HumanMessage(content='2 ğŸ¦œ 4'), AIMessage(content='6')]\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
        "\n",
        "# Define the few-shot prompt.\n",
        "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
        "    # The input variables select the values to pass to the example_selector\n",
        "    input_variables=[\"input\"],\n",
        "    example_selector=example_selector,\n",
        "    # Define how each example will be formatted.\n",
        "    # In this case, each example will become 2 messages:\n",
        "    # 1 human, and 1 AI\n",
        "    example_prompt=ChatPromptTemplate.from_messages(\n",
        "        [(\"human\", \"{input}\"), (\"ai\", \"{output}\")]\n",
        "    ),\n",
        ")\n",
        "\n",
        "print(few_shot_prompt.invoke(input=\"What's 3 ğŸ¦œ 3?\").to_messages())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "339cae7d-0eb0-44a6-852f-0267c5ff72b3",
      "metadata": {},
      "source": [
        "ç„¶åæˆ‘ä»¬å¯ä»¥å°†è¿™ä¸ªfew-shotèŠå¤©æ¶ˆæ¯æç¤ºæ¨¡æ¿ä¼ é€’åˆ°å¦ä¸€ä¸ªèŠå¤©æç¤ºæ¨¡æ¿ä¸­ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e731cb45-f0ea-422c-be37-42af2a6cb2c4",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "messages=[HumanMessage(content='2 ğŸ¦œ 3'), AIMessage(content='5'), HumanMessage(content='2 ğŸ¦œ 4'), AIMessage(content='6')]\n"
          ]
        }
      ],
      "source": [
        "final_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a wondrous wizard of math.\"),\n",
        "        few_shot_prompt,\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(few_shot_prompt.invoke(input=\"What's 3 ğŸ¦œ 3?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2408ea69-1880-4ef5-a0fa-ffa8d2026aa9",
      "metadata": {},
      "source": [
        "### ä¸èŠå¤©æ¨¡å‹é…åˆä½¿ç”¨\n\næœ€åï¼Œæ‚¨å¯ä»¥å°†æ¨¡å‹è¿æ¥åˆ°å°‘æ ·æœ¬æç¤ºã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "0568cbc6-5354-47f1-ab4d-dfcc616cf583",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='6', response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 60, 'total_tokens': 61}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-d1863e5e-17cd-4e9d-bf7a-b9f118747a65-0', usage_metadata={'input_tokens': 60, 'output_tokens': 1, 'total_tokens': 61})"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain = final_prompt | ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
        "\n",
        "chain.invoke({\"input\": \"What's 3 ğŸ¦œ 3?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c87fad3c",
      "metadata": {},
      "source": [
        "## åç»­æ­¥éª¤\n\næ‚¨ç°åœ¨å·²ç»å­¦ä¼šäº†å¦‚ä½•åœ¨èŠå¤©æç¤ºä¸­æ·»åŠ å°‘æ ·æœ¬ç¤ºä¾‹ã€‚\n\næ¥ä¸‹æ¥ï¼Œè¯·æŸ¥çœ‹æœ¬èŠ‚ä¸­å…³äºæç¤ºæ¨¡æ¿çš„å…¶ä»–æ“ä½œæŒ‡å—ï¼Œç›¸å…³çš„å…³äºä½¿ç”¨æ–‡æœ¬è¡¥å…¨æ¨¡å‹è¿›è¡Œå°‘æ ·æœ¬æ“ä½œçš„æ“ä½œæŒ‡å— [few shotting with text completion models](/docs/how_to/few_shot_examples)ï¼Œæˆ–è€…å…¶ä»–çš„ [ç¤ºä¾‹é€‰æ‹©å™¨æ“ä½œæŒ‡å—](/docs/how_to/example_selectors/)ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46e26b53",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}