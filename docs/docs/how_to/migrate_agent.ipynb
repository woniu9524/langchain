{
  "cells": [
    {
      "cell_type": "raw",
      "id": "adc7ee09",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "keywords: [create_react_agent, create_react_agent()]\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "457cdc67-1893-4653-8b0c-b185a5947e74",
      "metadata": {},
      "source": [
        "# 如何从旧版 LangChain 代理迁移到 LangGraph\n\n:::info 先决条件\n\n本指南假定您熟悉以下概念：\n- [代理](/docs/concepts/agents)\n- [LangGraph](https://langchain-ai.github.io/langgraph/)\n- [工具调用](/docs/how_to/tool_calling/)\n\n:::\n\n在这里，我们将重点介绍如何从旧版 LangChain 代理迁移到更灵活的 [LangGraph](https://langchain-ai.github.io/langgraph/) 代理。\nLangChain 代理（特别是 [AgentExecutor](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor)）具有多个配置参数。\n在本笔记本中，我们将展示这些参数如何通过 [create_react_agent](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.chat_agent_executor.create_react_agent) 预构建的助手方法映射到 LangGraph 的 react 代理执行器。\n\n\n:::note\n在 LangGraph 中，图取代了 LangChain 的代理执行器。它管理代理的循环，并将其作为状态内的消息来跟踪其 the scratchpad。LangChain 的“代理”对应于您提供的提示和 LLM。\n:::\n\n\n#### 先决条件\n\n本操作指南使用 OpenAI 作为 LLM。安装依赖项以运行。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "662fac50",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U langgraph langchain langchain-openai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f8ec38f",
      "metadata": {},
      "source": [
        "然后，设置你的 OpenAI API 密钥。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5fca87ef",
      "metadata": {},
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API key:\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e50635c-1671-46e6-be65-ce95f8167c2f",
      "metadata": {},
      "source": [
        "## 基本用法\n\n对于创建和使用一个工具调用式的 ReAct 风格代理，其功能是相同的。首先，我们定义模型和工具，然后用它们来创建一个代理。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1e425fea-2796-4b99-bee6-9a6ffe73f756",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o\")\n",
        "\n",
        "\n",
        "@tool\n",
        "def magic_function(input: int) -> int:\n",
        "    \"\"\"Applies a magic function to an input.\"\"\"\n",
        "    return input + 2\n",
        "\n",
        "\n",
        "tools = [magic_function]\n",
        "\n",
        "\n",
        "query = \"what is the value of magic_function(3)?\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af002033-fe51-4d14-b47c-3e9b483c8395",
      "metadata": {},
      "source": [
        "对于 LangChain 的 [AgentExecutor](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor)，我们定义了一个带有代理记忆区占位符的提示。代理可以按如下方式调用："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "03ea357c-9c36-4464-b2cc-27bd150e1554",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input': 'what is the value of magic_function(3)?',\n",
              " 'output': 'The value of `magic_function(3)` is 5.'}"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "        # Placeholders fill up a **list** of messages\n",
        "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "agent = create_tool_calling_agent(model, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools)\n",
        "\n",
        "agent_executor.invoke({\"input\": query})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94205f3b-fd2b-4fd7-af69-0a3fc313dc88",
      "metadata": {},
      "source": [
        "LangGraph 的 [react agent executor](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.chat_agent_executor.create_react_agent) 管理一个由消息列表定义的 state。它将继续处理该列表，直到 agent 的输出中不再有工具调用。为了启动它，我们输入一个消息列表。输出将包含图的整个 state——在这个例子中，就是对话历史。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "53a3737a-d167-4255-89bf-20ac37f89a3e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input': 'what is the value of magic_function(3)?',\n",
              " 'output': 'The value of `magic_function(3)` is 5.'}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "langgraph_agent_executor = create_react_agent(model, tools)\n",
        "\n",
        "\n",
        "messages = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query)]})\n",
        "{\n",
        "    \"input\": query,\n",
        "    \"output\": messages[\"messages\"][-1].content,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "74ecebe3-512e-409c-a661-bdd5b0a2b782",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input': 'Pardon?',\n",
              " 'output': 'The result of applying `magic_function` to the input value 3 is 5.'}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "message_history = messages[\"messages\"]\n",
        "\n",
        "new_query = \"Pardon?\"\n",
        "\n",
        "messages = langgraph_agent_executor.invoke(\n",
        "    {\"messages\": message_history + [(\"human\", new_query)]}\n",
        ")\n",
        "{\n",
        "    \"input\": new_query,\n",
        "    \"output\": messages[\"messages\"][-1].content,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4466a4d-e55e-4ece-bee8-2269a0b5677b",
      "metadata": {},
      "source": [
        "## Prompt 模板\n\n在使用旧版 LangChain 代理时，你需要传入一个 prompt 模板。你可以通过它来控制代理的行为。\n\n使用 LangGraph 的 [react agent executor](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.chat_agent_executor.create_react_agent) 时，默认情况下没有 prompt。你可以通过以下几种方式实现对代理的类似控制：\n\n1.  将一个系统消息作为输入传入。\n2.  使用一个系统消息来初始化代理。\n3.  使用一个函数来初始化代理，该函数在消息传递给模型之前，会转换图状态中的消息。\n4.  使用一个 [Runnable](/docs/concepts/lcel) 来初始化代理，该 Runnable 在消息传递给模型之前，会转换图状态中的消息。这也包括传入 prompt 模板。\n\n下面让我们来看看所有这些方法。我们将传入自定义指令，让代理用西班牙语回复。\n\n首先，使用 `AgentExecutor`："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a9a11ccd-75e2-4c11-844d-a34870b0ff91",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input': 'what is the value of magic_function(3)?',\n",
              " 'output': 'El valor de magic_function(3) es 5.'}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant. Respond only in Spanish.\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "        # Placeholders fill up a **list** of messages\n",
        "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "agent = create_tool_calling_agent(model, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools)\n",
        "\n",
        "agent_executor.invoke({\"input\": query})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd5f5500-5ae4-4000-a9fd-8c5a2cc6404d",
      "metadata": {},
      "source": [
        "现在，让我们来为一个 [react agent executor](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.chat_agent_executor.create_react_agent) 传递一个自定义的 system message。\n\nLangGraph 的预构建 `create_react_agent` 不直接将 prompt template 作为参数，而是接受一个 [`prompt`](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.chat_agent_executor.create_react_agent) 参数。这会在调用 llm 之前修改 graph state，并且它可以是以下四种值之一：\n\n- 一个 `SystemMessage`，它会被添加到消息列表的开头。\n- 一个 `string`，它会被转换为 `SystemMessage` 并添加到消息列表的开头。\n- 一个 `Callable`，它应该接收完整的 graph state。然后输出会传递给 language model。\n- 或者一个 [`Runnable`](/docs/concepts/lcel)，它应该接收完整的 graph state。然后输出会传递给 language model。\n\n以下是实际操作中的样子："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a9486805-676a-4d19-a5c4-08b41b172989",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.messages import SystemMessage\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "system_message = \"You are a helpful assistant. Respond only in Spanish.\"\n",
        "# This could also be a SystemMessage object\n",
        "# system_message = SystemMessage(content=\"You are a helpful assistant. Respond only in Spanish.\")\n",
        "\n",
        "langgraph_agent_executor = create_react_agent(model, tools, prompt=system_message)\n",
        "\n",
        "\n",
        "messages = langgraph_agent_executor.invoke({\"messages\": [(\"user\", query)]})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc6059fd-0df7-4b6f-a84c-b5874e983638",
      "metadata": {},
      "source": [
        "我们还可以传入任意函数或可运行对象。该函数/可运行对象应接收图状态并输出消息列表。\n我们可以在此处进行任意类型的消息格式化。在这种情况下，让我们在消息列表的开头添加一个 SystemMessage，并在末尾追加另一个 user 消息。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d369ab45-0c82-45f4-9d3e-8efb8dd47e2c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input': 'what is the value of magic_function(3)?', 'output': 'El valor de magic_function(3) es 5. ¡Pandamonium!'}\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.prebuilt.chat_agent_executor import AgentState\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant. Respond only in Spanish.\"),\n",
        "        (\"placeholder\", \"{messages}\"),\n",
        "        (\"user\", \"Also say 'Pandamonium!' after the answer.\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# alternatively, this can be passed as a function, e.g.\n",
        "# def prompt(state: AgentState):\n",
        "#     return (\n",
        "#         [SystemMessage(content=\"You are a helpful assistant. Respond only in Spanish.\")] +\n",
        "#         state[\"messages\"] +\n",
        "#         [HumanMessage(content=\"Also say 'Pandamonium!' after the answer.\")]\n",
        "#     )\n",
        "\n",
        "\n",
        "langgraph_agent_executor = create_react_agent(model, tools, prompt=prompt)\n",
        "\n",
        "\n",
        "messages = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query)]})\n",
        "print(\n",
        "    {\n",
        "        \"input\": query,\n",
        "        \"output\": messages[\"messages\"][-1].content,\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68df3a09",
      "metadata": {},
      "source": [
        "## Memory"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96e7ffc8",
      "metadata": {},
      "source": [
        "### 在 LangChain 中\n\n使用 LangChain 的 [AgentExecutor](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.iter)，您可以添加聊天 [Memory](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.memory)，从而进行多轮对话。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b97beba5-8f74-430c-9399-91b77c8fa15c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The output of the magic function when the input is 3 is 5.\n",
            "---\n",
            "Yes, you mentioned your name is Polly.\n",
            "---\n",
            "The output of the magic function when the input is 3 is 5.\n"
          ]
        }
      ],
      "source": [
        "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
        "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_core.tools import tool\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o\")\n",
        "memory = InMemoryChatMessageHistory(session_id=\"test-session\")\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant.\"),\n",
        "        # First put the history\n",
        "        (\"placeholder\", \"{chat_history}\"),\n",
        "        # Then the new input\n",
        "        (\"human\", \"{input}\"),\n",
        "        # Finally the scratchpad\n",
        "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "@tool\n",
        "def magic_function(input: int) -> int:\n",
        "    \"\"\"Applies a magic function to an input.\"\"\"\n",
        "    return input + 2\n",
        "\n",
        "\n",
        "tools = [magic_function]\n",
        "\n",
        "\n",
        "agent = create_tool_calling_agent(model, tools, prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools)\n",
        "\n",
        "agent_with_chat_history = RunnableWithMessageHistory(\n",
        "    agent_executor,\n",
        "    # This is needed because in most real world scenarios, a session id is needed\n",
        "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
        "    lambda session_id: memory,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"chat_history\",\n",
        ")\n",
        "\n",
        "config = {\"configurable\": {\"session_id\": \"test-session\"}}\n",
        "print(\n",
        "    agent_with_chat_history.invoke(\n",
        "        {\"input\": \"Hi, I'm polly! What's the output of magic_function of 3?\"}, config\n",
        "    )[\"output\"]\n",
        ")\n",
        "print(\"---\")\n",
        "print(agent_with_chat_history.invoke({\"input\": \"Remember my name?\"}, config)[\"output\"])\n",
        "print(\"---\")\n",
        "print(\n",
        "    agent_with_chat_history.invoke({\"input\": \"what was that output again?\"}, config)[\n",
        "        \"output\"\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2a5a32f",
      "metadata": {},
      "source": [
        "### 在 LangGraph 中\n\n内存只是[持久化](https://langchain-ai.github.io/langgraph/how-tos/persistence/)，也称为[检查点](https://langchain-ai.github.io/langgraph/reference/checkpoints/)。\n\n向代理添加 `checkpointer`，即可免费获得聊天记忆。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "baca3dc6-678b-4509-9275-2fd653102898",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The output of the magic function for the input 3 is 5.\n",
            "---\n",
            "Yes, you mentioned that your name is Polly.\n",
            "---\n",
            "The output of the magic function for the input 3 was 5.\n"
          ]
        }
      ],
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver  # an in-memory checkpointer\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "system_message = \"You are a helpful assistant.\"\n",
        "# This could also be a SystemMessage object\n",
        "# system_message = SystemMessage(content=\"You are a helpful assistant. Respond only in Spanish.\")\n",
        "\n",
        "memory = MemorySaver()\n",
        "langgraph_agent_executor = create_react_agent(\n",
        "    model, tools, prompt=system_message, checkpointer=memory\n",
        ")\n",
        "\n",
        "config = {\"configurable\": {\"thread_id\": \"test-thread\"}}\n",
        "print(\n",
        "    langgraph_agent_executor.invoke(\n",
        "        {\n",
        "            \"messages\": [\n",
        "                (\"user\", \"Hi, I'm polly! What's the output of magic_function of 3?\")\n",
        "            ]\n",
        "        },\n",
        "        config,\n",
        "    )[\"messages\"][-1].content\n",
        ")\n",
        "print(\"---\")\n",
        "print(\n",
        "    langgraph_agent_executor.invoke(\n",
        "        {\"messages\": [(\"user\", \"Remember my name?\")]}, config\n",
        "    )[\"messages\"][-1].content\n",
        ")\n",
        "print(\"---\")\n",
        "print(\n",
        "    langgraph_agent_executor.invoke(\n",
        "        {\"messages\": [(\"user\", \"what was that output again?\")]}, config\n",
        "    )[\"messages\"][-1].content\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7cf24a8",
      "metadata": {},
      "source": [
        "## 迭代步骤\n\n### 在 LangChain 中\n\n使用 LangChain 的 [AgentExecutor](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.iter)，你可以通过 [stream](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.stream)（或异步 `astream`）方法或 [iter](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.iter) 方法迭代步骤。LangGraph 支持使用 [stream](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.stream) 进行分步迭代。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e62843c4-1107-41f0-a50b-aea256e28053",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'actions': [ToolAgentAction(tool='magic_function', tool_input={'input': 3}, log=\"\\nInvoking: `magic_function` with `{'input': 3}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_yyetzabaDBRX9Ml2KyqfKzZM', 'function': {'arguments': '{\"input\":3}', 'name': 'magic_function'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a7d06e42a7'}, id='run-7a3a5ada-52ec-4df0-bf7d-81e5051b01b4', tool_calls=[{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_yyetzabaDBRX9Ml2KyqfKzZM', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'magic_function', 'args': '{\"input\":3}', 'id': 'call_yyetzabaDBRX9Ml2KyqfKzZM', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='call_yyetzabaDBRX9Ml2KyqfKzZM')], 'messages': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_yyetzabaDBRX9Ml2KyqfKzZM', 'function': {'arguments': '{\"input\":3}', 'name': 'magic_function'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a7d06e42a7'}, id='run-7a3a5ada-52ec-4df0-bf7d-81e5051b01b4', tool_calls=[{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_yyetzabaDBRX9Ml2KyqfKzZM', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'magic_function', 'args': '{\"input\":3}', 'id': 'call_yyetzabaDBRX9Ml2KyqfKzZM', 'index': 0, 'type': 'tool_call_chunk'}])]}\n",
            "{'steps': [AgentStep(action=ToolAgentAction(tool='magic_function', tool_input={'input': 3}, log=\"\\nInvoking: `magic_function` with `{'input': 3}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_yyetzabaDBRX9Ml2KyqfKzZM', 'function': {'arguments': '{\"input\":3}', 'name': 'magic_function'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a7d06e42a7'}, id='run-7a3a5ada-52ec-4df0-bf7d-81e5051b01b4', tool_calls=[{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_yyetzabaDBRX9Ml2KyqfKzZM', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'magic_function', 'args': '{\"input\":3}', 'id': 'call_yyetzabaDBRX9Ml2KyqfKzZM', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='call_yyetzabaDBRX9Ml2KyqfKzZM'), observation=5)], 'messages': [FunctionMessage(content='5', additional_kwargs={}, response_metadata={}, name='magic_function')]}\n",
            "{'output': 'The value of `magic_function(3)` is 5.', 'messages': [AIMessage(content='The value of `magic_function(3)` is 5.', additional_kwargs={}, response_metadata={})]}\n"
          ]
        }
      ],
      "source": [
        "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.tools import tool\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o\")\n",
        "\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant.\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "        # Placeholders fill up a **list** of messages\n",
        "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "@tool\n",
        "def magic_function(input: int) -> int:\n",
        "    \"\"\"Applies a magic function to an input.\"\"\"\n",
        "    return input + 2\n",
        "\n",
        "\n",
        "tools = [magic_function]\n",
        "\n",
        "agent = create_tool_calling_agent(model, tools, prompt=prompt)\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools)\n",
        "\n",
        "for step in agent_executor.stream({\"input\": query}):\n",
        "    print(step)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46ccbcbf",
      "metadata": {},
      "source": [
        "### 在 LangGraph 中\n\n在 LangGraph 中，使用 [stream](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.graph.CompiledGraph.stream) 或异步的 `astream` 方法来原生处理事物。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "076ebc85-f804-4093-a25a-a16334c9898e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_IHTMrjvIHn8gFOX42FstIpr9', 'function': {'arguments': '{\"input\":3}', 'name': 'magic_function'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 61, 'total_tokens': 75, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a7d06e42a7', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-1a6970da-163a-4e4d-b9b7-7e73b1057f42-0', tool_calls=[{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_IHTMrjvIHn8gFOX42FstIpr9', 'type': 'tool_call'}], usage_metadata={'input_tokens': 61, 'output_tokens': 14, 'total_tokens': 75, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})]}}\n",
            "{'tools': {'messages': [ToolMessage(content='5', name='magic_function', id='51a9d3e4-734d-426f-a5a1-c6597e4efe25', tool_call_id='call_IHTMrjvIHn8gFOX42FstIpr9')]}}\n",
            "{'agent': {'messages': [AIMessage(content='The value of `magic_function(3)` is 5.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 84, 'total_tokens': 98, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a20a4ee344', 'finish_reason': 'stop', 'logprobs': None}, id='run-73001576-a3dc-4552-8d81-c9ce8aec05b3-0', usage_metadata={'input_tokens': 84, 'output_tokens': 14, 'total_tokens': 98, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})]}}\n"
          ]
        }
      ],
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.prebuilt.chat_agent_executor import AgentState\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant.\"),\n",
        "        (\"placeholder\", \"{messages}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "langgraph_agent_executor = create_react_agent(model, tools, prompt=prompt)\n",
        "\n",
        "for step in langgraph_agent_executor.stream(\n",
        "    {\"messages\": [(\"human\", query)]}, stream_mode=\"updates\"\n",
        "):\n",
        "    print(step)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6898ccbc-42b1-4373-954a-2c7b3849fbb0",
      "metadata": {},
      "source": [
        "## `return_intermediate_steps`\n\n### 在 LangChain 中\n\n在 AgentExecutor 上设置此参数允许用户访问 `intermediate_steps`，它将代理操作（例如工具调用）与其结果配对。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a2f720f3-c121-4be2-b498-92c16bb44b0a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(ToolAgentAction(tool='magic_function', tool_input={'input': 3}, log=\"\\nInvoking: `magic_function` with `{'input': 3}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_njTvl2RsVf4q1aMUxoYnJuK1', 'function': {'arguments': '{\"input\":3}', 'name': 'magic_function'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a7d06e42a7'}, id='run-c9dfe3ab-2db6-4592-851e-89e056aeab32', tool_calls=[{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_njTvl2RsVf4q1aMUxoYnJuK1', 'type': 'tool_call'}], tool_call_chunks=[{'name': 'magic_function', 'args': '{\"input\":3}', 'id': 'call_njTvl2RsVf4q1aMUxoYnJuK1', 'index': 0, 'type': 'tool_call_chunk'}])], tool_call_id='call_njTvl2RsVf4q1aMUxoYnJuK1'), 5)]\n"
          ]
        }
      ],
      "source": [
        "agent_executor = AgentExecutor(agent=agent, tools=tools, return_intermediate_steps=True)\n",
        "result = agent_executor.invoke({\"input\": query})\n",
        "print(result[\"intermediate_steps\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "594f7567-302f-4fa8-85bb-025ac8322162",
      "metadata": {},
      "source": [
        "### 在 LangGraph 中\n\n默认情况下，LangGraph 中的 [react agent executor](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.chat_agent_executor.create_react_agent) 会将所有消息追加到中心状态。因此，只需查看整个状态即可轻松了解任何中间步骤。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ef23117a-5ccb-42ce-80c3-ea49a9d3a942",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='what is the value of magic_function(3)?', additional_kwargs={}, response_metadata={}, id='1abb52c2-4bc2-4d82-bd32-5a24c3976b0f'),\n",
              "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_XfQD6C7rAalcmicQubkhJVFq', 'function': {'arguments': '{\"input\":3}', 'name': 'magic_function'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 55, 'total_tokens': 69, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a20a4ee344', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-34f02786-5b5c-4bb1-bd9e-406c81944a24-0', tool_calls=[{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_XfQD6C7rAalcmicQubkhJVFq', 'type': 'tool_call'}], usage_metadata={'input_tokens': 55, 'output_tokens': 14, 'total_tokens': 69, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}),\n",
              "  ToolMessage(content='5', name='magic_function', id='cbc9fadf-1962-4ed7-b476-348c774652be', tool_call_id='call_XfQD6C7rAalcmicQubkhJVFq'),\n",
              "  AIMessage(content='The value of `magic_function(3)` is 5.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 78, 'total_tokens': 92, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a7d06e42a7', 'finish_reason': 'stop', 'logprobs': None}, id='run-547e03d2-872d-4008-a38d-b7f739a77df5-0', usage_metadata={'input_tokens': 78, 'output_tokens': 14, 'total_tokens': 92, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})]}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "langgraph_agent_executor = create_react_agent(model, tools=tools)\n",
        "\n",
        "messages = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query)]})\n",
        "\n",
        "messages"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45b528e5-57e1-450e-8d91-513eab53b543",
      "metadata": {},
      "source": [
        "## `max_iterations`\n\n### 在 LangChain 中\n\n`AgentExecutor` 实现了一个 `max_iterations` 参数，允许用户中止超过指定迭代次数的运行。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "16f189a7-fc78-4cb5-aa16-a94ca06401a6",
      "metadata": {},
      "outputs": [],
      "source": [
        "@tool\n",
        "def magic_function(input: str) -> str:\n",
        "    \"\"\"Applies a magic function to an input.\"\"\"\n",
        "    return \"Sorry, there was an error. Please try again.\"\n",
        "\n",
        "\n",
        "tools = [magic_function]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "c96aefd7-6f6e-4670-aca6-1ac3d4e7871f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mLo siento, no puedo decirte directamente el valor de `magic_function(3)`. Si deseas, puedo usar la función mágica para calcularlo. ¿Te gustaría que lo hiciera?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'what is the value of magic_function(3)?',\n",
              " 'output': 'Lo siento, no puedo decirte directamente el valor de `magic_function(3)`. Si deseas, puedo usar la función mágica para calcularlo. ¿Te gustaría que lo hiciera?'}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant. Respond only in Spanish.\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "        # Placeholders fill up a **list** of messages\n",
        "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "agent = create_tool_calling_agent(model, tools, prompt)\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=agent,\n",
        "    tools=tools,\n",
        "    verbose=True,\n",
        "    max_iterations=3,\n",
        ")\n",
        "\n",
        "agent_executor.invoke({\"input\": query})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd3a933f",
      "metadata": {},
      "source": [
        "### 在 LangGraph 中\n\n在 LangGraph 中，这由 `recursion_limit` 配置参数控制。\n\n请注意，在 `AgentExecutor` 中，“迭代”包括完整的工具调用和执行轮次。在 LangGraph 中，每一步都会计入递归限制，因此我们需要乘以二（再加上一）才能得到等效结果。\n\n如果达到递归限制，LangGraph 会引发一个特定的异常类型，我们可以像 AgentExecutor 一样捕获和管理它。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "b974a91f-6ae8-4644-83d9-73666258a6db",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content='what is the value of magic_function(3)?' additional_kwargs={} response_metadata={} id='c2489fe8-e69c-4163-876d-3cce26b28521'\n",
            "content='' additional_kwargs={'tool_calls': [{'id': 'call_OyNTcO6SDAvZcBlIEknPRrTR', 'function': {'arguments': '{\"input\":\"3\"}', 'name': 'magic_function'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 55, 'total_tokens': 69, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a7d06e42a7', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-b65504bb-fa23-4f8a-8d6c-7edb6d16e7ff-0' tool_calls=[{'name': 'magic_function', 'args': {'input': '3'}, 'id': 'call_OyNTcO6SDAvZcBlIEknPRrTR', 'type': 'tool_call'}] usage_metadata={'input_tokens': 55, 'output_tokens': 14, 'total_tokens': 69, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n",
            "content='Sorry, there was an error. Please try again.' name='magic_function' id='f00e0bff-54fe-4726-a1a7-127a59d8f7ed' tool_call_id='call_OyNTcO6SDAvZcBlIEknPRrTR'\n",
            "content=\"It seems there was an error when trying to compute the value of the magic function with input 3. Let's try again.\" additional_kwargs={'tool_calls': [{'id': 'call_Q020rQoJh4cnh8WglIMnDm4z', 'function': {'arguments': '{\"input\":\"3\"}', 'name': 'magic_function'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 88, 'total_tokens': 128, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a7d06e42a7', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-556d8cb2-b47a-4826-b17d-b520982c2475-0' tool_calls=[{'name': 'magic_function', 'args': {'input': '3'}, 'id': 'call_Q020rQoJh4cnh8WglIMnDm4z', 'type': 'tool_call'}] usage_metadata={'input_tokens': 88, 'output_tokens': 40, 'total_tokens': 128, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n",
            "content='Sorry, there was an error. Please try again.' name='magic_function' id='777212cd-8381-44db-9762-3f81951ea73e' tool_call_id='call_Q020rQoJh4cnh8WglIMnDm4z'\n",
            "content=\"It seems there is a persistent issue in computing the value of the magic function with the input 3. Unfortunately, I can't provide the value at this time. If you have any other questions or need further assistance, feel free to ask!\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 150, 'total_tokens': 199, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a7d06e42a7', 'finish_reason': 'stop', 'logprobs': None} id='run-92ec0b90-bc8e-4851-9139-f1d976145ab7-0' usage_metadata={'input_tokens': 150, 'output_tokens': 49, 'total_tokens': 199, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n"
          ]
        }
      ],
      "source": [
        "from langgraph.errors import GraphRecursionError\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "RECURSION_LIMIT = 2 * 3 + 1\n",
        "\n",
        "langgraph_agent_executor = create_react_agent(model, tools=tools)\n",
        "\n",
        "try:\n",
        "    for chunk in langgraph_agent_executor.stream(\n",
        "        {\"messages\": [(\"human\", query)]},\n",
        "        {\"recursion_limit\": RECURSION_LIMIT},\n",
        "        stream_mode=\"values\",\n",
        "    ):\n",
        "        print(chunk[\"messages\"][-1])\n",
        "except GraphRecursionError:\n",
        "    print({\"input\": query, \"output\": \"Agent stopped due to max iterations.\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a527158-ada5-4774-a98b-8272c6b6b2c0",
      "metadata": {},
      "source": [
        "## `max_execution_time`\n\n### 在 LangChain 中\n\n`AgentExecutor` 实现了一个 `max_execution_time` 参数，允许用户中止超过总时间限制的运行。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "4b8498fc-a7af-4164-a401-d8714f082306",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mLo siento, no tengo la capacidad de evaluar directamente una función llamada \"magic_function\" con el valor 3. Sin embargo, si me proporcionas más detalles sobre qué hace la función o cómo está definida, podría intentar ayudarte a comprender su comportamiento o resolverlo de otra manera.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'what is the value of magic_function(3)?',\n",
              " 'output': 'Lo siento, no tengo la capacidad de evaluar directamente una función llamada \"magic_function\" con el valor 3. Sin embargo, si me proporcionas más detalles sobre qué hace la función o cómo está definida, podría intentar ayudarte a comprender su comportamiento o resolverlo de otra manera.'}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "\n",
        "@tool\n",
        "def magic_function(input: str) -> str:\n",
        "    \"\"\"Applies a magic function to an input.\"\"\"\n",
        "    time.sleep(2.5)\n",
        "    return \"Sorry, there was an error. Please try again.\"\n",
        "\n",
        "\n",
        "tools = [magic_function]\n",
        "\n",
        "agent = create_tool_calling_agent(model, tools, prompt)\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=agent,\n",
        "    tools=tools,\n",
        "    max_execution_time=2,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "agent_executor.invoke({\"input\": query})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d02eb025",
      "metadata": {},
      "source": [
        "### 在 LangGraph 中\n\n使用 LangGraph 的 react agent，您可以在两个级别上控制超时。\n\n您可以设置一个 `step_timeout` 来限制每个 **step**："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "b1d8883d-f5c4-444b-b15e-09827f1b9c57",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_UuxSgpGaqzX84sNlKzCVOiRO', 'function': {'arguments': '{\"input\":\"3\"}', 'name': 'magic_function'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 55, 'total_tokens': 69, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a7d06e42a7', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-24c94cbd-2962-48cf-a447-af888eb6ef86-0', tool_calls=[{'name': 'magic_function', 'args': {'input': '3'}, 'id': 'call_UuxSgpGaqzX84sNlKzCVOiRO', 'type': 'tool_call'}], usage_metadata={'input_tokens': 55, 'output_tokens': 14, 'total_tokens': 69, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})]}}\n",
            "------\n",
            "{'input': 'what is the value of magic_function(3)?', 'output': 'Agent stopped due to a step timeout.'}\n"
          ]
        }
      ],
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "langgraph_agent_executor = create_react_agent(model, tools=tools)\n",
        "# Set the max timeout for each step here\n",
        "langgraph_agent_executor.step_timeout = 2\n",
        "\n",
        "try:\n",
        "    for chunk in langgraph_agent_executor.stream({\"messages\": [(\"human\", query)]}):\n",
        "        print(chunk)\n",
        "        print(\"------\")\n",
        "except TimeoutError:\n",
        "    print({\"input\": query, \"output\": \"Agent stopped due to a step timeout.\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32a9db70",
      "metadata": {},
      "source": [
        "另一种为整个运行设置单个最大超时的方法是直接使用 Python 标准库 [asyncio](https://docs.python.org/3/library/asyncio.html)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "f8d5bd03-6e7e-484b-a543-c8c0ab160b69",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_km17xvoY7wJ5yNnXhb5V9D3I', 'function': {'arguments': '{\"input\":\"3\"}', 'name': 'magic_function'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 55, 'total_tokens': 69, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_45c6de4934', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-b44a04e5-9b68-4020-be36-98de1593eefc-0', tool_calls=[{'name': 'magic_function', 'args': {'input': '3'}, 'id': 'call_km17xvoY7wJ5yNnXhb5V9D3I', 'type': 'tool_call'}], usage_metadata={'input_tokens': 55, 'output_tokens': 14, 'total_tokens': 69, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})]}}\n",
            "------\n",
            "Task Cancelled.\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "langgraph_agent_executor = create_react_agent(model, tools=tools)\n",
        "\n",
        "\n",
        "async def stream(langgraph_agent_executor, inputs):\n",
        "    async for chunk in langgraph_agent_executor.astream(\n",
        "        {\"messages\": [(\"human\", query)]}\n",
        "    ):\n",
        "        print(chunk)\n",
        "        print(\"------\")\n",
        "\n",
        "\n",
        "try:\n",
        "    task = asyncio.create_task(\n",
        "        stream(langgraph_agent_executor, {\"messages\": [(\"human\", query)]})\n",
        "    )\n",
        "    await asyncio.wait_for(task, timeout=3)\n",
        "except asyncio.TimeoutError:\n",
        "    print(\"Task Cancelled.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4884ac87",
      "metadata": {},
      "source": [
        "## `early_stopping_method`\n\n### 在 LangChain 中\n\n使用 LangChain 的 [AgentExecutor](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.iter)，您可以配置一个 [early_stopping_method](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.early_stopping_method) 来返回一个字符串 \"Agent stopped due to iteration limit or time limit.\"（`\"force\"`），或者提示 LLM 最后一次响应（`\"generate\"`）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "3f6e2cf2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output with early_stopping_method='force':\n",
            "Agent stopped due to max iterations.\n"
          ]
        }
      ],
      "source": [
        "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.tools import tool\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o\")\n",
        "\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant.\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "        # Placeholders fill up a **list** of messages\n",
        "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "@tool\n",
        "def magic_function(input: int) -> int:\n",
        "    \"\"\"Applies a magic function to an input.\"\"\"\n",
        "    return \"Sorry there was an error, please try again.\"\n",
        "\n",
        "\n",
        "tools = [magic_function]\n",
        "\n",
        "agent = create_tool_calling_agent(model, tools, prompt=prompt)\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=agent, tools=tools, early_stopping_method=\"force\", max_iterations=1\n",
        ")\n",
        "\n",
        "result = agent_executor.invoke({\"input\": query})\n",
        "print(\"Output with early_stopping_method='force':\")\n",
        "print(result[\"output\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "706e05c4",
      "metadata": {},
      "source": [
        "### 在 LangGraph 中\n\n在 LangGraph 中，您可以显式地处理响应行为在代理之外，因为可以访问完整的状态。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "73cabbc4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content='what is the value of magic_function(3)?' additional_kwargs={} response_metadata={} id='81fd2e50-1e6a-4871-87aa-b7c1225913a4'\n",
            "content='' additional_kwargs={'tool_calls': [{'id': 'call_aaEzj3aO1RTnB0uoc9rYUIhi', 'function': {'arguments': '{\"input\":3}', 'name': 'magic_function'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 55, 'total_tokens': 69, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a7d06e42a7', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-476bc4b1-b7bf-4607-a31c-ddf09dc814c5-0' tool_calls=[{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_aaEzj3aO1RTnB0uoc9rYUIhi', 'type': 'tool_call'}] usage_metadata={'input_tokens': 55, 'output_tokens': 14, 'total_tokens': 69, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n",
            "content='Sorry there was an error, please try again.' name='magic_function' id='dcbe7e3e-0ed4-467d-a729-2f45916ff44f' tool_call_id='call_aaEzj3aO1RTnB0uoc9rYUIhi'\n",
            "content=\"It seems there was an error when trying to compute the value of `magic_function(3)`. Let's try that again.\" additional_kwargs={'tool_calls': [{'id': 'call_jr4R8uJn2pdXF5GZC2Dg3YWS', 'function': {'arguments': '{\"input\":3}', 'name': 'magic_function'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 87, 'total_tokens': 127, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a7d06e42a7', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-d94b8932-6e9e-4ab1-99f7-7dca89887ffe-0' tool_calls=[{'name': 'magic_function', 'args': {'input': 3}, 'id': 'call_jr4R8uJn2pdXF5GZC2Dg3YWS', 'type': 'tool_call'}] usage_metadata={'input_tokens': 87, 'output_tokens': 40, 'total_tokens': 127, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n",
            "{'input': 'what is the value of magic_function(3)?', 'output': 'Agent stopped due to max iterations.'}\n"
          ]
        }
      ],
      "source": [
        "from langgraph.errors import GraphRecursionError\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "RECURSION_LIMIT = 2 * 1 + 1\n",
        "\n",
        "langgraph_agent_executor = create_react_agent(model, tools=tools)\n",
        "\n",
        "try:\n",
        "    for chunk in langgraph_agent_executor.stream(\n",
        "        {\"messages\": [(\"human\", query)]},\n",
        "        {\"recursion_limit\": RECURSION_LIMIT},\n",
        "        stream_mode=\"values\",\n",
        "    ):\n",
        "        print(chunk[\"messages\"][-1])\n",
        "except GraphRecursionError:\n",
        "    print({\"input\": query, \"output\": \"Agent stopped due to max iterations.\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "017fe20e",
      "metadata": {},
      "source": [
        "## `trim_intermediate_steps`\n\n### 在 LangChain 中\n\n使用 LangChain 的 [AgentExecutor](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor)，您可以使用 [trim_intermediate_steps](https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html#langchain.agents.agent.AgentExecutor.trim_intermediate_steps) 来截断长时间运行的代理的中间步骤，该参数可以是一个整数（表示代理应保留最后 N 个步骤）或一个自定义函数。\n\n例如，我们可以截断该值，以便代理只看到最近的中间步骤。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "b94bb169",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Call number: 1\n",
            "Call number: 2\n",
            "Call number: 3\n",
            "Call number: 4\n",
            "Call number: 5\n",
            "Call number: 6\n",
            "Call number: 7\n",
            "Call number: 8\n",
            "Call number: 9\n",
            "Call number: 10\n",
            "Call number: 11\n",
            "Call number: 12\n",
            "Call number: 13\n",
            "Call number: 14\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Stopping agent prematurely due to triggering stop condition\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Call number: 15\n"
          ]
        }
      ],
      "source": [
        "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.tools import tool\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o\")\n",
        "\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant.\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "        # Placeholders fill up a **list** of messages\n",
        "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "magic_step_num = 1\n",
        "\n",
        "\n",
        "@tool\n",
        "def magic_function(input: int) -> int:\n",
        "    \"\"\"Applies a magic function to an input.\"\"\"\n",
        "    global magic_step_num\n",
        "    print(f\"Call number: {magic_step_num}\")\n",
        "    magic_step_num += 1\n",
        "    return input + magic_step_num\n",
        "\n",
        "\n",
        "tools = [magic_function]\n",
        "\n",
        "agent = create_tool_calling_agent(model, tools, prompt=prompt)\n",
        "\n",
        "\n",
        "def trim_steps(steps: list):\n",
        "    # Let's give the agent amnesia\n",
        "    return []\n",
        "\n",
        "\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=agent, tools=tools, trim_intermediate_steps=trim_steps\n",
        ")\n",
        "\n",
        "\n",
        "query = \"Call the magic function 4 times in sequence with the value 3. You cannot call it multiple times at once.\"\n",
        "\n",
        "for step in agent_executor.stream({\"input\": query}):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d450c5a",
      "metadata": {},
      "source": [
        "### 在 LangGraph 中\n\n我们可以在传入 [prompt templates](#prompt-templates) 时，像之前一样使用 [`prompt`](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.chat_agent_executor.create_react_agent)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "b309ba9a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Call number: 1\n",
            "Call number: 2\n",
            "Call number: 3\n",
            "Call number: 4\n",
            "Call number: 5\n",
            "Call number: 6\n",
            "Call number: 7\n",
            "Call number: 8\n",
            "Call number: 9\n",
            "Call number: 10\n",
            "Call number: 11\n",
            "Call number: 12\n",
            "Stopping agent prematurely due to triggering stop condition\n"
          ]
        }
      ],
      "source": [
        "from langgraph.errors import GraphRecursionError\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.prebuilt.chat_agent_executor import AgentState\n",
        "\n",
        "magic_step_num = 1\n",
        "\n",
        "\n",
        "@tool\n",
        "def magic_function(input: int) -> int:\n",
        "    \"\"\"Applies a magic function to an input.\"\"\"\n",
        "    global magic_step_num\n",
        "    print(f\"Call number: {magic_step_num}\")\n",
        "    magic_step_num += 1\n",
        "    return input + magic_step_num\n",
        "\n",
        "\n",
        "tools = [magic_function]\n",
        "\n",
        "\n",
        "def _modify_state_messages(state: AgentState):\n",
        "    # Give the agent amnesia, only keeping the original user query\n",
        "    return [(\"system\", \"You are a helpful assistant\"), state[\"messages\"][0]]\n",
        "\n",
        "\n",
        "langgraph_agent_executor = create_react_agent(\n",
        "    model, tools, prompt=_modify_state_messages\n",
        ")\n",
        "\n",
        "try:\n",
        "    for step in langgraph_agent_executor.stream(\n",
        "        {\"messages\": [(\"human\", query)]}, stream_mode=\"updates\"\n",
        "    ):\n",
        "        pass\n",
        "except GraphRecursionError as e:\n",
        "    print(\"Stopping agent prematurely due to triggering stop condition\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41377eb8",
      "metadata": {},
      "source": [
        "## 后续步骤\n\n您现在已经学会了如何将 LangChain Agent Executors 迁移到 LangGraph。\n\n接下来，请查看其他的 [LangGraph 操作指南](https://langchain-ai.github.io/langgraph/how-tos/)。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}