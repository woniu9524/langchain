{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "80f15d95-00d8-4c38-a291-07ff2233b4fd",
      "metadata": {},
      "source": [
        "# å¦‚ä½•åˆ›å»ºè‡ªå®šä¹‰è¾“å‡ºè§£æå™¨\n\nåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæ‚¨å¯èƒ½å¸Œæœ›å®ç°è‡ªå®šä¹‰çš„ [è§£æå™¨](/docs/concepts/output_parsers/)ï¼Œå°†æ¨¡å‹è¾“å‡ºç»“æ„åŒ–ä¸ºè‡ªå®šä¹‰æ ¼å¼ã€‚\n\næœ‰ä¸¤ç§æ–¹æ³•å¯ä»¥å®ç°è‡ªå®šä¹‰è§£æå™¨ï¼š\n\n1. ä½¿ç”¨ [LCEL](/docs/concepts/lcel/) ä¸­çš„ `RunnableLambda` æˆ– `RunnableGenerator` â€”â€” æˆ‘ä»¬å¼ºçƒˆæ¨èåœ¨å¤§å¤šæ•°ç”¨ä¾‹ä¸­ä½¿ç”¨è¿™ç§æ–¹æ³•\n2. é€šè¿‡ç»§æ‰¿è¾“å‡ºè§£æçš„åŸºç±»ä¹‹ä¸€ â€”â€” è¿™æ˜¯æ¯”è¾ƒâ€œç¡¬æ ¸â€çš„åšæ³•\n\nè¿™ä¸¤ç§æ–¹æ³•ä¹‹é—´çš„åŒºåˆ«ä¸»è¦åœ¨äºè¡¨é¢ä¸Šï¼Œå¹¶ä¸”ä¸»è¦ä½“ç°åœ¨è§¦å‘çš„å›è°ƒï¼ˆä¾‹å¦‚ `on_chain_start` ä¸ `on_parser_start`ï¼‰ä»¥åŠåœ¨ LangSmith ç­‰è·Ÿè¸ªå¹³å°ä¸­å¦‚ä½•å¯è§†åŒ– runnable lambda ä¸è§£æå™¨ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c651cc26-28cb-45d1-9969-d88deff8b819",
      "metadata": {},
      "source": [
        "## å¯è¿è¡Œçš„ Lambda å’Œç”Ÿæˆå™¨\n\næ¨èçš„è§£ææ–¹å¼æ˜¯ä½¿ç”¨**å¯è¿è¡Œçš„ Lambda** å’Œ **å¯è¿è¡Œçš„ç”Ÿæˆå™¨**ï¼\n\nåœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªç®€å•çš„è§£æå™¨ï¼Œå®ƒä¼šåè½¬æ¨¡å‹è¾“å‡ºçš„å¤§å°å†™ã€‚\n\nä¾‹å¦‚ï¼Œå¦‚æœæ¨¡å‹è¾“å‡ºï¼šâ€œMeowâ€ï¼Œè§£æå™¨å°†ç”Ÿæˆâ€œmEOWâ€ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6cd7cc21-ec51-4e22-82d0-32c4401f5adc",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'hELLO!'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from typing import Iterable\n",
        "\n",
        "from langchain_anthropic.chat_models import ChatAnthropic\n",
        "from langchain_core.messages import AIMessage, AIMessageChunk\n",
        "\n",
        "model = ChatAnthropic(model_name=\"claude-2.1\")\n",
        "\n",
        "\n",
        "def parse(ai_message: AIMessage) -> str:\n",
        "    \"\"\"Parse the AI message.\"\"\"\n",
        "    return ai_message.content.swapcase()\n",
        "\n",
        "\n",
        "chain = model | parse\n",
        "chain.invoke(\"hello\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eed8baf2-f4c2-44c1-b47d-e9f560af6202",
      "metadata": {},
      "source": [
        ":::tip\n\nLCEL åœ¨ä½¿ç”¨ `|` è¯­æ³•ç»„åˆæ—¶ï¼Œä¼šè‡ªåŠ¨å°† `parse` å‡½æ•°å‡çº§ä¸º `RunnableLambda(parse)`ã€‚\n\nå¦‚æœä½ ä¸å–œæ¬¢è¿™ç§æ–¹å¼ï¼Œå¯ä»¥æ‰‹åŠ¨å¯¼å…¥ `RunnableLambda`ï¼Œç„¶åè¿è¡Œ `parse = RunnableLambda(parse)`ã€‚\n:::"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "896f52ce-91e2-4c7c-bd62-1f901002ade2",
      "metadata": {},
      "source": [
        "æµå¼ä¼ è¾“æ˜¯å¦æœ‰æ•ˆï¼Ÿ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4e35389a-caa5-4c0d-9d95-48648d0b8d4f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i'M cLAUDE, AN ai ASSISTANT CREATED BY aNTHROPIC TO BE HELPFUL, HARMLESS, AND HONEST.|"
          ]
        }
      ],
      "source": [
        "for chunk in chain.stream(\"tell me about yourself in one sentence\"):\n",
        "    print(chunk, end=\"|\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11c486bb-b2d4-461b-8fd8-19b9e0472129",
      "metadata": {},
      "source": [
        "ä¸ï¼Œå®ƒæ²¡æœ‰ï¼Œå› ä¸ºè§£æå™¨åœ¨è§£æè¾“å‡ºä¹‹å‰ä¼šèšåˆè¾“å…¥ã€‚\n\nå¦‚æœæˆ‘ä»¬æƒ³å®ç°ä¸€ä¸ªæµå¼è§£æå™¨ï¼Œæˆ‘ä»¬å¯ä»¥è®©è§£æå™¨æ¥å—ä¸€ä¸ªå¯è¿­ä»£çš„è¾“å…¥ï¼Œå¹¶åœ¨ç»“æœå¯ç”¨æ—¶è¿›è¡Œç”Ÿæˆã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "930aa59e-82d0-447c-b711-b416d92a08b7",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnableGenerator\n",
        "\n",
        "\n",
        "def streaming_parse(chunks: Iterable[AIMessageChunk]) -> Iterable[str]:\n",
        "    for chunk in chunks:\n",
        "        yield chunk.content.swapcase()\n",
        "\n",
        "\n",
        "streaming_parse = RunnableGenerator(streaming_parse)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62192808-c7e1-4b3a-85f4-b7901de7c0b8",
      "metadata": {},
      "source": [
        ":::important\n\nè¯·å°†æµå¼è§£æå™¨åŒ…è£…åœ¨ `RunnableGenerator` ä¸­ï¼Œå› ä¸ºæˆ‘ä»¬å¯èƒ½ä¸å†æ”¯æŒä½¿ç”¨ `|` è¯­æ³•è‡ªåŠ¨å‡çº§å®ƒã€‚\n:::"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c054d4da-66f3-4f11-8137-0734bb3de06c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'hELLO!'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain = model | streaming_parse\n",
        "chain.invoke(\"hello\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d344ff2-5c93-49a9-af00-03856d2cbfdb",
      "metadata": {},
      "source": [
        "æˆ‘ä»¬æ¥ç¡®è®¤ä¸€ä¸‹æµå¼ä¼ è¾“æ˜¯å¦æ­£å¸¸å·¥ä½œï¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "26d746ae-9c5a-4cda-a535-33f555e2e04a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i|'M| cLAUDE|,| AN| ai| ASSISTANT| CREATED| BY| aN|THROP|IC| TO| BE| HELPFUL|,| HARMLESS|,| AND| HONEST|.|"
          ]
        }
      ],
      "source": [
        "for chunk in chain.stream(\"tell me about yourself in one sentence\"):\n",
        "    print(chunk, end=\"|\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24067447-8a5a-4d6b-86a3-4b9cc4b4369b",
      "metadata": {},
      "source": [
        "## ä»è§£æåŸºç±»ç»§æ‰¿"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9713f547-b2e4-48eb-807f-a0f6f6d0e7e0",
      "metadata": {},
      "source": [
        "å¦ä¸€ç§å®ç°è§£æå™¨çš„æ–¹æ³•æ˜¯ç»§æ‰¿ `BaseOutputParser`ã€`BaseGenerationOutputParser` æˆ–å…¶ä»–åŸºç¡€è§£æå™¨ï¼Œå…·ä½“å–å†³äºæ‚¨çš„éœ€æ±‚ã€‚\n\næ€»çš„æ¥è¯´ï¼Œæˆ‘ä»¬**ä¸**å»ºè®®åœ¨å¤§å¤šæ•°ç”¨ä¾‹ä¸­é‡‡ç”¨è¿™ç§æ–¹æ³•ï¼Œå› ä¸ºå®ƒéœ€è¦ç¼–å†™æ›´å¤šä»£ç ï¼Œä½†å¸¦æ¥çš„å¥½å¤„å¹¶ä¸æ˜¾è‘—ã€‚\n\næœ€ç®€å•çš„è¾“å‡ºè§£æå™¨ç±»å‹æ˜¯ç»§æ‰¿ `BaseOutputParser` ç±»ï¼Œå¹¶ä¸”å¿…é¡»å®ç°ä»¥ä¸‹æ–¹æ³•ï¼š\n\n* `parse`ï¼šæ¥æ”¶æ¨¡å‹ç”Ÿæˆçš„å­—ç¬¦ä¸²è¾“å‡ºå¹¶è¿›è¡Œè§£æ\n* ï¼ˆå¯é€‰ï¼‰`_type`ï¼šæ ‡è¯†è§£æå™¨çš„åç§°ã€‚\n\nå½“èŠå¤©æ¨¡å‹æˆ– LLM çš„è¾“å‡ºæ ¼å¼é”™è¯¯æ—¶ï¼Œå¯ä»¥æŠ›å‡º `OutputParserException` æ¥è¡¨æ˜ç”±äºè¾“å…¥é”™è¯¯å¯¼è‡´è§£æå¤±è´¥ã€‚ä½¿ç”¨æ­¤å¼‚å¸¸å¯ä»¥ä½¿ä½¿ç”¨è¯¥è§£æå™¨çš„ä»£ç ä»¥ä¸€è‡´çš„æ–¹å¼å¤„ç†å¼‚å¸¸ã€‚\n\n:::tip è§£æå™¨æ˜¯ Runnablesï¼ğŸƒ\n\nç”±äº `BaseOutputParser` å®ç°äº† `Runnable` æ¥å£ï¼Œæ‚¨é€šè¿‡è¿™ç§æ–¹å¼åˆ›å»ºçš„ä»»ä½•è‡ªå®šä¹‰è§£æå™¨éƒ½å°†æˆä¸ºæœ‰æ•ˆçš„ LangChain Runnablesï¼Œå¹¶å—ç›Šäºè‡ªåŠ¨å¼‚æ­¥æ”¯æŒã€æ‰¹é‡æ¥å£ã€æ—¥å¿—è®°å½•æ”¯æŒç­‰ã€‚\n:::"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e0f9c59-b5bd-4ed0-a187-ae514c203e80",
      "metadata": {},
      "source": [
        "### ç®€å•çš„è§£æå™¨"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a96a846-1296-4d92-8e76-e29e583dee22",
      "metadata": {},
      "source": [
        "è¿™æ˜¯ä¸€ä¸ªç®€å•çš„è§£æå™¨ï¼Œå¯ä»¥å°†å¸ƒå°”å€¼çš„**å­—ç¬¦ä¸²**è¡¨ç¤ºï¼ˆä¾‹å¦‚ `YES` æˆ– `NO`ï¼‰è½¬æ¢ä¸ºç›¸åº”çš„ `boolean` ç±»å‹ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "733a0c4f-471a-4161-ad3e-804f63053e6f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.exceptions import OutputParserException\n",
        "from langchain_core.output_parsers import BaseOutputParser\n",
        "\n",
        "\n",
        "# The [bool] desribes a parameterization of a generic.\n",
        "# It's basically indicating what the return type of parse is\n",
        "# in this case the return type is either True or False\n",
        "class BooleanOutputParser(BaseOutputParser[bool]):\n",
        "    \"\"\"Custom boolean parser.\"\"\"\n",
        "\n",
        "    true_val: str = \"YES\"\n",
        "    false_val: str = \"NO\"\n",
        "\n",
        "    def parse(self, text: str) -> bool:\n",
        "        cleaned_text = text.strip().upper()\n",
        "        if cleaned_text not in (self.true_val.upper(), self.false_val.upper()):\n",
        "            raise OutputParserException(\n",
        "                f\"BooleanOutputParser expected output value to either be \"\n",
        "                f\"{self.true_val} or {self.false_val} (case-insensitive). \"\n",
        "                f\"Received {cleaned_text}.\"\n",
        "            )\n",
        "        return cleaned_text == self.true_val.upper()\n",
        "\n",
        "    @property\n",
        "    def _type(self) -> str:\n",
        "        return \"boolean_output_parser\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "101e54f0-12f1-4734-a80d-98e6f62644b2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parser = BooleanOutputParser()\n",
        "parser.invoke(\"YES\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "39ed9d84-16a1-4612-a1f7-13269b9f48e8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Triggered an exception of type: <class 'langchain_core.exceptions.OutputParserException'>\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    parser.invoke(\"MEOW\")\n",
        "except Exception as e:\n",
        "    print(f\"Triggered an exception of type: {type(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c27da11a-2c64-4108-9a8a-38008d6041fc",
      "metadata": {},
      "source": [
        "è®©æˆ‘ä»¬æµ‹è¯•ä¸€ä¸‹æ›´æ”¹å‚æ•°åŒ–"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2e94c0f4-f6c1-401b-8cee-2572a80846cb",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parser = BooleanOutputParser(true_val=\"OKAY\")\n",
        "parser.invoke(\"OKAY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dac313d5-20c8-44a9-bfe9-c2b5020172e2",
      "metadata": {},
      "source": [
        "è®©æˆ‘ä»¬ç¡®è®¤ä¸€ä¸‹æ˜¯å¦è¿˜å­˜åœ¨å…¶ä»–çš„ LCEL æ–¹æ³•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "97fb540f-83b2-46fd-a741-b200235f8f9e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[True, False]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parser.batch([\"OKAY\", \"NO\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "60cbdb2f-5538-4e74-ba03-53bc1bc4bb2f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[True, False]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "await parser.abatch([\"OKAY\", \"NO\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6520dff0-259c-48e4-be69-829fb3275ac2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='OKAY')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_anthropic.chat_models import ChatAnthropic\n",
        "\n",
        "anthropic = ChatAnthropic(model_name=\"claude-2.1\")\n",
        "anthropic.invoke(\"say OKAY or NO\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12dc079e-c451-496c-953c-cba55ef26de8",
      "metadata": {},
      "source": [
        "è®©æˆ‘ä»¬æµ‹è¯•ä¸€ä¸‹æˆ‘ä»¬çš„è§£æå™¨æ˜¯å¦å·¥ä½œï¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "bb177c14-b1f5-474f-a1c8-5b32ae242259",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain = anthropic | parser\n",
        "chain.invoke(\"say OKAY or NO\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18f83192-37e8-43f5-ab29-9568b1279f1b",
      "metadata": {},
      "source": [
        ":::note\nè§£æå™¨å¯ä»¥å¤„ç†æ¥è‡ª LLMï¼ˆå­—ç¬¦ä¸²ï¼‰æˆ–æ¥è‡ªèŠå¤©æ¨¡å‹ï¼ˆAIMessageï¼‰çš„è¾“å‡ºï¼\n:::"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ed063d3-3159-4f5b-8362-710956fc50bd",
      "metadata": {},
      "source": [
        "### è§£æåŸå§‹æ¨¡å‹è¾“å‡º\n\næœ‰æ—¶ï¼Œé™¤äº†åŸå§‹æ–‡æœ¬ä¹‹å¤–ï¼Œæ¨¡å‹è¾“å‡ºè¿˜åŒ…å«é‡è¦çš„é™„åŠ å…ƒæ•°æ®ã€‚ä¸€ä¸ªä¾‹å­æ˜¯å·¥å…·è°ƒç”¨ï¼Œå…¶ä¸­ç”¨äºä¼ é€’ç»™å·²è°ƒç”¨å‡½æ•°çš„å‚æ•°åœ¨å•ç‹¬çš„å±æ€§ä¸­è¿”å›ã€‚å¦‚æœéœ€è¦è¿™ç§æ›´ç»†ç²’åº¦çš„æ§åˆ¶ï¼Œå¯ä»¥æ”¹ç”¨ `BaseGenerationOutputParser` ç±»ã€‚\n\næ­¤ç±»éœ€è¦ä¸€ä¸ªåä¸º `parse_result` çš„æ–¹æ³•ã€‚æ­¤æ–¹æ³•æ¥æ”¶åŸå§‹æ¨¡å‹è¾“å‡ºï¼ˆä¾‹å¦‚ `Generation` æˆ– `ChatGeneration` çš„åˆ—è¡¨ï¼‰ï¼Œå¹¶è¿”å›è§£æåçš„è¾“å‡ºã€‚\n\nåŒæ—¶æ”¯æŒ `Generation` å’Œ `ChatGeneration` å…è®¸è§£æå™¨åŒæ—¶ç”¨äºå¸¸è§„ LLM å’ŒèŠå¤©æ¨¡å‹ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "0fd1f936-e77d-4602-921c-52a37e589e90",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "from langchain_core.exceptions import OutputParserException\n",
        "from langchain_core.messages import AIMessage\n",
        "from langchain_core.output_parsers import BaseGenerationOutputParser\n",
        "from langchain_core.outputs import ChatGeneration, Generation\n",
        "\n",
        "\n",
        "class StrInvertCase(BaseGenerationOutputParser[str]):\n",
        "    \"\"\"An example parser that inverts the case of the characters in the message.\n",
        "\n",
        "    This is an example parse shown just for demonstration purposes and to keep\n",
        "    the example as simple as possible.\n",
        "    \"\"\"\n",
        "\n",
        "    def parse_result(self, result: List[Generation], *, partial: bool = False) -> str:\n",
        "        \"\"\"Parse a list of model Generations into a specific format.\n",
        "\n",
        "        Args:\n",
        "            result: A list of Generations to be parsed. The Generations are assumed\n",
        "                to be different candidate outputs for a single model input.\n",
        "                Many parsers assume that only a single generation is passed it in.\n",
        "                We will assert for that\n",
        "            partial: Whether to allow partial results. This is used for parsers\n",
        "                     that support streaming\n",
        "        \"\"\"\n",
        "        if len(result) != 1:\n",
        "            raise NotImplementedError(\n",
        "                \"This output parser can only be used with a single generation.\"\n",
        "            )\n",
        "        generation = result[0]\n",
        "        if not isinstance(generation, ChatGeneration):\n",
        "            # Say that this one only works with chat generations\n",
        "            raise OutputParserException(\n",
        "                \"This output parser can only be used with a chat generation.\"\n",
        "            )\n",
        "        return generation.message.content.swapcase()\n",
        "\n",
        "\n",
        "chain = anthropic | StrInvertCase()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "accab8a3-6b0e-4ad0-89e6-1824ca20c726",
      "metadata": {},
      "source": [
        "è®©æ–°çš„è§£æå™¨æ¥å¤„ç†å§ï¼å®ƒåº”è¯¥èƒ½å¤Ÿåè½¬æ¨¡å‹çš„è¾“å‡ºã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "568fae19-b09c-484f-8775-1c9a60aabdf4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'hELLO! mY NAME IS cLAUDE.'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke(\"Tell me a short sentence about yourself\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}