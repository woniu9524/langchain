{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "80f15d95-00d8-4c38-a291-07ff2233b4fd",
      "metadata": {},
      "source": [
        "# 如何创建自定义输出解析器\n\n在某些情况下，您可能希望实现自定义的 [解析器](/docs/concepts/output_parsers/)，将模型输出结构化为自定义格式。\n\n有两种方法可以实现自定义解析器：\n\n1. 使用 [LCEL](/docs/concepts/lcel/) 中的 `RunnableLambda` 或 `RunnableGenerator` —— 我们强烈推荐在大多数用例中使用这种方法\n2. 通过继承输出解析的基类之一 —— 这是比较“硬核”的做法\n\n这两种方法之间的区别主要在于表面上，并且主要体现在触发的回调（例如 `on_chain_start` 与 `on_parser_start`）以及在 LangSmith 等跟踪平台中如何可视化 runnable lambda 与解析器。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c651cc26-28cb-45d1-9969-d88deff8b819",
      "metadata": {},
      "source": [
        "## 可运行的 Lambda 和生成器\n\n推荐的解析方式是使用**可运行的 Lambda** 和 **可运行的生成器**！\n\n在这里，我们将创建一个简单的解析器，它会反转模型输出的大小写。\n\n例如，如果模型输出：“Meow”，解析器将生成“mEOW”。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6cd7cc21-ec51-4e22-82d0-32c4401f5adc",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'hELLO!'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from typing import Iterable\n",
        "\n",
        "from langchain_anthropic.chat_models import ChatAnthropic\n",
        "from langchain_core.messages import AIMessage, AIMessageChunk\n",
        "\n",
        "model = ChatAnthropic(model_name=\"claude-2.1\")\n",
        "\n",
        "\n",
        "def parse(ai_message: AIMessage) -> str:\n",
        "    \"\"\"Parse the AI message.\"\"\"\n",
        "    return ai_message.content.swapcase()\n",
        "\n",
        "\n",
        "chain = model | parse\n",
        "chain.invoke(\"hello\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eed8baf2-f4c2-44c1-b47d-e9f560af6202",
      "metadata": {},
      "source": [
        ":::tip\n\nLCEL 在使用 `|` 语法组合时，会自动将 `parse` 函数升级为 `RunnableLambda(parse)`。\n\n如果你不喜欢这种方式，可以手动导入 `RunnableLambda`，然后运行 `parse = RunnableLambda(parse)`。\n:::"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "896f52ce-91e2-4c7c-bd62-1f901002ade2",
      "metadata": {},
      "source": [
        "流式传输是否有效？"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4e35389a-caa5-4c0d-9d95-48648d0b8d4f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i'M cLAUDE, AN ai ASSISTANT CREATED BY aNTHROPIC TO BE HELPFUL, HARMLESS, AND HONEST.|"
          ]
        }
      ],
      "source": [
        "for chunk in chain.stream(\"tell me about yourself in one sentence\"):\n",
        "    print(chunk, end=\"|\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11c486bb-b2d4-461b-8fd8-19b9e0472129",
      "metadata": {},
      "source": [
        "不，它没有，因为解析器在解析输出之前会聚合输入。\n\n如果我们想实现一个流式解析器，我们可以让解析器接受一个可迭代的输入，并在结果可用时进行生成。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "930aa59e-82d0-447c-b711-b416d92a08b7",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnableGenerator\n",
        "\n",
        "\n",
        "def streaming_parse(chunks: Iterable[AIMessageChunk]) -> Iterable[str]:\n",
        "    for chunk in chunks:\n",
        "        yield chunk.content.swapcase()\n",
        "\n",
        "\n",
        "streaming_parse = RunnableGenerator(streaming_parse)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62192808-c7e1-4b3a-85f4-b7901de7c0b8",
      "metadata": {},
      "source": [
        ":::important\n\n请将流式解析器包装在 `RunnableGenerator` 中，因为我们可能不再支持使用 `|` 语法自动升级它。\n:::"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c054d4da-66f3-4f11-8137-0734bb3de06c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'hELLO!'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain = model | streaming_parse\n",
        "chain.invoke(\"hello\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d344ff2-5c93-49a9-af00-03856d2cbfdb",
      "metadata": {},
      "source": [
        "我们来确认一下流式传输是否正常工作！"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "26d746ae-9c5a-4cda-a535-33f555e2e04a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i|'M| cLAUDE|,| AN| ai| ASSISTANT| CREATED| BY| aN|THROP|IC| TO| BE| HELPFUL|,| HARMLESS|,| AND| HONEST|.|"
          ]
        }
      ],
      "source": [
        "for chunk in chain.stream(\"tell me about yourself in one sentence\"):\n",
        "    print(chunk, end=\"|\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24067447-8a5a-4d6b-86a3-4b9cc4b4369b",
      "metadata": {},
      "source": [
        "## 从解析基类继承"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9713f547-b2e4-48eb-807f-a0f6f6d0e7e0",
      "metadata": {},
      "source": [
        "另一种实现解析器的方法是继承 `BaseOutputParser`、`BaseGenerationOutputParser` 或其他基础解析器，具体取决于您的需求。\n\n总的来说，我们**不**建议在大多数用例中采用这种方法，因为它需要编写更多代码，但带来的好处并不显著。\n\n最简单的输出解析器类型是继承 `BaseOutputParser` 类，并且必须实现以下方法：\n\n* `parse`：接收模型生成的字符串输出并进行解析\n* （可选）`_type`：标识解析器的名称。\n\n当聊天模型或 LLM 的输出格式错误时，可以抛出 `OutputParserException` 来表明由于输入错误导致解析失败。使用此异常可以使使用该解析器的代码以一致的方式处理异常。\n\n:::tip 解析器是 Runnables！🏃\n\n由于 `BaseOutputParser` 实现了 `Runnable` 接口，您通过这种方式创建的任何自定义解析器都将成为有效的 LangChain Runnables，并受益于自动异步支持、批量接口、日志记录支持等。\n:::"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e0f9c59-b5bd-4ed0-a187-ae514c203e80",
      "metadata": {},
      "source": [
        "### 简单的解析器"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a96a846-1296-4d92-8e76-e29e583dee22",
      "metadata": {},
      "source": [
        "这是一个简单的解析器，可以将布尔值的**字符串**表示（例如 `YES` 或 `NO`）转换为相应的 `boolean` 类型。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "733a0c4f-471a-4161-ad3e-804f63053e6f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.exceptions import OutputParserException\n",
        "from langchain_core.output_parsers import BaseOutputParser\n",
        "\n",
        "\n",
        "# The [bool] desribes a parameterization of a generic.\n",
        "# It's basically indicating what the return type of parse is\n",
        "# in this case the return type is either True or False\n",
        "class BooleanOutputParser(BaseOutputParser[bool]):\n",
        "    \"\"\"Custom boolean parser.\"\"\"\n",
        "\n",
        "    true_val: str = \"YES\"\n",
        "    false_val: str = \"NO\"\n",
        "\n",
        "    def parse(self, text: str) -> bool:\n",
        "        cleaned_text = text.strip().upper()\n",
        "        if cleaned_text not in (self.true_val.upper(), self.false_val.upper()):\n",
        "            raise OutputParserException(\n",
        "                f\"BooleanOutputParser expected output value to either be \"\n",
        "                f\"{self.true_val} or {self.false_val} (case-insensitive). \"\n",
        "                f\"Received {cleaned_text}.\"\n",
        "            )\n",
        "        return cleaned_text == self.true_val.upper()\n",
        "\n",
        "    @property\n",
        "    def _type(self) -> str:\n",
        "        return \"boolean_output_parser\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "101e54f0-12f1-4734-a80d-98e6f62644b2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parser = BooleanOutputParser()\n",
        "parser.invoke(\"YES\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "39ed9d84-16a1-4612-a1f7-13269b9f48e8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Triggered an exception of type: <class 'langchain_core.exceptions.OutputParserException'>\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    parser.invoke(\"MEOW\")\n",
        "except Exception as e:\n",
        "    print(f\"Triggered an exception of type: {type(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c27da11a-2c64-4108-9a8a-38008d6041fc",
      "metadata": {},
      "source": [
        "让我们测试一下更改参数化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2e94c0f4-f6c1-401b-8cee-2572a80846cb",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parser = BooleanOutputParser(true_val=\"OKAY\")\n",
        "parser.invoke(\"OKAY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dac313d5-20c8-44a9-bfe9-c2b5020172e2",
      "metadata": {},
      "source": [
        "让我们确认一下是否还存在其他的 LCEL 方法"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "97fb540f-83b2-46fd-a741-b200235f8f9e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[True, False]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parser.batch([\"OKAY\", \"NO\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "60cbdb2f-5538-4e74-ba03-53bc1bc4bb2f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[True, False]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "await parser.abatch([\"OKAY\", \"NO\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6520dff0-259c-48e4-be69-829fb3275ac2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='OKAY')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_anthropic.chat_models import ChatAnthropic\n",
        "\n",
        "anthropic = ChatAnthropic(model_name=\"claude-2.1\")\n",
        "anthropic.invoke(\"say OKAY or NO\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12dc079e-c451-496c-953c-cba55ef26de8",
      "metadata": {},
      "source": [
        "让我们测试一下我们的解析器是否工作！"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "bb177c14-b1f5-474f-a1c8-5b32ae242259",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain = anthropic | parser\n",
        "chain.invoke(\"say OKAY or NO\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18f83192-37e8-43f5-ab29-9568b1279f1b",
      "metadata": {},
      "source": [
        ":::note\n解析器可以处理来自 LLM（字符串）或来自聊天模型（AIMessage）的输出！\n:::"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ed063d3-3159-4f5b-8362-710956fc50bd",
      "metadata": {},
      "source": [
        "### 解析原始模型输出\n\n有时，除了原始文本之外，模型输出还包含重要的附加元数据。一个例子是工具调用，其中用于传递给已调用函数的参数在单独的属性中返回。如果需要这种更细粒度的控制，可以改用 `BaseGenerationOutputParser` 类。\n\n此类需要一个名为 `parse_result` 的方法。此方法接收原始模型输出（例如 `Generation` 或 `ChatGeneration` 的列表），并返回解析后的输出。\n\n同时支持 `Generation` 和 `ChatGeneration` 允许解析器同时用于常规 LLM 和聊天模型。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "0fd1f936-e77d-4602-921c-52a37e589e90",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "from langchain_core.exceptions import OutputParserException\n",
        "from langchain_core.messages import AIMessage\n",
        "from langchain_core.output_parsers import BaseGenerationOutputParser\n",
        "from langchain_core.outputs import ChatGeneration, Generation\n",
        "\n",
        "\n",
        "class StrInvertCase(BaseGenerationOutputParser[str]):\n",
        "    \"\"\"An example parser that inverts the case of the characters in the message.\n",
        "\n",
        "    This is an example parse shown just for demonstration purposes and to keep\n",
        "    the example as simple as possible.\n",
        "    \"\"\"\n",
        "\n",
        "    def parse_result(self, result: List[Generation], *, partial: bool = False) -> str:\n",
        "        \"\"\"Parse a list of model Generations into a specific format.\n",
        "\n",
        "        Args:\n",
        "            result: A list of Generations to be parsed. The Generations are assumed\n",
        "                to be different candidate outputs for a single model input.\n",
        "                Many parsers assume that only a single generation is passed it in.\n",
        "                We will assert for that\n",
        "            partial: Whether to allow partial results. This is used for parsers\n",
        "                     that support streaming\n",
        "        \"\"\"\n",
        "        if len(result) != 1:\n",
        "            raise NotImplementedError(\n",
        "                \"This output parser can only be used with a single generation.\"\n",
        "            )\n",
        "        generation = result[0]\n",
        "        if not isinstance(generation, ChatGeneration):\n",
        "            # Say that this one only works with chat generations\n",
        "            raise OutputParserException(\n",
        "                \"This output parser can only be used with a chat generation.\"\n",
        "            )\n",
        "        return generation.message.content.swapcase()\n",
        "\n",
        "\n",
        "chain = anthropic | StrInvertCase()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "accab8a3-6b0e-4ad0-89e6-1824ca20c726",
      "metadata": {},
      "source": [
        "让新的解析器来处理吧！它应该能够反转模型的输出。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "568fae19-b09c-484f-8775-1c9a60aabdf4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'hELLO! mY NAME IS cLAUDE.'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke(\"Tell me a short sentence about yourself\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}