{
  "cells": [
    {
      "cell_type": "raw",
      "id": "e9437c8a-d8b7-4bf6-8ff4-54068a5a266c",
      "metadata": {},
      "source": [
        "---\n",
        "sidebar_position: 1.5\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0df7646-b1e1-4014-a841-6dae9b3c50d9",
      "metadata": {},
      "source": [
        "# 如何流式传输聊天模型响应\n\n\n所有 [聊天模型](https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.chat_models.BaseChatModel.html) 都实现了 [Runnable 接口](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable)，该接口自带了标准可运行方法（即 `ainvoke`, `batch`, `abatch`, `stream`, `astream`, `astream_events`）的**默认**实现。\n\n**默认**的流式传输实现提供了一个 `Iterator`（或异步流式的 `AsyncIterator`），它 yield 一个值：底层聊天模型提供商的最终输出。\n\n:::tip\n\n**默认**实现**不**支持逐 token 流式传输，但它确保了模型可以被替换为任何其他支持相同标准接口的模型。\n\n:::\n\n能否逐 token 流式传输输出取决于提供商是否实现了正确的流式传输支持。\n\n[在此处](/docs/integrations/chat/) 查看哪些集成支持逐 token 流式传输。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a76660e-7691-48b7-a2b4-2ccdff7875c3",
      "metadata": {},
      "source": [
        "## 同步流\n\n下面我们使用 `|` 来帮助可视化 token 之间的分隔符。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "975c4f32-21f6-4a71-9091-f87b56347c33",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here| is| a| |1| |verse| song| about| gol|dfish| on| the| moon|:|\n",
            "\n",
            "Floating| up| in| the| star|ry| night|,|\n",
            "Fins| a|-|gl|im|mer| in| the| pale| moon|light|.|\n",
            "Gol|dfish| swimming|,| peaceful| an|d free|,|\n",
            "Se|ren|ely| |drif|ting| across| the| lunar| sea|.|"
          ]
        }
      ],
      "source": [
        "from langchain_anthropic.chat_models import ChatAnthropic\n",
        "\n",
        "chat = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n",
        "for chunk in chat.stream(\"Write me a 1 verse song about goldfish on the moon\"):\n",
        "    print(chunk.content, end=\"|\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5482d3a7-ee4f-40ba-b871-4d3f52603cd5",
      "metadata": {
        "tags": []
      },
      "source": [
        "## 异步流"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "422f480c-df79-42e8-9bee-d0ebed31c557",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here| is| a| |1| |verse| song| about| gol|dfish| on| the| moon|:|\n",
            "\n",
            "Floating| up| above| the| Earth|,|\n",
            "Gol|dfish| swim| in| alien| m|irth|.|\n",
            "In| their| bowl| of| lunar| dust|,|\n",
            "Gl|it|tering| scales| reflect| the| trust|\n",
            "Of| swimming| free| in| this| new| worl|d,|\n",
            "Where| their| aqu|atic| dream|'s| unf|ur|le|d.|"
          ]
        }
      ],
      "source": [
        "from langchain_anthropic.chat_models import ChatAnthropic\n",
        "\n",
        "chat = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n",
        "async for chunk in chat.astream(\"Write me a 1 verse song about goldfish on the moon\"):\n",
        "    print(chunk.content, end=\"|\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c61e1309-3b6e-42fb-820a-2e4e3e6bc074",
      "metadata": {},
      "source": [
        "## 流式事件\n\nChat 模型同样支持标准的 [流式事件](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable.astream_events) 方法。\n\n如果你正在从包含多个步骤的大型 LLM 应用（例如，由提示、LLM 和解析器组成的 LLM 链）流式传输输出，那么此方法非常有用。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5a03086e-2813-4cb1-b12b-d00e7eeba122",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'event': 'on_chat_model_start', 'data': {'input': 'Write me a 1 verse song about goldfish on the moon'}, 'name': 'ChatAnthropic', 'tags': [], 'run_id': '1d430164-52b1-4d00-8c00-b16460f7737e', 'metadata': {'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}, 'parent_ids': []}\n",
            "{'event': 'on_chat_model_stream', 'run_id': '1d430164-52b1-4d00-8c00-b16460f7737e', 'name': 'ChatAnthropic', 'tags': [], 'metadata': {'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}, 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run-1d430164-52b1-4d00-8c00-b16460f7737e', usage_metadata={'input_tokens': 21, 'output_tokens': 2, 'total_tokens': 23, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})}, 'parent_ids': []}\n",
            "{'event': 'on_chat_model_stream', 'run_id': '1d430164-52b1-4d00-8c00-b16460f7737e', 'name': 'ChatAnthropic', 'tags': [], 'metadata': {'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}, 'data': {'chunk': AIMessageChunk(content=\"Here's\", additional_kwargs={}, response_metadata={}, id='run-1d430164-52b1-4d00-8c00-b16460f7737e')}, 'parent_ids': []}\n",
            "{'event': 'on_chat_model_stream', 'run_id': '1d430164-52b1-4d00-8c00-b16460f7737e', 'name': 'ChatAnthropic', 'tags': [], 'metadata': {'ls_provider': 'anthropic', 'ls_model_name': 'claude-3-haiku-20240307', 'ls_model_type': 'chat', 'ls_temperature': None, 'ls_max_tokens': 1024}, 'data': {'chunk': AIMessageChunk(content=' a short one-verse song', additional_kwargs={}, response_metadata={}, id='run-1d430164-52b1-4d00-8c00-b16460f7737e')}, 'parent_ids': []}\n",
            "...Truncated\n"
          ]
        }
      ],
      "source": [
        "from langchain_anthropic.chat_models import ChatAnthropic\n",
        "\n",
        "chat = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n",
        "idx = 0\n",
        "\n",
        "async for event in chat.astream_events(\n",
        "    \"Write me a 1 verse song about goldfish on the moon\"\n",
        "):\n",
        "    idx += 1\n",
        "    if idx >= 5:  # Truncate the output\n",
        "        print(\"...Truncated\")\n",
        "        break\n",
        "    print(event)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}