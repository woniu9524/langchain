{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "sidebar_position: 2\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 如何为聊天机器人添加检索\n\n[检索](/docs/concepts/retrieval/) 是一种聊天机器人常用的技术，用于用聊天模型训练数据之外的数据来增强其响应。本节将介绍如何在聊天机器人的上下文中实现检索，但值得注意的是，检索是一个非常微妙且深刻的话题——我们鼓励您探索 [文档的其他部分](/docs/how_to#qa-with-rag)，其中更深入地介绍了相关内容！\n\n## 设置\n\n您需要安装一些包，并将您的 OpenAI API 密钥设置为名为 `OPENAI_API_KEY` 的环境变量："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.\n",
            "You should consider upgrading via the '/Users/jacoblee/.pyenv/versions/3.10.5/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pip install -qU langchain langchain-openai langchain-chroma beautifulsoup4\n",
        "\n",
        "# Set env var OPENAI_API_KEY or load from a .env file:\n",
        "import dotenv\n",
        "\n",
        "dotenv.load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "我们也来设置一个聊天模型，供下面的示例使用。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 创建检索器\n\n我们将使用[LangSmith 文档](https://docs.smith.langchain.com/overview)作为源材料，并将内容存储在[向量库](/docs/concepts/vectorstores/)中以供后续检索。请注意，此示例将略过有关解析和存储数据源的一些细节——您可以在[此处更深入的文档中了解创建检索系统](/docs/how_to#qa-with-rag)。\n\n让我们使用文档加载器从文档中提取文本："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n",
        "data = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "接下来，我们将它分割成更小的、LLM 的上下文窗口可以处理的块，并将它们存储在向量数据库中："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
        "all_splits = text_splitter.split_documents(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "然后我们将这些块嵌入并存储在向量数据库中："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "最后，我们从初始化的 vectorstore 中创建一个 retriever："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='Skip to main content🦜️🛠️ LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}),\n",
              " Document(page_content='LangSmith Overview and User Guide | 🦜️🛠️ LangSmith', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}),\n",
              " Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}),\n",
              " Document(page_content=\"does that affect the output?\\u200bSo you notice a bad output, and you go into LangSmith to see what's going on. You find the faulty LLM call and are now looking at the exact input. You want to try changing a word or a phrase to see what happens -- what do you do?We constantly ran into this issue. Initially, we copied the prompt to a playground of sorts. But this got annoying, so we built a playground of our own! When examining an LLM call, you can click the Open in Playground button to access this\", metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'})]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# k is the number of chunks to retrieve\n",
        "retriever = vectorstore.as_retriever(k=4)\n",
        "\n",
        "docs = retriever.invoke(\"Can LangSmith help test my LLM applications?\")\n",
        "\n",
        "docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "我们可以看到，调用上面的检索器会得到 LangSmith 文档中一些包含测试信息的部分，这些信息可以作为 chatbot 回答问题的上下文。现在我们有了一个可以从 LangSmith 文档中返回相关数据的检索器！\n\n## 文档链\n\n既然我们有了一个可以返回 LangChain 文档的检索器，那么我们就来创建一个可以利用这些文档作为上下文来回答问题的链。我们将使用 `create_stuff_documents_chain` 辅助函数将所有输入文档“塞入”提示中。它还将负责将文档格式化为字符串。\n\n除了聊天模型之外，该函数还期望一个包含 `context` 变量的提示，以及一个名为 `messages` 的聊天历史消息占位符。我们将创建一个合适的提示并按如下方式传递："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "SYSTEM_TEMPLATE = \"\"\"\n",
        "Answer the user's questions based on the below context. \n",
        "If the context doesn't contain any relevant information to the question, don't make something up and just say \"I don't know\":\n",
        "\n",
        "<context>\n",
        "{context}\n",
        "</context>\n",
        "\"\"\"\n",
        "\n",
        "question_answering_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            SYSTEM_TEMPLATE,\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "document_chain = create_stuff_documents_chain(chat, question_answering_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "我们可以单独调用这个 `document_chain` 来回答问题。 让我们使用上面检索到的文档和相同的问题：“langsmith 如何帮助测试？”："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, LangSmith can help test and evaluate your LLM applications. It simplifies the initial setup, and you can use it to monitor your application, log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise.'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "document_chain.invoke(\n",
        "    {\n",
        "        \"context\": docs,\n",
        "        \"messages\": [\n",
        "            HumanMessage(content=\"Can LangSmith help test my LLM applications?\")\n",
        "        ],\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "看起来不错！为了进行比较，我们可以尝试不包含上下文文档，然后比较结果："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"I don't know about LangSmith's specific capabilities for testing LLM applications. It's best to reach out to LangSmith directly to inquire about their services and how they can assist with testing your LLM applications.\""
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "document_chain.invoke(\n",
        "    {\n",
        "        \"context\": [],\n",
        "        \"messages\": [\n",
        "            HumanMessage(content=\"Can LangSmith help test my LLM applications?\")\n",
        "        ],\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "我们可以看到 LLM 没有返回任何结果。\n\n## Retrieval chains\n\n让我们将这个文档链与检索器结合起来。这里有一种方式可以实现："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Dict\n",
        "\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "\n",
        "def parse_retriever_input(params: Dict):\n",
        "    return params[\"messages\"][-1].content\n",
        "\n",
        "\n",
        "retrieval_chain = RunnablePassthrough.assign(\n",
        "    context=parse_retriever_input | retriever,\n",
        ").assign(\n",
        "    answer=document_chain,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "给定一个输入消息列表，我们提取列表中最后一条消息的内容，并将其传递给检索器以获取文档。然后，我们将这些文档作为上下文传递给我们的文档链以生成最终响应。\n\n调用此链会合并上面概述的两个步骤："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Can LangSmith help test my LLM applications?')],\n",
              " 'context': [Document(page_content='Skip to main content🦜️🛠️ LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}),\n",
              "  Document(page_content='LangSmith Overview and User Guide | 🦜️🛠️ LangSmith', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}),\n",
              "  Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}),\n",
              "  Document(page_content=\"does that affect the output?\\u200bSo you notice a bad output, and you go into LangSmith to see what's going on. You find the faulty LLM call and are now looking at the exact input. You want to try changing a word or a phrase to see what happens -- what do you do?We constantly ran into this issue. Initially, we copied the prompt to a playground of sorts. But this got annoying, so we built a playground of our own! When examining an LLM call, you can click the Open in Playground button to access this\", metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'})],\n",
              " 'answer': 'Yes, LangSmith can help test and evaluate your LLM applications. It simplifies the initial setup, and you can use it to monitor your application, log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise.'}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retrieval_chain.invoke(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            HumanMessage(content=\"Can LangSmith help test my LLM applications?\")\n",
        "        ],\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "看起来不错！\n\n## 查询转换\n\n我们的检索链能够回答有关 LangSmith 的问题，但这里存在一个问题——聊天机器人以对话方式与用户互动，因此必须处理后续问题。\n\n目前形式的链在处理这个问题时会遇到困难。以我们原始问题的一个后续问题为例，如“Tell me more!”。如果我们直接用那个查询调用我们的检索器，我们会得到与 LLM 应用测试无关的文档："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}),\n",
              " Document(page_content='playground. Here, you can modify the prompt and re-run it to observe the resulting changes to the output - as many times as needed!Currently, this feature supports only OpenAI and Anthropic models and works for LLM and Chat Model calls. We plan to extend its functionality to more LLM types, chains, agents, and retrievers in the future.What is the exact sequence of events?\\u200bIn complicated chains and agents, it can often be hard to understand what is going on under the hood. What calls are being', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}),\n",
              " Document(page_content='however, there is still no complete substitute for human review to get the utmost quality and reliability from your application.', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}),\n",
              " Document(page_content='Skip to main content🦜️🛠️ LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'})]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever.invoke(\"Tell me more!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "这是因为检索器本身没有状态的概念，它只会拉取与给定查询最相似的文档。为了解决这个问题，我们可以将查询转换为一个独立的查询，而无需任何外部 LLM 的引用。\n\n这里有一个例子："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='\"LangSmith LLM application testing and evaluation\"')"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "\n",
        "query_transform_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "        (\n",
        "            \"user\",\n",
        "            \"Given the above conversation, generate a search query to look up in order to get information relevant to the conversation. Only respond with the query, nothing else.\",\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "query_transformation_chain = query_transform_prompt | chat\n",
        "\n",
        "query_transformation_chain.invoke(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            HumanMessage(content=\"Can LangSmith help test my LLM applications?\"),\n",
        "            AIMessage(\n",
        "                content=\"Yes, LangSmith can help test and evaluate your LLM applications. It allows you to quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs. Additionally, LangSmith can be used to monitor your application, log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise.\"\n",
        "            ),\n",
        "            HumanMessage(content=\"Tell me more!\"),\n",
        "        ],\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "太棒了！这个转换后的查询将提取与 LLM 应用测试相关的上下文文档。\n\n让我们将其添加到检索链中。我们可以像这样包装我们的检索器："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnableBranch\n",
        "\n",
        "query_transforming_retriever_chain = RunnableBranch(\n",
        "    (\n",
        "        lambda x: len(x.get(\"messages\", [])) == 1,\n",
        "        # If only one message, then we just pass that message's content to retriever\n",
        "        (lambda x: x[\"messages\"][-1].content) | retriever,\n",
        "    ),\n",
        "    # If messages, then we pass inputs to LLM chain to transform the query, then pass to retriever\n",
        "    query_transform_prompt | chat | StrOutputParser() | retriever,\n",
        ").with_config(run_name=\"chat_retriever_chain\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "然后，我们可以使用这个查询转换链，让我们的检索链更好地处理这类后续问题："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "SYSTEM_TEMPLATE = \"\"\"\n",
        "Answer the user's questions based on the below context. \n",
        "If the context doesn't contain any relevant information to the question, don't make something up and just say \"I don't know\":\n",
        "\n",
        "<context>\n",
        "{context}\n",
        "</context>\n",
        "\"\"\"\n",
        "\n",
        "question_answering_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            SYSTEM_TEMPLATE,\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "document_chain = create_stuff_documents_chain(chat, question_answering_prompt)\n",
        "\n",
        "conversational_retrieval_chain = RunnablePassthrough.assign(\n",
        "    context=query_transforming_retriever_chain,\n",
        ").assign(\n",
        "    answer=document_chain,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "太棒了！让我们用和之前一样的输入来调用这个新链："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Can LangSmith help test my LLM applications?')],\n",
              " 'context': [Document(page_content='Skip to main content🦜️🛠️ LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}),\n",
              "  Document(page_content='LangSmith Overview and User Guide | 🦜️🛠️ LangSmith', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}),\n",
              "  Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}),\n",
              "  Document(page_content=\"does that affect the output?\\u200bSo you notice a bad output, and you go into LangSmith to see what's going on. You find the faulty LLM call and are now looking at the exact input. You want to try changing a word or a phrase to see what happens -- what do you do?We constantly ran into this issue. Initially, we copied the prompt to a playground of sorts. But this got annoying, so we built a playground of our own! When examining an LLM call, you can click the Open in Playground button to access this\", metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'})],\n",
              " 'answer': 'Yes, LangSmith can help test and evaluate LLM (Language Model) applications. It simplifies the initial setup, and you can use it to monitor your application, log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise.'}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversational_retrieval_chain.invoke(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            HumanMessage(content=\"Can LangSmith help test my LLM applications?\"),\n",
        "        ]\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='Can LangSmith help test my LLM applications?'),\n",
              "  AIMessage(content='Yes, LangSmith can help test and evaluate your LLM applications. It allows you to quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs. Additionally, LangSmith can be used to monitor your application, log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise.'),\n",
              "  HumanMessage(content='Tell me more!')],\n",
              " 'context': [Document(page_content='LangSmith Overview and User Guide | 🦜️🛠️ LangSmith', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}),\n",
              "  Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}),\n",
              "  Document(page_content='Skip to main content🦜️🛠️ LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}),\n",
              "  Document(page_content='LangSmith makes it easy to manually review and annotate runs through annotation queues.These queues allow you to select any runs based on criteria like model type or automatic evaluation scores, and queue them up for human review. As a reviewer, you can then quickly step through the runs, viewing the input, output, and any existing tags before adding your own feedback.We often use this for a couple of reasons:To assess subjective qualities that automatic evaluators struggle with, like', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'})],\n",
              " 'answer': 'LangSmith simplifies the initial setup for building reliable LLM applications, but it acknowledges that there is still work needed to bring the performance of prompts, chains, and agents up to the level where they are reliable enough to be used in production. It also provides the capability to manually review and annotate runs through annotation queues, allowing you to select runs based on criteria like model type or automatic evaluation scores for human review. This feature is particularly useful for assessing subjective qualities that automatic evaluators struggle with.'}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversational_retrieval_chain.invoke(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            HumanMessage(content=\"Can LangSmith help test my LLM applications?\"),\n",
        "            AIMessage(\n",
        "                content=\"Yes, LangSmith can help test and evaluate your LLM applications. It allows you to quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs. Additionally, LangSmith can be used to monitor your application, log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise.\"\n",
        "            ),\n",
        "            HumanMessage(content=\"Tell me more!\"),\n",
        "        ],\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "您可以查看 [此 LangSmith 追踪](https://smith.langchain.com/public/bb329a3b-e92a-4063-ad78-43f720fbb5a2/r)，亲自了解内部查询转换步骤。\n\n## 流式传输\n\n因为此链是通过 LCEL 构建的，所以您可以使用诸如 `.stream()` 之类的熟悉方法："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'messages': [HumanMessage(content='Can LangSmith help test my LLM applications?'), AIMessage(content='Yes, LangSmith can help test and evaluate your LLM applications. It allows you to quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs. Additionally, LangSmith can be used to monitor your application, log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise.'), HumanMessage(content='Tell me more!')]}\n",
            "{'context': [Document(page_content='LangSmith Overview and User Guide | 🦜️🛠️ LangSmith', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}), Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}), Document(page_content='Skip to main content🦜️🛠️ LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'}), Document(page_content='LangSmith makes it easy to manually review and annotate runs through annotation queues.These queues allow you to select any runs based on criteria like model type or automatic evaluation scores, and queue them up for human review. As a reviewer, you can then quickly step through the runs, viewing the input, output, and any existing tags before adding your own feedback.We often use this for a couple of reasons:To assess subjective qualities that automatic evaluators struggle with, like', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | 🦜️🛠️ LangSmith'})]}\n",
            "{'answer': ''}\n",
            "{'answer': 'Lang'}\n",
            "{'answer': 'Smith'}\n",
            "{'answer': ' simpl'}\n",
            "{'answer': 'ifies'}\n",
            "{'answer': ' the'}\n",
            "{'answer': ' initial'}\n",
            "{'answer': ' setup'}\n",
            "{'answer': ' for'}\n",
            "{'answer': ' building'}\n",
            "{'answer': ' reliable'}\n",
            "{'answer': ' L'}\n",
            "{'answer': 'LM'}\n",
            "{'answer': ' applications'}\n",
            "{'answer': '.'}\n",
            "{'answer': ' It'}\n",
            "{'answer': ' provides'}\n",
            "{'answer': ' features'}\n",
            "{'answer': ' for'}\n",
            "{'answer': ' manually'}\n",
            "{'answer': ' reviewing'}\n",
            "{'answer': ' and'}\n",
            "{'answer': ' annot'}\n",
            "{'answer': 'ating'}\n",
            "{'answer': ' runs'}\n",
            "{'answer': ' through'}\n",
            "{'answer': ' annotation'}\n",
            "{'answer': ' queues'}\n",
            "{'answer': ','}\n",
            "{'answer': ' allowing'}\n",
            "{'answer': ' you'}\n",
            "{'answer': ' to'}\n",
            "{'answer': ' select'}\n",
            "{'answer': ' runs'}\n",
            "{'answer': ' based'}\n",
            "{'answer': ' on'}\n",
            "{'answer': ' criteria'}\n",
            "{'answer': ' like'}\n",
            "{'answer': ' model'}\n",
            "{'answer': ' type'}\n",
            "{'answer': ' or'}\n",
            "{'answer': ' automatic'}\n",
            "{'answer': ' evaluation'}\n",
            "{'answer': ' scores'}\n",
            "{'answer': ','}\n",
            "{'answer': ' and'}\n",
            "{'answer': ' queue'}\n",
            "{'answer': ' them'}\n",
            "{'answer': ' up'}\n",
            "{'answer': ' for'}\n",
            "{'answer': ' human'}\n",
            "{'answer': ' review'}\n",
            "{'answer': '.'}\n",
            "{'answer': ' As'}\n",
            "{'answer': ' a'}\n",
            "{'answer': ' reviewer'}\n",
            "{'answer': ','}\n",
            "{'answer': ' you'}\n",
            "{'answer': ' can'}\n",
            "{'answer': ' quickly'}\n",
            "{'answer': ' step'}\n",
            "{'answer': ' through'}\n",
            "{'answer': ' the'}\n",
            "{'answer': ' runs'}\n",
            "{'answer': ','}\n",
            "{'answer': ' view'}\n",
            "{'answer': ' the'}\n",
            "{'answer': ' input'}\n",
            "{'answer': ','}\n",
            "{'answer': ' output'}\n",
            "{'answer': ','}\n",
            "{'answer': ' and'}\n",
            "{'answer': ' any'}\n",
            "{'answer': ' existing'}\n",
            "{'answer': ' tags'}\n",
            "{'answer': ' before'}\n",
            "{'answer': ' adding'}\n",
            "{'answer': ' your'}\n",
            "{'answer': ' own'}\n",
            "{'answer': ' feedback'}\n",
            "{'answer': '.'}\n",
            "{'answer': ' This'}\n",
            "{'answer': ' can'}\n",
            "{'answer': ' be'}\n",
            "{'answer': ' particularly'}\n",
            "{'answer': ' useful'}\n",
            "{'answer': ' for'}\n",
            "{'answer': ' assessing'}\n",
            "{'answer': ' subjective'}\n",
            "{'answer': ' qualities'}\n",
            "{'answer': ' that'}\n",
            "{'answer': ' automatic'}\n",
            "{'answer': ' evalu'}\n",
            "{'answer': 'ators'}\n",
            "{'answer': ' struggle'}\n",
            "{'answer': ' with'}\n",
            "{'answer': '.'}\n",
            "{'answer': ''}\n"
          ]
        }
      ],
      "source": [
        "stream = conversational_retrieval_chain.stream(\n",
        "    {\n",
        "        \"messages\": [\n",
        "            HumanMessage(content=\"Can LangSmith help test my LLM applications?\"),\n",
        "            AIMessage(\n",
        "                content=\"Yes, LangSmith can help test and evaluate your LLM applications. It allows you to quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs. Additionally, LangSmith can be used to monitor your application, log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise.\"\n",
        "            ),\n",
        "            HumanMessage(content=\"Tell me more!\"),\n",
        "        ],\n",
        "    }\n",
        ")\n",
        "\n",
        "for chunk in stream:\n",
        "    print(chunk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 更多阅读\n\n本指南仅初步介绍了检索技术。有关摄取、准备和检索最相关数据的不同方法，请在此处的[相关操作指南](/docs/how_to#document-loaders)中查看。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}