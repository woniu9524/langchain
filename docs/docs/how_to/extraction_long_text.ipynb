{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9e161a8a-fcf0-4d55-933e-da271ce28d7e",
      "metadata": {},
      "source": [
        "# 如何处理长文本进行提取\n\n当处理像 PDF 这样的文件时，你可能会遇到文本长度超出语言模型上下文窗口的情况。要处理这类文本，可以考虑以下策略：\n\n1. **更换 LLM** 选择一个支持更大上下文窗口的不同 LLM。\n2. **暴力破解** 将文档分块，并从每个块中提取内容。\n3. **RAG** 将文档分块，对分块进行索引，并且只从看起来“相关”的块子集中提取内容。\n\n请记住，这些策略有不同的权衡取舍，最佳策略可能取决于你设计的应用程序！\n\n本指南演示了如何实现策略 2 和 3。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57969139-ad0a-487e-97d8-cb30e2af9742",
      "metadata": {},
      "source": [
        "## 设置\n\n首先，我们将安装本指南所需的依赖项："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a3b4d838-5be4-4207-8a4a-9ef5624c48f2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-10T20:35:19.850767Z",
          "iopub.status.busy": "2024-09-10T20:35:19.850427Z",
          "iopub.status.idle": "2024-09-10T20:35:21.432233Z",
          "shell.execute_reply": "2024-09-10T20:35:21.431606Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -qU langchain-community lxml faiss-cpu langchain-openai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac000b03-33fc-414f-8f2c-3850df621a35",
      "metadata": {},
      "source": [
        "现在我们需要一些示例数据！让我们从 Wikipedia 下载一篇关于[汽车](https://en.wikipedia.org/wiki/Car)的文章，并将其加载为 LangChain 的 [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "84460db2-36e1-4037-bfa6-2a11883c2ba5",
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "import requests\n",
        "from langchain_community.document_loaders import BSHTMLLoader\n",
        "\n",
        "# Download the content\n",
        "response = requests.get(\"https://en.wikipedia.org/wiki/Car\")\n",
        "# Write it to a file\n",
        "with open(\"car.html\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(response.text)\n",
        "# Load it with an HTML parser\n",
        "loader = BSHTMLLoader(\"car.html\")\n",
        "document = loader.load()[0]\n",
        "# Clean up code\n",
        "# Replace consecutive new lines with a single new line\n",
        "document.page_content = re.sub(\"\\n\\n+\", \"\\n\", document.page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fcb6917b-123d-4630-a0ce-ed8b293d482d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "78865\n"
          ]
        }
      ],
      "source": [
        "print(len(document.page_content))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af3ffb8d-587a-4370-886a-e56e617bcb9c",
      "metadata": {},
      "source": [
        "## 定义模式\n\n遵循[提取教程](/docs/tutorials/extraction)，我们将使用 Pydantic 来定义我们希望提取的信息的模式。在这种情况下，我们将提取一系列“关键进展”（例如重要的历史事件），其中包含年份和描述。\n\n请注意，我们还包含了一个 `evidence` 键，并指示模型 verbatim 提供文章中的相关句子。这使我们能够将提取结果与（模型重建的）原始文档中的文本进行比较。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a3b288ed-87a6-4af0-aac8-20921dc370d4",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import List, Optional\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "\n",
        "class KeyDevelopment(BaseModel):\n",
        "    \"\"\"Information about a development in the history of cars.\"\"\"\n",
        "\n",
        "    year: int = Field(\n",
        "        ..., description=\"The year when there was an important historic development.\"\n",
        "    )\n",
        "    description: str = Field(\n",
        "        ..., description=\"What happened in this year? What was the development?\"\n",
        "    )\n",
        "    evidence: str = Field(\n",
        "        ...,\n",
        "        description=\"Repeat in verbatim the sentence(s) from which the year and description information were extracted\",\n",
        "    )\n",
        "\n",
        "\n",
        "class ExtractionData(BaseModel):\n",
        "    \"\"\"Extracted information about key developments in the history of cars.\"\"\"\n",
        "\n",
        "    key_developments: List[KeyDevelopment]\n",
        "\n",
        "\n",
        "# Define a custom prompt to provide instructions and any additional context.\n",
        "# 1) You can add examples into the prompt template to improve extraction quality\n",
        "# 2) Introduce additional parameters to take context into account (e.g., include metadata\n",
        "#    about the document from which the text was extracted.)\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are an expert at identifying key historic development in text. \"\n",
        "            \"Only extract important historic developments. Extract nothing if no important information can be found in the text.\",\n",
        "        ),\n",
        "        (\"human\", \"{text}\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3909e22e-8a00-4f3d-bbf2-4762a0558af3",
      "metadata": {},
      "source": [
        "## 创建提取器\n\n让我们选择一个 LLM。由于我们正在使用工具调用，因此需要一个支持工具调用功能的模型。请参阅[此表](/docs/integrations/chat)了解可用的 LLM。\n\nimport ChatModelTabs from \"@theme/ChatModelTabs\";\n\n<ChatModelTabs\n  customVarName=\"llm\"\n  overrideParams={{openai: {model: \"gpt-4o\", kwargs: \"temperature=0\"}}}\n/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "109f4f05-d0ff-431d-93d9-8f5aa34979a6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# | output: false\n",
        "# | echo: false\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "aa4ae224-6d3d-4fe2-b210-7db19a9fe580",
      "metadata": {},
      "outputs": [],
      "source": [
        "extractor = prompt | llm.with_structured_output(\n",
        "    schema=ExtractionData,\n",
        "    include_raw=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13aebafb-26b5-42b2-ae8e-9c05cd56e5c5",
      "metadata": {},
      "source": [
        "## 暴力破解方法\n\n将文档分割成块，使每个块都能放入 LLM 的上下文窗口。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "27b8a373-14b3-45ea-8bf5-9749122ad927",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_text_splitters import TokenTextSplitter\n",
        "\n",
        "text_splitter = TokenTextSplitter(\n",
        "    # Controls the size of each chunk\n",
        "    chunk_size=2000,\n",
        "    # Controls overlap between chunks\n",
        "    chunk_overlap=20,\n",
        ")\n",
        "\n",
        "texts = text_splitter.split_text(document.page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b43d7e0-3c85-4d97-86c7-e8c984b60b0a",
      "metadata": {},
      "source": [
        "使用 [batch](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html) 功能在**并行**模式下运行跨每个块的提取！\n\n:::tip\n您通常可以使用 .batch() 来并行化提取！`.batch` 在底层使用线程池来帮助您并行化工作负载。\n\n如果您的模型是通过 API 公开的，这很可能会加快您的提取流程！\n:::"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6ba766b5-8d6c-48e6-8d69-f391a66b65d2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Limit just to the first 3 chunks\n",
        "# so the code can be re-run quickly\n",
        "first_few = texts[:3]\n",
        "\n",
        "extractions = extractor.batch(\n",
        "    [{\"text\": text} for text in first_few],\n",
        "    {\"max_concurrency\": 5},  # limit the concurrency by passing max concurrency!\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67da8904-e927-406b-a439-2a16f6087ccf",
      "metadata": {},
      "source": [
        "### 合并结果\n\n在从所有分块中提取数据之后，我们需要将这些提取结果合并在一起。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3c118525-97cb-4f07-a5ec-5c053dca6ed2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[KeyDevelopment(year=1769, description='Nicolas-Joseph Cugnot built the first steam-powered road vehicle.', evidence='The French inventor Nicolas-Joseph Cugnot built the first steam-powered road vehicle in 1769, while the Swiss inventor François Isaac de Rivaz designed and constructed the first internal combustion-powered automobile in 1808.'),\n",
              " KeyDevelopment(year=1808, description='François Isaac de Rivaz designed and constructed the first internal combustion-powered automobile.', evidence='The French inventor Nicolas-Joseph Cugnot built the first steam-powered road vehicle in 1769, while the Swiss inventor François Isaac de Rivaz designed and constructed the first internal combustion-powered automobile in 1808.'),\n",
              " KeyDevelopment(year=1886, description='Carl Benz invented the modern car, a practical, marketable automobile for everyday use, and patented his Benz Patent-Motorwagen.', evidence='The modern car—a practical, marketable automobile for everyday use—was invented in 1886, when the German inventor Carl Benz patented his Benz Patent-Motorwagen.'),\n",
              " KeyDevelopment(year=1901, description='The Oldsmobile Curved Dash became the first mass-produced car.', evidence='The 1901 Oldsmobile Curved Dash and the 1908 Ford Model T, both American cars, are widely considered the first mass-produced[3][4] and mass-affordable[5][6][7] cars, respectively.'),\n",
              " KeyDevelopment(year=1908, description='The Ford Model T became the first mass-affordable car.', evidence='The 1901 Oldsmobile Curved Dash and the 1908 Ford Model T, both American cars, are widely considered the first mass-produced[3][4] and mass-affordable[5][6][7] cars, respectively.'),\n",
              " KeyDevelopment(year=1885, description='Carl Benz built the original Benz Patent-Motorwagen, the first modern car.', evidence='The original Benz Patent-Motorwagen, the first modern car, built in 1885 and awarded the patent for the concept'),\n",
              " KeyDevelopment(year=1881, description='Gustave Trouvé demonstrated a three-wheeled car powered by electricity.', evidence='In November 1881, French inventor Gustave Trouvé demonstrated a three-wheeled car powered by electricity at the International Exposition of Electricity.'),\n",
              " KeyDevelopment(year=1888, description=\"Bertha Benz undertook the first road trip by car to prove the road-worthiness of her husband's invention.\", evidence=\"In August 1888, Bertha Benz, the wife and business partner of Carl Benz, undertook the first road trip by car, to prove the road-worthiness of her husband's invention.\"),\n",
              " KeyDevelopment(year=1896, description='Benz designed and patented the first internal-combustion flat engine, called boxermotor.', evidence='In 1896, Benz designed and patented the first internal-combustion flat engine, called boxermotor.'),\n",
              " KeyDevelopment(year=1897, description='The first motor car in central Europe and one of the first factory-made cars in the world was produced by Czech company Nesselsdorfer Wagenbau (later renamed to Tatra), the Präsident automobil.', evidence='The first motor car in central Europe and one of the first factory-made cars in the world, was produced by Czech company Nesselsdorfer Wagenbau (later renamed to Tatra) in 1897, the Präsident automobil.')]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "key_developments = []\n",
        "\n",
        "for extraction in extractions:\n",
        "    key_developments.extend(extraction.key_developments)\n",
        "\n",
        "key_developments[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48afd4a7-abcd-48b4-8ff1-6ca485f529e3",
      "metadata": {},
      "source": [
        "## 基于 RAG 的方法\n\n另一个简单的想法是将文本分块，但不是从每个块中提取信息，而是只关注最相关的块。\n\n:::caution\n确定哪些块是相关的可能很困难。\n\n例如，在我们这里使用的 `car` 文章中，文章的大部分都包含关键的开发信息。因此，使用\n**RAG**，我们可能会舍弃大量相关信息。\n\n我们建议根据你的用例进行实验，并确定此方法是否有效。\n:::\n\n要实现基于 RAG 的方法：\n\n1.  将你的文档分块并建立索引（例如，在向量数据库中）；\n2.  在 `extractor` 链前面添加一个使用向量数据库的检索步骤。\n\n下面是一个依赖于 `FAISS` 向量数据库的简单示例。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "aaf37c82-625b-4fa1-8e88-73303f08ac16",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "\n",
        "texts = text_splitter.split_text(document.page_content)\n",
        "vectorstore = FAISS.from_texts(texts, embedding=OpenAIEmbeddings())\n",
        "\n",
        "retriever = vectorstore.as_retriever(\n",
        "    search_kwargs={\"k\": 1}\n",
        ")  # Only extract from first document"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "013ecad9-f80f-477c-b954-494b46a02a07",
      "metadata": {},
      "source": [
        "在这种情况下，RAG 提取器只查看顶层文档。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "47aad00b-7013-4f7f-a1b0-02ef269093bf",
      "metadata": {},
      "outputs": [],
      "source": [
        "rag_extractor = {\n",
        "    \"text\": retriever | (lambda docs: docs[0].page_content)  # fetch content of top doc\n",
        "} | extractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "68f2de01-0cd8-456e-a959-db236189d41b",
      "metadata": {},
      "outputs": [],
      "source": [
        "results = rag_extractor.invoke(\"Key developments associated with cars\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "1788e2d6-77bb-417f-827c-eb96c035164e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-09-10T20:35:43.200497Z",
          "iopub.status.busy": "2024-09-10T20:35:43.200037Z",
          "iopub.status.idle": "2024-09-10T20:35:43.206773Z",
          "shell.execute_reply": "2024-09-10T20:35:43.205426Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "year=2006 description='Car-sharing services in the US experienced double-digit growth in revenue and membership.' evidence='in the US, some car-sharing services have experienced double-digit growth in revenue and membership growth between 2006 and 2007.'\n",
            "year=2020 description='56 million cars were manufactured worldwide, with China producing the most.' evidence='In 2020, there were 56 million cars manufactured worldwide, down from 67 million the previous year. The automotive industry in China produces by far the most (20 million in 2020).'\n"
          ]
        }
      ],
      "source": [
        "for key_development in results.key_developments:\n",
        "    print(key_development)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf36e626-cf5d-4324-ba29-9bd602be9b97",
      "metadata": {},
      "source": [
        "## 常见问题\n\n不同的方法在成本、速度和准确性方面都有各自的优缺点。\n\n请注意以下问题：\n\n*   分块处理内容意味着，如果信息分散在多个块中，大型语言模型（LLM）可能无法提取信息。\n*   较大的块重叠可能会导致同一信息被提取两次，因此请做好去重的准备！\n*   大型语言模型（LLM）可能会编造数据。如果寻找大段文本中的单个事实并使用暴力方法，您可能会得到更多编造的数据。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}