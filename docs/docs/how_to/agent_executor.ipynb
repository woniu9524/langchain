{
  "cells": [
    {
      "cell_type": "raw",
      "id": "17546ebb",
      "metadata": {},
      "source": [
        "---\n",
        "sidebar_position: 4\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4c03f40-1328-412d-8a48-1db0cd481b77",
      "metadata": {},
      "source": [
        "# 使用 AgentExecutor (旧版) 构建 Agent\n\n:::important\n本节将介绍如何使用旧版的 LangChain AgentExecutor 进行构建。虽说它们适合入门，但一旦超越某个阶段，你可能会发现它们在灵活性和控制力方面无法满足你的需求。对于更高级的 Agent，我们建议你查阅 [LangGraph Agents](/docs/concepts/architecture/#langgraph) 或 [迁移指南](/docs/how_to/migrate_agent/)。\n:::\n\n语言模型本身无法执行操作，它们只会输出文本。\nLangChain 的一个重要用例是创建 **[agents](/docs/concepts/agents/)**。\nAgents 是利用 LLM 作为推理引擎，来决定执行何种操作以及这些操作的输入是什么的系统。\n这些操作的结果随后可以反馈给 Agent，它会决定是否需要执行更多操作，或者是否可以结束。\n\n在本教程中，我们将构建一个能够与多个不同工具交互的 Agent：其中一个是本地数据库，另一个是搜索引擎。你将能够向这个 Agent 提问，观察它调用工具，并与它进行对话。\n\n## 概念\n\n我们将涵盖的概念包括：\n- 使用 [语言模型](/docs/concepts/chat_models)，特别是它们的工具调用能力\n- 创建一个 [Retriever](/docs/concepts/retrievers) 以向我们的 Agent 暴露特定信息\n- 使用搜索 [Tool](/docs/concepts/tools) 在网上查找内容\n- [`Chat History`](/docs/concepts/chat_history)，它允许聊天机器人“记住”过去的交互，并在回应后续问题时将其考虑在内。\n- 使用 [LangSmith](https://docs.smith.langchain.com/) 进行应用程序的调试和追踪\n\n## 设置\n\n### Jupyter Notebook\n\n本指南（以及文档中的大多数其他指南）使用 [Jupyter notebooks](https://jupyter.org/)，并假设读者也在使用。Jupyter notebooks 非常适合学习如何使用 LLM 系统，因为事情常常会出错（意外输出、API 宕机等），而在交互式环境中学习指南是更好地理解它们的绝佳方式。\n\n本教程及其他教程最好在 Jupyter notebook 中运行。请参阅 [此处](https://jupyter.org/install) 查看安装说明。\n\n### 安装\n\n要安装 LangChain，请运行：\n\nimport Tabs from '@theme/Tabs';\nimport TabItem from '@theme/TabItem';\nimport CodeBlock from \"@theme/CodeBlock\";\n\n<Tabs>\n  <TabItem value=\"pip\" label=\"Pip\" default>\n    <CodeBlock language=\"bash\">pip install langchain</CodeBlock>\n  </TabItem>\n  <TabItem value=\"conda\" label=\"Conda\">\n    <CodeBlock language=\"bash\">conda install langchain -c conda-forge</CodeBlock>\n  </TabItem>\n</Tabs>\n\n有关更多详细信息，请参阅我们的 [安装指南](/docs/how_to/installation)。\n\n### LangSmith\n\n你用 LangChain 构建的许多应用程序将包含多个步骤以及多次 LLM 调用。\n随着这些应用程序变得越来越复杂，能够检查你的 Chain 或 Agent 内部到底发生了什么变得至关重要。\n做到这一点最好的方法就是使用 [LangSmith](https://smith.langchain.com)。\n\n在上面的链接注册后，请确保设置你的环境变量以开始记录追踪：\n\n```shell\nexport LANGSMITH_TRACING=\"true\"\nexport LANGSMITH_API_KEY=\"...\"\n```\n\n或者，如果你在 notebook 中，你可以用以下方式设置它们：\n\n```python\nimport getpass\nimport os\n\nos.environ[\"LANGSMITH_TRACING\"] = \"true\"\nos.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()\n```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c335d1bf",
      "metadata": {},
      "source": [
        "## 定义工具\n\n我们首先需要创建想要使用的工具。我们将使用两个工具：[Tavily](/docs/integrations/tools/tavily_search)（用于在线搜索）以及一个我们稍后创建的本地索引的检索器。\n\n### [Tavily](/docs/integrations/tools/tavily_search)\n\nLangChain 内置了一个工具，可以轻松地将 Tavily 搜索引擎用作工具。\n请注意，这需要一个 API 密钥——它们提供免费套餐，但如果你没有或不想创建一个，可以随时忽略此步骤。\n\n创建 API 密钥后，你需要将其导出为：\n\n```bash\nexport TAVILY_API_KEY=\"...\"\n```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "482ce13d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9cc86c0b",
      "metadata": {},
      "outputs": [],
      "source": [
        "search = TavilySearchResults(max_results=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e593bbf6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'url': 'https://www.weatherapi.com/',\n",
              "  'content': \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.78, 'lon': -122.42, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1714000492, 'localtime': '2024-04-24 16:14'}, 'current': {'last_updated_epoch': 1713999600, 'last_updated': '2024-04-24 16:00', 'temp_c': 15.6, 'temp_f': 60.1, 'is_day': 1, 'condition': {'text': 'Overcast', 'icon': '//cdn.weatherapi.com/weather/64x64/day/122.png', 'code': 1009}, 'wind_mph': 10.5, 'wind_kph': 16.9, 'wind_degree': 330, 'wind_dir': 'NNW', 'pressure_mb': 1018.0, 'pressure_in': 30.06, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 72, 'cloud': 100, 'feelslike_c': 15.6, 'feelslike_f': 60.1, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 5.0, 'gust_mph': 14.8, 'gust_kph': 23.8}}\"},\n",
              " {'url': 'https://www.weathertab.com/en/c/e/04/united-states/california/san-francisco/',\n",
              "  'content': 'San Francisco Weather Forecast for Apr 2024 - Risk of Rain Graph. Rain Risk Graph: Monthly Overview. Bar heights indicate rain risk percentages. Yellow bars mark low-risk days, while black and grey bars signal higher risks. Grey-yellow bars act as buffers, advising to keep at least one day clear from the riskier grey and black days, guiding ...'}]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "search.invoke(\"what is the weather in SF\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8097977",
      "metadata": {},
      "source": [
        "### Retriever\n\n我们还将创建一个检索器来处理我们自己的数据。有关此处每个步骤的更深入的解释，请参阅[此教程](/docs/tutorials/rag)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9c9ce713",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n",
        "docs = loader.load()\n",
        "documents = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000, chunk_overlap=200\n",
        ").split_documents(docs)\n",
        "vector = FAISS.from_documents(documents, OpenAIEmbeddings())\n",
        "retriever = vector.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "dae53ec6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content='# The data to predict and grade over    evaluators=[exact_match], # The evaluators to score the results    experiment_prefix=\"sample-experiment\", # The name of the experiment    metadata={      \"version\": \"1.0.0\",      \"revision_id\": \"beta\"    },)import { Client, Run, Example } from \\'langsmith\\';import { runOnDataset } from \\'langchain/smith\\';import { EvaluationResult } from \\'langsmith/evaluation\\';const client = new Client();// Define dataset: these are your test casesconst datasetName = \"Sample Dataset\";const dataset = await client.createDataset(datasetName, {    description: \"A sample dataset in LangSmith.\"});await client.createExamples({    inputs: [        { postfix: \"to LangSmith\" },        { postfix: \"to Evaluations in LangSmith\" },    ],    outputs: [        { output: \"Welcome to LangSmith\" },        { output: \"Welcome to Evaluations in LangSmith\" },    ],    datasetId: dataset.id,});// Define your evaluatorconst exactMatch = async ({ run, example }: { run: Run; example?:', metadata={'source': 'https://docs.smith.langchain.com/overview', 'title': 'Getting started with LangSmith | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'Introduction', 'language': 'en'})"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever.invoke(\"how to upload a dataset\")[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04aeca39",
      "metadata": {},
      "source": [
        "现在我们已经填充了我们将要进行检索的索引，我们可以轻松地将其变成一个工具（代理程序需要正确使用它的格式）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "117594b5",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.tools.retriever import create_retriever_tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7280b031",
      "metadata": {},
      "outputs": [],
      "source": [
        "retriever_tool = create_retriever_tool(\n",
        "    retriever,\n",
        "    \"langsmith_search\",\n",
        "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3b47c1d",
      "metadata": {},
      "source": [
        "### 工具\n\n现在我们已经创建了两者，我们可以创建一个下游将要使用的工具列表。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b8e8e710",
      "metadata": {},
      "outputs": [],
      "source": [
        "tools = [search, retriever_tool]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e00068b0",
      "metadata": {},
      "source": [
        "## 使用语言模型\n\n接下来，我们将学习如何使用语言模型调用工具。LangChain 支持许多不同的语言模型，您可以互换使用它们——在下方选择您想使用的模型！\n\nimport ChatModelTabs from \"@theme/ChatModelTabs\";\n\n<ChatModelTabs overrideParams={{openai: {model: \"gpt-4\"}}} />"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "69185491",
      "metadata": {},
      "outputs": [],
      "source": [
        "# | output: false\n",
        "# | echo: false\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "642ed8bf",
      "metadata": {},
      "source": [
        "您可以向语言模型传递消息列表来调用它。默认情况下，响应是 `content` 字符串。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c96c960b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Hello! How can I assist you today?'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "response = model.invoke([HumanMessage(content=\"hi!\")])\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47bf8210",
      "metadata": {},
      "source": [
        "现在我们可以了解启用此模型进行工具调用的情况了。为了实现这一点，我们使用 `.bind_tools` 来使语言模型了解这些工具。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ba692a74",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_with_tools = model.bind_tools(tools)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd920b69",
      "metadata": {},
      "source": [
        "现在我们可以调用模型了。让我们先用一个普通消息调用它，看看它如何回应。我们可以同时查看 `content` 字段和 `tool_calls` 字段。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b6a7e925",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ContentString: Hello! How can I assist you today?\n",
            "ToolCalls: []\n"
          ]
        }
      ],
      "source": [
        "response = model_with_tools.invoke([HumanMessage(content=\"Hi!\")])\n",
        "\n",
        "print(f\"ContentString: {response.content}\")\n",
        "print(f\"ToolCalls: {response.tool_calls}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8c81e76",
      "metadata": {},
      "source": [
        "现在，让我们尝试使用一些期望调用工具的输入来调用它。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "688b465d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ContentString: \n",
            "ToolCalls: [{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'call_4HteVahXkRAkWjp6dGXryKZX'}]\n"
          ]
        }
      ],
      "source": [
        "response = model_with_tools.invoke([HumanMessage(content=\"What's the weather in SF?\")])\n",
        "\n",
        "print(f\"ContentString: {response.content}\")\n",
        "print(f\"ToolCalls: {response.tool_calls}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83c4bcd3",
      "metadata": {},
      "source": [
        "我们可以看到，现在没有内容了，但有一个工具调用！它要求我们调用 Tavily Search 工具。\n\n这还不是在调用该工具——它只是在告诉我们要调用它。为了实际调用它，我们需要创建我们的代理。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40ccec80",
      "metadata": {},
      "source": [
        "## 创建代理\n\n现在我们已经定义了工具和 LLM，就可以创建代理了。我们将使用一个工具调用代理——关于这种类型的代理以及其他选项的更多信息，请参阅[本指南](/docs/concepts/agents/)。\n\n我们可以首先选择用于指导代理的提示。\n\n如果你想查看此提示的内容并访问 LangSmith，可以转到：\n\n[https://smith.langchain.com/hub/hwchase17/openai-functions-agent](https://smith.langchain.com/hub/hwchase17/openai-functions-agent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "af83d3e3",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
              " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
              " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
              " MessagesPlaceholder(variable_name='agent_scratchpad')]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain import hub\n",
        "\n",
        "# Get the prompt to use - you can modify this!\n",
        "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
        "prompt.messages"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8014c9d",
      "metadata": {},
      "source": [
        "现在，我们可以初始化代理（agent）的 LLM、提示（prompt）和工具（tools）。代理负责接收输入并决定采取什么行动。至关重要的是，代理本身并不执行这些行动——这些行动将由 AgentExecutor 来执行（下一步骤）。有关如何理解这些组件的更多信息，请参阅我们的[概念指南](/docs/concepts/agents)。\n\n请注意，我们传递的是 `model`，而不是 `model_with_tools`。这是因为 `create_tool_calling_agent` 会在后台为我们调用 `.bind_tools`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "89cf72b4-6046-4b47-8f27-5522d8cb8036",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents import create_tool_calling_agent\n",
        "\n",
        "agent = create_tool_calling_agent(model, tools, prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a58c9f8",
      "metadata": {},
      "source": [
        "最后，我们将 Agent（大脑）和工具组合在 AgentExecutor 中（它将反复调用 Agent 并执行工具）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "ce33904a",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents import AgentExecutor\n",
        "\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4df0e06",
      "metadata": {},
      "source": [
        "## 运行代理\n\n现在我们可以对一些查询运行代理了！请注意，目前这些都是**无状态**查询（它不会记住之前的交互）。\n\n首先，让我们看看在不需要调用工具时它的响应："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "114ba50d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input': 'hi!', 'output': 'Hello! How can I assist you today?'}"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent_executor.invoke({\"input\": \"hi!\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71493a42",
      "metadata": {},
      "source": [
        "为了准确了解幕后发生的情况（并确保它没有调用工具），我们可以查看一下 LangSmith 跟踪： [LangSmith trace](https://smith.langchain.com/public/8441812b-94ce-4832-93ec-e1114214553a/r)\n\n现在让我们在它应该调用检索器的示例上进行尝试。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "3fa4780a",
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input': 'how can langsmith help with testing?',\n",
              " 'output': 'LangSmith is a platform that aids in building production-grade Language Learning Model (LLM) applications. It can assist with testing in several ways:\\n\\n1. **Monitoring and Evaluation**: LangSmith allows close monitoring and evaluation of your application. This helps you to ensure the quality of your application and deploy it with confidence.\\n\\n2. **Tracing**: LangSmith has tracing capabilities that can be beneficial for debugging and understanding the behavior of your application.\\n\\n3. **Evaluation Capabilities**: LangSmith has built-in tools for evaluating the performance of your LLM. \\n\\n4. **Prompt Hub**: This is a prompt management tool built into LangSmith that can help in testing different prompts and their responses.\\n\\nPlease note that to use LangSmith, you would need to install it and create an API key. The platform offers Python and Typescript SDKs for utilization. It works independently and does not require the use of LangChain.'}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent_executor.invoke({\"input\": \"how can langsmith help with testing?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2d94242",
      "metadata": {},
      "source": [
        "让我们看一下 [LangSmith trace](https://smith.langchain.com/public/762153f6-14d4-4c98-8659-82650f860c62/r)，以确保它确实调用了该工具。\n\n现在我们来试试需要调用搜索工具的一个："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "77c2f769",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input': 'whats the weather in sf?',\n",
              " 'output': 'The current weather in San Francisco is partly cloudy with a temperature of 16.1°C (61.0°F). The wind is coming from the WNW at a speed of 10.5 mph. The humidity is at 67%. [source](https://www.weatherapi.com/)'}"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent_executor.invoke({\"input\": \"whats the weather in sf?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c174f838",
      "metadata": {},
      "source": [
        "我们可以查看 [LangSmith trace](https://smith.langchain.com/public/36df5b1a-9a0b-4185-bae2-964e1d53c665/r) 来确保它有效地调用了搜索工具。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "022cbc8a",
      "metadata": {},
      "source": [
        "## 添加记忆\n\n如前所述，该代理是无状态的。这意味着它不记得之前的交互。为了给它记忆，我们需要传入先前的 `chat_history`。注意：由于我们使用的提示，它必须被命名为 `chat_history`。如果我们使用不同的提示，可以更改变量名。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "c4073e35",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input': 'hi! my name is bob',\n",
              " 'chat_history': [],\n",
              " 'output': 'Hello Bob! How can I assist you today?'}"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Here we pass in an empty list of messages for chat_history because it is the first message in the chat\n",
        "agent_executor.invoke({\"input\": \"hi! my name is bob\", \"chat_history\": []})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "9dc5ed68",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.messages import AIMessage, HumanMessage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "550e0c6e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'chat_history': [HumanMessage(content='hi! my name is bob'),\n",
              "  AIMessage(content='Hello Bob! How can I assist you today?')],\n",
              " 'input': \"what's my name?\",\n",
              " 'output': 'Your name is Bob. How can I assist you further?'}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent_executor.invoke(\n",
        "    {\n",
        "        \"chat_history\": [\n",
        "            HumanMessage(content=\"hi! my name is bob\"),\n",
        "            AIMessage(content=\"Hello Bob! How can I assist you today?\"),\n",
        "        ],\n",
        "        \"input\": \"what's my name?\",\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07b3bcf2",
      "metadata": {},
      "source": [
        "如果我们想自动跟踪这些消息，我们可以将其包装在 `RunnableWithMessageHistory` 中。有关如何使用它的更多信息，请参阅[本指南](/docs/how_to/message_history)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "8edd96e6",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "store = {}\n",
        "\n",
        "\n",
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] = ChatMessageHistory()\n",
        "    return store[session_id]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c450d6a5",
      "metadata": {},
      "source": [
        "因为我们有多个输入，所以需要指定两件事：\n\n- `input_messages_key`: 用于添加到对话历史记录的输入键。\n- `history_messages_key`: 用于将加载的消息添加到的键。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "828d1e95",
      "metadata": {},
      "outputs": [],
      "source": [
        "agent_with_chat_history = RunnableWithMessageHistory(\n",
        "    agent_executor,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"chat_history\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "1f5932b6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input': \"hi! I'm bob\",\n",
              " 'chat_history': [],\n",
              " 'output': 'Hello Bob! How can I assist you today?'}"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent_with_chat_history.invoke(\n",
        "    {\"input\": \"hi! I'm bob\"},\n",
        "    config={\"configurable\": {\"session_id\": \"<foo>\"}},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "ae627966",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input': \"what's my name?\",\n",
              " 'chat_history': [HumanMessage(content=\"hi! I'm bob\"),\n",
              "  AIMessage(content='Hello Bob! How can I assist you today?')],\n",
              " 'output': 'Your name is Bob.'}"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent_with_chat_history.invoke(\n",
        "    {\"input\": \"what's my name?\"},\n",
        "    config={\"configurable\": {\"session_id\": \"<foo>\"}},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6de2798e",
      "metadata": {},
      "source": [
        "示例 LangSmith trace：https://smith.langchain.com/public/98c8d162-60ae-4493-aa9f-992d87bd0429/r"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c029798f",
      "metadata": {},
      "source": [
        "## 结论\n\n本次教程到此结束！在这个快速入门指南中，我们学习了如何创建一个简单的代理。代理是一个复杂的话题，还有很多内容值得学习！\n\n:::important\n本节介绍了如何使用 LangChain Agents 进行构建。它们对于入门来说很不错，但达到一定程度后，您很可能会需要它们不提供的灵活性和控制力。要开发更高级的代理，我们建议您查看 [LangGraph](/docs/concepts/architecture/#langgraph)\n:::\n\n如果您想继续使用 LangChain 代理，以下是一些优秀的进阶指南：\n\n- [如何使用 LangGraph 的内置版本 `AgentExecutor`](/docs/how_to/migrate_agent)\n- [如何创建自定义代理](https://python.langchain.com/v0.1/docs/modules/agents/how_to/custom_agent/)\n- [如何从代理流式传输响应](https://python.langchain.com/v0.1/docs/modules/agents/how_to/streaming/)\n- [如何从代理返回结构化输出](https://python.langchain.com/v0.1/docs/modules/agents/how_to/agent_structured/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3ec3244",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}