{
  "cells": [
    {
      "cell_type": "raw",
      "id": "38831021-76ed-48b3-9f62-d1241a68b6ad",
      "metadata": {},
      "source": [
        "---\n",
        "sidebar_position: 3\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a745f98b-c495-44f6-a882-757c38992d76",
      "metadata": {},
      "source": [
        "# 如何使用输出解析器将 LLM 响应解析为结构化格式\n\n语言模型输出文本。但有时您希望获取比纯文本更结构化的信息。虽然一些模型提供商支持[返回结构化输出的内置方法](/docs/how_to/structured_output)，但并非所有提供商都支持。\n\n[输出解析器](/docs/concepts/output_parsers/) 是帮助结构化语言模型响应的类。输出解析器必须实现两个主要方法：\n\n- \"Get format instructions\"：一个返回字符串的方法，其中包含有关如何格式化语言模型输出的说明。\n- \"Parse\"：一个接收字符串（假定为语言模型的响应）并将其解析为某种结构的方法。\n\n然后还有一个可选方法：\n\n- \"Parse with prompt\"：一个接收字符串（假定为语言模型的响应）和提示（假定为生成该响应的提示）并将其解析为某种结构的方法。提供提示主要是为了在 OutputParser 想要重试或修复输出时，需要提示中的信息来执行此操作。\n\n## 入门\n\n下面我们介绍主要的输出解析器类型 `PydanticOutputParser`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3ad71dfb-e247-459d-b4ae-cb14964ea872",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Joke(setup='Why did the tomato turn red?', punchline='Because it saw the salad dressing!')"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import OpenAI\n",
        "from pydantic import BaseModel, Field, model_validator\n",
        "\n",
        "model = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0.0)\n",
        "\n",
        "\n",
        "# Define your desired data structure.\n",
        "class Joke(BaseModel):\n",
        "    setup: str = Field(description=\"question to set up a joke\")\n",
        "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
        "\n",
        "    # You can add custom validation logic easily with Pydantic.\n",
        "    @model_validator(mode=\"before\")\n",
        "    @classmethod\n",
        "    def question_ends_with_question_mark(cls, values: dict) -> dict:\n",
        "        setup = values.get(\"setup\")\n",
        "        if setup and setup[-1] != \"?\":\n",
        "            raise ValueError(\"Badly formed question!\")\n",
        "        return values\n",
        "\n",
        "\n",
        "# Set up a parser + inject instructions into the prompt template.\n",
        "parser = PydanticOutputParser(pydantic_object=Joke)\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
        "    input_variables=[\"query\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "# And a query intended to prompt a language model to populate the data structure.\n",
        "prompt_and_model = prompt | model\n",
        "output = prompt_and_model.invoke({\"query\": \"Tell me a joke.\"})\n",
        "parser.invoke(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75976cd6-78e2-458b-821f-3ddf3683466b",
      "metadata": {},
      "source": [
        "## LCEL\n\n输出解析器实现了 [Runnable 接口](/docs/concepts/runnables)，这是 [LangChain Expression Language (LCEL)](/docs/concepts/lcel) 的基本构建块。这意味着它们支持 `invoke`、`ainvoke`、`stream`、`astream`、`batch`、`abatch`、`astream_log` 调用。\n\n输出解析器接受字符串或 `BaseMessage` 作为输入，并可以返回任意类型。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "34f7ff0c-8443-4eb9-8704-b4f821811d93",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Joke(setup='Why did the tomato turn red?', punchline='Because it saw the salad dressing!')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parser.invoke(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdebf4a5-57a8-4632-bd17-56723d431cf1",
      "metadata": {},
      "source": [
        "我们可以不手动调用解析器，而是将其添加到我们的 `Runnable` 序列中："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "51f7fff5-e9bd-49a1-b5ab-b9ff281b93cb",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Joke(setup='Why did the tomato turn red?', punchline='Because it saw the salad dressing!')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain = prompt | model | parser\n",
        "chain.invoke({\"query\": \"Tell me a joke.\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d88590a0-f36b-4ad5-8a56-d300971a6440",
      "metadata": {},
      "source": [
        "尽管所有解析器都支持流式接口，但只有特定的解析器能够通过部分解析的对象进行流式传输，因为这在很大程度上取决于输出类型。无法构造部分对象的解析器将直接产生完全解析的输出。\n\n例如，`SimpleJsonOutputParser` 可以通过部分输出来进行流式传输："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d7ecfe4d-dae8-4452-98ea-e48bdc498788",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
        "\n",
        "json_prompt = PromptTemplate.from_template(\n",
        "    \"Return a JSON object with an `answer` key that answers the following question: {question}\"\n",
        ")\n",
        "json_parser = SimpleJsonOutputParser()\n",
        "json_chain = json_prompt | model | json_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "cc2b999e-47aa-41f4-ba6a-13b20a204576",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{},\n",
              " {'answer': ''},\n",
              " {'answer': 'Ant'},\n",
              " {'answer': 'Anton'},\n",
              " {'answer': 'Antonie'},\n",
              " {'answer': 'Antonie van'},\n",
              " {'answer': 'Antonie van Lee'},\n",
              " {'answer': 'Antonie van Leeu'},\n",
              " {'answer': 'Antonie van Leeuwen'},\n",
              " {'answer': 'Antonie van Leeuwenho'},\n",
              " {'answer': 'Antonie van Leeuwenhoek'}]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(json_chain.stream({\"question\": \"Who invented the microscope?\"}))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ca23082-c602-4ee8-af8c-a185b1f42bd1",
      "metadata": {},
      "source": [
        "类似地，对于 `PydanticOutputParser`："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a23b7592-1bda-4d3c-93ed-0e650dfb8d37",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Joke(setup='Why did the tomato turn red?', punchline=''),\n",
              " Joke(setup='Why did the tomato turn red?', punchline='Because'),\n",
              " Joke(setup='Why did the tomato turn red?', punchline='Because it'),\n",
              " Joke(setup='Why did the tomato turn red?', punchline='Because it saw'),\n",
              " Joke(setup='Why did the tomato turn red?', punchline='Because it saw the'),\n",
              " Joke(setup='Why did the tomato turn red?', punchline='Because it saw the salad'),\n",
              " Joke(setup='Why did the tomato turn red?', punchline='Because it saw the salad dressing'),\n",
              " Joke(setup='Why did the tomato turn red?', punchline='Because it saw the salad dressing!')]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(chain.stream({\"query\": \"Tell me a joke.\"}))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}