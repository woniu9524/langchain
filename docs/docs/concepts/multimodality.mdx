# 多模态

## 概述

**多模态**是指处理不同形式数据的能力，例如文本、音频、图像和视频。多模态可以出现在各种组件中，使模型和系统能够无缝地处理和处理这些数据类型的混合。

- **聊天模型**：理论上，它们可以接受和生成多模态输入和输出，处理文本、图像、音频和视频等各种数据类型。
- **嵌入模型**：嵌入模型可以表示多模态内容，将各种形式的数据（如文本、图像和音频）嵌入到向量空间中。
- **向量存储**：向量存储可以搜索表示多模态数据的嵌入，从而实现跨不同类型信息的检索。

## 聊天模型中的多模态

:::info 先决条件
* [聊天模型](/docs/concepts/chat_models)
* [消息](/docs/concepts/messages)
:::
 
LangChain 支持将多模态数据作为聊天模型的输入：

1. 遵循特定提供商的格式
2. 遵守跨提供商的标准（详情请参阅[操作指南](/docs/how_to/#multimodal)）

### 如何使用多模态模型

* 使用[聊天模型集成表](/docs/integrations/chat/)来确定哪些模型支持多模态。
* 参考[相关操作指南](/docs/how_to/#multimodal)了解使用多模态模型的具体示例。

### 支持哪些类型多模态？

#### 输入

某些模型可以接受多模态输入，例如图像、音频、视频或文件。
支持的多模态输入类型取决于模型提供商。例如，
[OpenAI](/docs/integrations/chat/openai/)、
[Anthropic](/docs/integrations/chat/anthropic/) 和
[Google Gemini](/docs/integrations/chat/google_generative_ai/)
支持 PDF 等文档作为输入。

将多模态输入传递给聊天模型的核心是使用指定类型和相应数据的`content`块。例如，将图像作为 URL 传递给聊天模型：

```python
from langchain_core.messages import HumanMessage

message = HumanMessage(
    content=[
        {"type": "text", "text": "Describe the weather in this image:"},
        {
            "type": "image",
            "source_type": "url",
            "url": "https://...",
        },
    ],
)
response = model.invoke([message])
```

我们也可以将图像作为内联数据传递：

```python
from langchain_core.messages import HumanMessage

message = HumanMessage(
    content=[
        {"type": "text", "text": "Describe the weather in this image:"},
        {
            "type": "image",
            "source_type": "base64",
            "data": "<base64 string>",
            "mime_type": "image/jpeg",
        },
    ],
)
response = model.invoke([message])
```

将 PDF 文件作为内联数据（或 URL，如 Anthropic 等提供商所支持）传递，只需将`"type"`更改为`"file"`并将`"mime_type"`更改为`"application/pdf"`。

有关更多详细信息，请参阅[操作指南](/docs/how_to/#multimodal)。

大多数支持多模态**图像**输入的聊天模型也接受 OpenAI 的[聊天补全格式](https://platform.openai.com/docs/guides/images?api-mode=chat)中的这些值：

```python
from langchain_core.messages import HumanMessage

message = HumanMessage(
    content=[
        {"type": "text", "text": "Describe the weather in this image:"},
        {"type": "image_url", "image_url": {"url": image_url}},
    ],
)
response = model.invoke([message])
```

否则，聊天模型通常会接受原生的、特定于提供商的内容块格式。有关特定提供商的详细信息，请参阅[聊天模型集成](/docs/integrations/chat/)。


#### 输出

某些聊天模型支持多模态输出，例如图像和音频。多模态输出将作为 [AIMessage](/docs/concepts/messages/#aimessage) 响应对象的一部分出现。例如：

- 使用 OpenAI 生成[音频输出](/docs/integrations/chat/openai/#audio-generation-preview)；
- 使用 Google Gemini 生成[图像输出](/docs/integrations/chat/google_generative_ai/#multimodal-usage)。

#### 工具

目前，没有聊天模型旨在**直接**与[工具调用请求](/docs/concepts/tool_calling)或 [ToolMessage](/docs/concepts/tool_calling)结果中的多模态数据一起工作。

但是，聊天模型可以通过调用包含多模态数据的引用（例如 URL）的工具，而不是数据本身，来轻松地与多模态数据进行交互。例如，任何能够[工具调用](/docs/concepts/tool_calling)的模型都可以配备下载和处理图像、音频或视频的工具。

## 嵌入模型中的多模态

:::info 先决条件
* [嵌入模型](/docs/concepts/embedding_models)
:::

**嵌入**是用于相似性搜索和检索等任务的数据的向量表示。

LangChain 中使用的当前[嵌入接口](https://python.langchain.com/api_reference/core/embeddings/langchain_core.embeddings.embeddings.Embeddings.html#langchain_core.embeddings.embeddings.Embeddings.Embeddings)完全针对基于文本的数据进行了优化，**不**适用于多模态数据。

随着涉及多模态搜索和检索任务的用例变得越来越普遍，我们 আশা করি 扩展嵌入接口以支持图像、音频和视频等其他数据类型。

## 向量存储中的多模态

:::info 先决条件
* [向量存储](/docs/concepts/vectorstores)
:::

向量存储是用于存储和检索嵌入的数据库，通常用于搜索和检索任务。与嵌入类似，向量存储目前是针对基于文本的数据进行优化的。

随着涉及多模态搜索和检索任务的用例变得越来越普遍，我们 আশা করি 扩展向量存储接口以支持图像、音频和视频等其他数据类型。