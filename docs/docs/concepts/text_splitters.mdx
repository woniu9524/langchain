# 文本分割器
<span data-heading-keywords="text splitter,text splitting"></span>

:::info[必备条件]

* [文档](./retrievers.mdx)
* [分词](./tokens.mdx)
:::

## 概述

文档分割通常是许多应用程序的关键预处理步骤。
它涉及将大型文本分解成更小、更易于管理的数据块。
此过程具有多项优势，例如确保不同文档长度的一致处理、克服模型的输入大小限制，以及提高检索系统中使用的文本表示的质量。
有几种分割文档的策略，每种都有其优点。

## 关键概念

![概念概述](/img/text_splitters.png)

文本分割器会将文档分割成更小的数据块，供下游应用程序使用。

## 为什么要分割文档？

分割文档有几个原因：

- **处理不均匀的文档长度**：真实世界的文档集合通常包含不同大小的文本。分割可确保所有文档的一致处理。
- **克服模型限制**：许多嵌入模型和语言模型都有最大输入大小限制。分割使我们能够处理否则会超出这些限制的文档。
- **提高表示质量**：对于较长的文档，嵌入或其他表示的质量可能会随着它们试图捕获过多的信息而下降。分割可以导致对每个部分进行更专注、更准确的表示。
- **增强检索精度**：在信息检索系统中，分割可以提高搜索结果的粒度，从而更精确地将查询匹配到相关的文档部分。
- **优化计算资源**：处理小文本块在内存方面更有效，并允许更好地并行化处理任务。

现在，下一个问题是如何将文档分割成数据块！有几种策略，每种都有其优点。

:::info[深入阅读]
* 请参阅 Greg Kamradt 的 [chunkviz](https://chunkviz.up.railway.app/) 来可视化下面讨论的不同分割策略。
:::

## 方法

### 基于长度

最直观的策略是根据文本长度来分割文档。这种简单而有效的方法可确保每个数据块不会超过指定的尺寸限制。
基于长度分割的关键优点：
- 实现简单
- 数据块大小一致
- 可轻松适应不同的模型要求

基于长度分割的类型：
- **基于标记 (Token-based)**：根据标记的数量分割文本，这在处理语言模型时很有用。
- **基于字符 (Character-based)**：根据字符的数量分割文本，这在不同类型的文本中可能更一致。

使用 LangChain 的 `CharacterTextSplitter` 和基于标记分割的示例实现：

```python
from langchain_text_splitters import CharacterTextSplitter
text_splitter = CharacterTextSplitter.from_tiktoken_encoder(
    encoding_name="cl100k_base", chunk_size=100, chunk_overlap=0
)
texts = text_splitter.split_text(document)
```

:::info[深入阅读]

* 请参阅 [基于标记分割](/docs/how_to/split_by_token/) 的操作指南。
* 请参阅 [基于字符分割](/docs/how_to/character_text_splitter/) 的操作指南。

:::

### 基于文本结构

文本自然地组织成句子、段落和单词等层次结构单位。
我们可以利用这种固有的结构来指导我们的分割策略，创建能够保持自然语言流畅性、在数据块内保持语义连贯性并适应不同级别的文本粒度的分割。
LangChain 的 [`RecursiveCharacterTextSplitter`](/docs/how_to/recursive_text_splitter/) 体现了这一理念：
- `RecursiveCharacterTextSplitter` 会尝试将更大的单元（例如段落）保持不变。
- 如果一个单元的大小超过了数据块的大小限制，它会移动到下一个级别（例如句子）。
- 如果有必要，这个过程会一直持续到单词级别。

这是用法示例：

```python
from langchain_text_splitters import RecursiveCharacterTextSplitter
text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=0)
texts = text_splitter.split_text(document)
```

:::info[深入阅读]

* 请参阅 [递归文本分割](/docs/how_to/recursive_text_splitter/) 的操作指南。

:::

### 基于文档结构

某些文档具有固有的结构，例如 HTML、Markdown 或 JSON 文件。
在这些情况下，根据文档的结构进行分割会很有益，因为它通常能自然地将语义相关的文本分组。
基于结构分割的关键优点：
- 保持文档的逻辑组织结构
- 在每个数据块内保持上下文
- 对于检索或摘要等下游任务可能更有效

基于结构分割的示例：
- **Markdown**：根据标题（例如 #、##、###）进行分割
- **HTML**：使用标签进行分割
- **JSON**：按对象或数组元素进行分割
- **代码**：按函数、类或逻辑块进行分割

:::info[深入阅读]

* 请参阅 [Markdown 分割](/docs/how_to/markdown_header_metadata_splitter/) 的操作指南。
* 请参阅 [递归 JSON 分割](/docs/how_to/recursive_json_splitter/) 的操作指南。
* 请参阅 [代码分割](/docs/how_to/code_splitter/) 的操作指南。
* 请参阅 [HTML 分割](/docs/how_to/split_html/) 的操作指南。

:::

### 基于语义含义

与前几种方法不同，基于语义的分割实际上会考虑文本的*内容*。
虽然其他方法使用文档或文本结构作为语义含义的代理，但此方法直接分析文本的语义。
有几种方法可以实现这一点，但概念上，这种方法是在文本意义发生重大变化时分割文本。
例如，我们可以使用滑动窗口方法来生成嵌入，并比较嵌入以查找显著差异：

- 从前几句话开始并生成嵌入。
- 移动到下一组句子并生成另一个嵌入（例如，使用滑动窗口方法）。
- 比较嵌入以查找显著差异，这表明语义部分之间可能存在“断点”。

这项技术有助于创建更具语义连贯性的数据块，从而可能提高检索或摘要等下游任务的质量。

:::info[深入阅读]

* 请参阅 [基于语义含义分割文本](/docs/how_to/semantic-chunker/) 的操作指南。
* 请参阅 Greg Kamradt 的 [笔记本](https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb) 来展示语义分割。

:::