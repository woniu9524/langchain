{
  "cells": [
    {
      "cell_type": "raw",
      "id": "cb6f552e-775f-4d84-bc7c-dca94c06a33c",
      "metadata": {},
      "source": [
        "---\n",
        "title: Tagging\n",
        "sidebar_class_name: hidden\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0507a4b",
      "metadata": {},
      "source": [
        "[![在 Colab 中打开](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain/blob/master/docs/docs/use_cases/tagging.ipynb)\n\n# 将文本分类为标签\n\n标记是指为文档打上诸如以下之类的类别标签：\n\n- 情绪\n- 语言\n- 风格（例如，正式、非正式）\n- 涵盖的主题\n- 政治倾向\n\n![Image description](../../static/img/tagging.png)\n\n## 概述\n\n标记包含几个组件：\n\n* `function`：与 [提取](/docs/tutorials/extraction) 类似，标记也使用 [函数](https://openai.com/blog/function-calling-and-other-api-updates) 来指定模型应如何标记文档\n* `schema`：定义我们希望如何标记文档\n\n## 入门\n\n让我们通过一个非常简单的示例，了解如何在 LangChain 中使用 OpenAI 工具调用进行标记。我们将使用 OpenAI 模型支持的 [`with_structured_output`](/docs/how_to/structured_output) 方法。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc5cbb6f",
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install --upgrade --quiet langchain-core"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc2b7cdf-babb-46e2-98d0-302f69446842",
      "metadata": {},
      "source": [
        "我们需要加载一个 [chat model](/docs/integrations/chat/)：\n\nimport ChatModelTabs from \"@theme/ChatModelTabs\";\n\n<ChatModelTabs customVarName=\"llm\" />"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "608ee181-3f06-4719-842d-9672fdce6e57",
      "metadata": {},
      "outputs": [],
      "source": [
        "# | output: false\n",
        "# | echo: false\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8ca3f93",
      "metadata": {},
      "source": [
        "让我们用 Pydantic 模型指定具有几个属性及其在 schema 中的预期类型。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39f3ce3e",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "tagging_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "Extract the desired information from the following passage.\n",
        "\n",
        "Only extract the properties mentioned in the 'Classification' function.\n",
        "\n",
        "Passage:\n",
        "{input}\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "\n",
        "class Classification(BaseModel):\n",
        "    sentiment: str = Field(description=\"The sentiment of the text\")\n",
        "    aggressiveness: int = Field(\n",
        "        description=\"How aggressive the text is on a scale from 1 to 10\"\n",
        "    )\n",
        "    language: str = Field(description=\"The language the text is written in\")\n",
        "\n",
        "\n",
        "# Structured LLM\n",
        "structured_llm = llm.with_structured_output(Classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5509b6a6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Classification(sentiment='positive', aggressiveness=1, language='Spanish')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inp = \"Estoy increiblemente contento de haberte conocido! Creo que seremos muy buenos amigos!\"\n",
        "prompt = tagging_prompt.invoke({\"input\": inp})\n",
        "response = structured_llm.invoke(prompt)\n",
        "\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff3cf30d",
      "metadata": {},
      "source": [
        "如果我们想要字典输出，可以直接调用 `.model_dump()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9154474c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'sentiment': 'enojado', 'aggressiveness': 8, 'language': 'es'}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inp = \"Estoy muy enojado con vos! Te voy a dar tu merecido!\"\n",
        "prompt = tagging_prompt.invoke({\"input\": inp})\n",
        "response = structured_llm.invoke(prompt)\n",
        "\n",
        "response.model_dump()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d921bb53",
      "metadata": {},
      "source": [
        "正如我们在示例中看到的，它正确地解释了我们的意图。\n\n结果各不相同，因此我们可能会得到不同语言的情绪（例如，“积极”、“enojado”等）。\n\n我们将在下一节中了解如何控制这些结果。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bebb2f83",
      "metadata": {},
      "source": [
        "## 更精细化的控制\n\n精心的模式定义让我们能够更精细化地控制模型的输出。\n\n具体来说，我们可以定义：\n\n- 每个属性的可能值\n- 描述，以确保模型理解该属性\n- 模型必须返回的必需属性"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69ef0b9a",
      "metadata": {},
      "source": [
        "让我们重新声明我们的 Pydantic 模型，以 enum 的方式控制前面提到的各个方面："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6a5f7961",
      "metadata": {},
      "outputs": [],
      "source": [
        "class Classification(BaseModel):\n",
        "    sentiment: str = Field(..., enum=[\"happy\", \"neutral\", \"sad\"])\n",
        "    aggressiveness: int = Field(\n",
        "        ...,\n",
        "        description=\"describes how aggressive the statement is, the higher the number the more aggressive\",\n",
        "        enum=[1, 2, 3, 4, 5],\n",
        "    )\n",
        "    language: str = Field(\n",
        "        ..., enum=[\"spanish\", \"english\", \"french\", \"german\", \"italian\"]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "e5a5881f",
      "metadata": {},
      "outputs": [],
      "source": [
        "tagging_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "Extract the desired information from the following passage.\n",
        "\n",
        "Only extract the properties mentioned in the 'Classification' function.\n",
        "\n",
        "Passage:\n",
        "{input}\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\").with_structured_output(\n",
        "    Classification\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ded2332",
      "metadata": {},
      "source": [
        "现在答案将以我们期望的方式受到限制！"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "d9b9d53d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Classification(sentiment='positive', aggressiveness=1, language='Spanish')"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inp = \"Estoy increiblemente contento de haberte conocido! Creo que seremos muy buenos amigos!\"\n",
        "prompt = tagging_prompt.invoke({\"input\": inp})\n",
        "llm.invoke(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "1c12fa00",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Classification(sentiment='enojado', aggressiveness=8, language='es')"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inp = \"Estoy muy enojado con vos! Te voy a dar tu merecido!\"\n",
        "prompt = tagging_prompt.invoke({\"input\": inp})\n",
        "llm.invoke(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "0bdfcb05",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Classification(sentiment='neutral', aggressiveness=1, language='English')"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inp = \"Weather is ok here, I can go outside without much more than a coat\"\n",
        "prompt = tagging_prompt.invoke({\"input\": inp})\n",
        "llm.invoke(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf6b7389",
      "metadata": {},
      "source": [
        "LangSmith 的[追踪](https://smith.langchain.com/public/38294e04-33d8-4c5a-ae92-c2fe68be8332/r)让我们得以窥探其内部运作：\n\n![Image description](../../static/img/tagging_trace.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29346d09",
      "metadata": {},
      "source": [
        "### 深入了解\n\n* 您可以使用 [metadata tagger](/docs/integrations/document_transformers/openai_metadata_tagger) 文档转换器从 LangChain `Document` 中提取元数据。\n* 这涵盖了与 tagging chain 基本相同的功能，只是应用于 LangChain `Document`。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}