{
  "cells": [
    {
      "cell_type": "raw",
      "id": "df29b30a-fd27-4e08-8269-870df5631f9e",
      "metadata": {},
      "source": [
        "---\n",
        "sidebar_position: 4\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d28530a6-ddfd-49c0-85dc-b723551f6614",
      "metadata": {},
      "source": [
        "# æ„å»ºä¸€ä¸ªæå–é“¾\n\nåœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ [èŠå¤©æ¨¡å‹](/docs/concepts/chat_models) çš„ [å·¥å…·è°ƒç”¨](/docs/concepts/tool_calling) åŠŸèƒ½ä»éç»“æ„åŒ–æ–‡æœ¬ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯ã€‚æˆ‘ä»¬è¿˜å°†æ¼”ç¤ºå¦‚ä½•åœ¨æ­¤åœºæ™¯ä¸­ä½¿ç”¨ [å°‘æ ·æœ¬æç¤º](/docs/concepts/few_shot_prompting/) æ¥æé«˜æ€§èƒ½ã€‚\n\n:::important\næ­¤æ•™ç¨‹éœ€è¦ `langchain-core>=0.3.20`ï¼Œå¹¶ä¸”ä»…é€‚ç”¨äºæ”¯æŒ **å·¥å…·è°ƒç”¨** çš„æ¨¡å‹ã€‚\n:::"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4412def2-38e3-4bd0-bbf0-fb09ff9e5985",
      "metadata": {},
      "source": [
        "## è®¾ç½®\n\n### Jupyter Notebook\n\næœ¬æ•™ç¨‹ä»¥åŠå…¶ä»–æ•™ç¨‹ï¼Œä¹Ÿè®¸åœ¨ [Jupyter notebooks](https://jupyter.org/) ä¸­è¿è¡Œæ˜¯æœ€æ–¹ä¾¿çš„ã€‚åœ¨äº¤äº’å¼ç¯å¢ƒä¸­å­¦ä¹ æŒ‡å—æ˜¯æ›´å¥½åœ°ç†è§£å®ƒä»¬çš„å¥½æ–¹æ³•ã€‚æœ‰å…³å®‰è£…è¯´æ˜ï¼Œè¯·å‚è§ [æ­¤å¤„](https://jupyter.org/install)ã€‚\n\n### å®‰è£…\n\nè¦å®‰è£… LangChainï¼Œè¯·è¿è¡Œï¼š\n\nimport Tabs from '@theme/Tabs';\nimport TabItem from '@theme/TabItem';\nimport CodeBlock from \"@theme/CodeBlock\";\n\n<Tabs>\n  <TabItem value=\"pip\" label=\"Pip\" default>\n    <CodeBlock language=\"bash\">pip install --upgrade langchain-core</CodeBlock>\n  </TabItem>\n  <TabItem value=\"conda\" label=\"Conda\">\n    <CodeBlock language=\"bash\">conda install langchain-core -c conda-forge</CodeBlock>\n  </TabItem>\n</Tabs>\n\n\n\næœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…æˆ‘ä»¬çš„ [å®‰è£…æŒ‡å—](/docs/how_to/installation)ã€‚\n\n### LangSmith\n\næ‚¨ä½¿ç”¨ LangChain æ„å»ºçš„è®¸å¤šåº”ç”¨ç¨‹åºå°†åŒ…å«å¤šä¸ªæ­¥éª¤å’Œå¯¹ LLM çš„å¤šæ¬¡è°ƒç”¨ã€‚\néšç€è¿™äº›åº”ç”¨ç¨‹åºå˜å¾—è¶Šæ¥è¶Šå¤æ‚ï¼Œèƒ½å¤Ÿæ£€æŸ¥é“¾æˆ–ä»£ç†å†…éƒ¨ç©¶ç«Ÿå‘ç”Ÿäº†ä»€ä¹ˆå°±å˜å¾—è‡³å…³é‡è¦ã€‚\nåšåˆ°è¿™ä¸€ç‚¹æœ€å¥½æ–¹æ³•æ˜¯ä½¿ç”¨ [LangSmith](https://smith.langchain.com)ã€‚\n\nåœ¨ä¸Šé¢çš„é“¾æ¥æ³¨å†Œåï¼Œè¯·ç¡®ä¿è®¾ç½®æ‚¨çš„ç¯å¢ƒå˜é‡ä»¥å¼€å§‹è®°å½•è·Ÿè¸ªï¼š\n\n```shell\nexport LANGSMITH_TRACING=\"true\"\nexport LANGSMITH_API_KEY=\"...\"\n```\n\næˆ–è€…ï¼Œå¦‚æœæ‚¨åœ¨ notebook ä¸­ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ–¹å¼è®¾ç½®ï¼š\n\n```python\nimport getpass\nimport os\n\nos.environ[\"LANGSMITH_TRACING\"] = \"true\"\nos.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()\n```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54d6b970-2ea3-4192-951e-21237212b359",
      "metadata": {},
      "source": [
        "## Schema\n\né¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦æè¿°æˆ‘ä»¬æƒ³ä»æ–‡æœ¬ä¸­æå–å“ªäº›ä¿¡æ¯ã€‚\n\næˆ‘ä»¬å°†ä½¿ç”¨ Pydantic æ¥å®šä¹‰ä¸€ä¸ªç¤ºä¾‹ Schemaï¼Œç”¨äºæå–ä¸ªäººä¿¡æ¯ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c141084c-fb94-4093-8d6a-81175d688e40",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Optional\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "\n",
        "class Person(BaseModel):\n",
        "    \"\"\"Information about a person.\"\"\"\n",
        "\n",
        "    # ^ Doc-string for the entity Person.\n",
        "    # This doc-string is sent to the LLM as the description of the schema Person,\n",
        "    # and it can help to improve extraction results.\n",
        "\n",
        "    # Note that:\n",
        "    # 1. Each field is an `optional` -- this allows the model to decline to extract it!\n",
        "    # 2. Each field has a `description` -- this description is used by the LLM.\n",
        "    # Having a good description can help improve extraction results.\n",
        "    name: Optional[str] = Field(default=None, description=\"The name of the person\")\n",
        "    hair_color: Optional[str] = Field(\n",
        "        default=None, description=\"The color of the person's hair if known\"\n",
        "    )\n",
        "    height_in_meters: Optional[str] = Field(\n",
        "        default=None, description=\"Height measured in meters\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f248dd54-e36d-435a-b154-394ab4ed6792",
      "metadata": {},
      "source": [
        "å®šä¹‰ schema æ—¶ï¼Œæœ‰ä¸¤ä¸ªæœ€ä½³å®è·µï¼š\n\n1.  è®°å½• **å±æ€§** å’Œ **schema** æœ¬èº«ï¼šæ­¤ä¿¡æ¯å°†å‘é€ç»™ LLMï¼Œç”¨äºæé«˜ä¿¡æ¯æå–çš„è´¨é‡ã€‚\n2.  ä¸è¦å¼ºè¿« LLM ç¼–é€ ä¿¡æ¯ï¼æˆ‘ä»¬åœ¨ä¸Šé¢ä½¿ç”¨äº† `Optional` æ¥å®šä¹‰å±æ€§ï¼Œå…è®¸ LLM åœ¨ä¸çŸ¥é“ç­”æ¡ˆæ—¶è¾“å‡º `None`ã€‚\n\n:::important\nä¸ºè¾¾åˆ°æœ€ä½³æ€§èƒ½ï¼Œè¯·åŠ¡å¿…å……åˆ†è®°å½• schemaï¼Œå¹¶ç¡®ä¿æ¨¡å‹åœ¨æ–‡æœ¬ä¸­æ²¡æœ‰å¯æå–çš„ä¿¡æ¯æ—¶ï¼Œä¸ä¼šè¢«å¼ºè¿«è¿”å›ç»“æœã€‚\n:::\n\n## Extractor\n\nè®©æˆ‘ä»¬ä½¿ç”¨ä¸Šé¢å®šä¹‰çš„ schema æ¥åˆ›å»ºä¸€ä¸ªä¿¡æ¯æå–å™¨ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5e490f6-35ad-455e-8ae4-2bae021583ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "# Define a custom prompt to provide instructions and any additional context.\n",
        "# 1) You can add examples into the prompt template to improve extraction quality\n",
        "# 2) Introduce additional parameters to take context into account (e.g., include metadata\n",
        "#    about the document from which the text was extracted.)\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are an expert extraction algorithm. \"\n",
        "            \"Only extract relevant information from the text. \"\n",
        "            \"If you do not know the value of an attribute asked to extract, \"\n",
        "            \"return null for the attribute's value.\",\n",
        "        ),\n",
        "        # Please see the how-to about improving performance with\n",
        "        # reference examples.\n",
        "        # MessagesPlaceholder('examples'),\n",
        "        (\"human\", \"{text}\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "832bf6a1-8e0c-4b6a-aa37-12fe9c42a6d9",
      "metadata": {},
      "source": [
        "æˆ‘ä»¬éœ€è¦ä½¿ç”¨ä¸€ä¸ªæ”¯æŒå‡½æ•°/å·¥å…·è°ƒç”¨çš„æ¨¡å‹ã€‚\n\nè¯·å‚é˜…[æ–‡æ¡£](/docs/concepts/tool_calling)äº†è§£æ‰€æœ‰å¯ä¸æ­¤ API ç»“åˆä½¿ç”¨çš„æ¨¡å‹ã€‚\n\nimport ChatModelTabs from \"@theme/ChatModelTabs\";\n\n<ChatModelTabs customVarName=\"llm\" />"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "77c1311c-5252-41d6-83e6-fdb40b172e47",
      "metadata": {},
      "outputs": [],
      "source": [
        "# | output: false\n",
        "# | echo: false\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "04d846a6-d5cb-4009-ac19-61e3aac0177e",
      "metadata": {},
      "outputs": [],
      "source": [
        "structured_llm = llm.with_structured_output(schema=Person)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23582c0b-00ed-403f-a10e-3aeabf921f12",
      "metadata": {},
      "source": [
        "è®©æˆ‘ä»¬æ¥æµ‹è¯•ä¸€ä¸‹ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "dd42a935-022f-4860-b9e0-84268f55b22a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Person(name='Alan Smith', hair_color='blond', height_in_meters='1.83')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"Alan Smith is 6 feet tall and has blond hair.\"\n",
        "prompt = prompt_template.invoke({\"text\": text})\n",
        "structured_llm.invoke(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd1c493d-f9dc-4236-8da9-50f6919f5710",
      "metadata": {},
      "source": [
        ":::important\n\næå–æ˜¯ç”Ÿæˆå¼çš„ ğŸ¤¯\n\nLLM æ˜¯ç”Ÿæˆæ¨¡å‹ï¼Œå› æ­¤å®ƒä»¬å¯ä»¥åšä¸€äº›å¾ˆé…·çš„äº‹æƒ…ï¼Œä¾‹å¦‚æ­£ç¡®åœ°æå–äººçš„èº«é«˜ï¼ˆç±³ï¼‰ï¼Œå³ä½¿å®ƒåŸæœ¬æ˜¯ä»¥è‹±å°ºæä¾›çš„ï¼\n:::\n\næˆ‘ä»¬å¯ä»¥åœ¨[è¿™é‡Œ](https://smith.langchain.com/public/44b69a63-3b3b-47b8-8a6d-61b46533f015/r)æŸ¥çœ‹ LangSmith traceã€‚è¯·æ³¨æ„ï¼Œ[trace çš„èŠå¤©æ¨¡å‹éƒ¨åˆ†](https://smith.langchain.com/public/44b69a63-3b3b-47b8-8a6d-61b46533f015/r/dd1f6305-f1e9-4919-bd8f-339d03a12d01)æ˜¾ç¤ºäº†å‘é€ç»™æ¨¡å‹çš„ç²¾ç¡®æ¶ˆæ¯åºåˆ—ã€è°ƒç”¨çš„å·¥å…·ä»¥åŠå…¶ä»–å…ƒæ•°æ®ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28c5ef0c-b8d1-4e12-bd0e-e2528de87fcc",
      "metadata": {},
      "source": [
        "## å¤šä¸ªå®ä½“\n\nåœ¨**å¤§å¤šæ•°æƒ…å†µ**ä¸‹ï¼Œä½ åº”è¯¥æå–ä¸€ç³»åˆ—å®ä½“ï¼Œè€Œä¸æ˜¯å•ä¸ªå®ä½“ã€‚\n\né€šè¿‡å°†æ¨¡å‹ç›¸äº’åµŒå¥—ï¼Œå¯ä»¥ä½¿ç”¨ pydantic è½»æ¾å®ç°è¿™ä¸€ç‚¹ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "591a0c16-7a17-4883-91ee-0d6d2fdb265c",
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import List, Optional\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "\n",
        "class Person(BaseModel):\n",
        "    \"\"\"Information about a person.\"\"\"\n",
        "\n",
        "    # ^ Doc-string for the entity Person.\n",
        "    # This doc-string is sent to the LLM as the description of the schema Person,\n",
        "    # and it can help to improve extraction results.\n",
        "\n",
        "    # Note that:\n",
        "    # 1. Each field is an `optional` -- this allows the model to decline to extract it!\n",
        "    # 2. Each field has a `description` -- this description is used by the LLM.\n",
        "    # Having a good description can help improve extraction results.\n",
        "    name: Optional[str] = Field(default=None, description=\"The name of the person\")\n",
        "    hair_color: Optional[str] = Field(\n",
        "        default=None, description=\"The color of the person's hair if known\"\n",
        "    )\n",
        "    height_in_meters: Optional[str] = Field(\n",
        "        default=None, description=\"Height measured in meters\"\n",
        "    )\n",
        "\n",
        "\n",
        "class Data(BaseModel):\n",
        "    \"\"\"Extracted data about people.\"\"\"\n",
        "\n",
        "    # Creates a model so that we can extract multiple entities.\n",
        "    people: List[Person]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f5cda33-fd7b-481e-956a-703f45e40e1d",
      "metadata": {},
      "source": [
        ":::important\næå–ç»“æœå¯èƒ½ä¸å°½å®Œç¾ã€‚è¯·ç»§ç»­é˜…è¯»ï¼Œäº†è§£å¦‚ä½•ä½¿ç”¨ **Reference Examples** æ¥æé«˜æå–è´¨é‡ï¼Œå¹¶å‚é˜…æˆ‘ä»¬çš„æå– [æ“ä½œæŒ‡å—](/docs/how_to/#extraction) ä»¥è·å–æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚\n:::"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "83ecf0db-757b-4ae3-a9d2-eb1c9f6b2631",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Data(people=[Person(name='Jeff', hair_color='black', height_in_meters='1.83'), Person(name='Anna', hair_color='black', height_in_meters=None)])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "structured_llm = llm.with_structured_output(schema=Data)\n",
        "text = \"My name is Jeff, my hair is black and i am 6 feet tall. Anna has the same color hair as me.\"\n",
        "prompt = prompt_template.invoke({\"text\": text})\n",
        "structured_llm.invoke(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fba1d770-bf4d-4de4-9e4f-7384872ef0dc",
      "metadata": {},
      "source": [
        ":::tip\nå½“ Schema èƒ½å¤Ÿæå–**å¤šä¸ªå®ä½“**æ—¶ï¼Œå®ƒä¹Ÿå…è®¸æ¨¡å‹åœ¨æ–‡æœ¬ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯çš„æƒ…å†µä¸‹æå–**é›¶ä¸ªå®ä½“**ï¼Œåªéœ€æä¾›ä¸€ä¸ªç©ºåˆ—è¡¨å³å¯ã€‚\n\nè¿™é€šå¸¸æ˜¯ä¸€ä»¶**å¥½äº‹**ï¼å®ƒå…è®¸æˆ‘ä»¬åœ¨ä¸€ä¸ªå®ä½“ä¸ŠæŒ‡å®š**å¿…éœ€**çš„å±æ€§ï¼Œè€Œä¸å¿…å¼ºåˆ¶æ¨¡å‹æ£€æµ‹åˆ°è¯¥å®ä½“ã€‚\n:::\n\næˆ‘ä»¬å¯ä»¥åœ¨è¿™é‡ŒæŸ¥çœ‹ LangSmith çš„è¿½è¸ªè®°å½•ï¼š[here](https://smith.langchain.com/public/7173764d-5e76-45fe-8496-84460bd9cdef/r)ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c590f366-050a-43d4-8c78-acf84ccfbf9b",
      "metadata": {},
      "source": [
        "## å‚è€ƒç¤ºä¾‹\n\nLLM åº”ç”¨çš„è¡Œä¸ºå¯ä»¥é€šè¿‡ [å°‘æ ·æœ¬æç¤º (few-shot prompting)](/docs/concepts/few_shot_prompting/) è¿›è¡Œå¼•å¯¼ã€‚å¯¹äº [èŠå¤©æ¨¡å‹ (chat models)](/docs/concepts/chat_models/) æ¥è¯´ï¼Œè¿™å¯ä»¥è¡¨ç°ä¸ºä¸€ç³»åˆ—çš„è¾“å…¥å’Œå“åº”æ¶ˆæ¯å¯¹ï¼Œä»¥å±•ç¤ºæœŸæœ›çš„è¡Œä¸ºã€‚\n\nä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡äº¤æ›¿å‡ºç°çš„ `user` å’Œ `assistant` [æ¶ˆæ¯ (messages)](/docs/concepts/messages/#role) æ¥ä¼ è¾¾ä¸€ä¸ªç¬¦å·çš„å«ä¹‰ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "0bb138d7-116e-4542-aa5f-bebf0c301ec6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7\n"
          ]
        }
      ],
      "source": [
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"2 ğŸ¦œ 2\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"4\"},\n",
        "    {\"role\": \"user\", \"content\": \"2 ğŸ¦œ 3\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"5\"},\n",
        "    {\"role\": \"user\", \"content\": \"3 ğŸ¦œ 4\"},\n",
        "]\n",
        "\n",
        "response = llm.invoke(messages)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5691d07-e2b8-4ab3-a943-9b0b503e2549",
      "metadata": {},
      "source": [
        "[ç»“æ„åŒ–è¾“å‡º](/docs/concepts/structured_outputs/) é€šå¸¸ä¼šåœ¨åº•å±‚ä½¿ç”¨ [å·¥å…·è°ƒç”¨](/docs/concepts/tool_calling/)ã€‚è¿™é€šå¸¸æ¶‰åŠç”ŸæˆåŒ…å«å·¥å…·è°ƒç”¨çš„ [AI æ¶ˆæ¯](/docs/concepts/messages/#aimessage)ï¼Œä»¥åŠåŒ…å«å·¥å…·è°ƒç”¨ç»“æœçš„ [å·¥å…·æ¶ˆæ¯](/docs/concepts/messages/#toolmessage)ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ¶ˆæ¯åºåˆ—åº”è¯¥æ˜¯ä»€ä¹ˆæ ·çš„ï¼Ÿ\n\nä¸åŒçš„ [èŠå¤©æ¨¡å‹æä¾›å•†](/docs/integrations/chat/) å¯¹æœ‰æ•ˆçš„æ¶ˆæ¯åºåˆ—æœ‰ä¸åŒçš„è¦æ±‚ã€‚æœ‰äº›æ¥å—å¦‚ä¸‹ï¼ˆé‡å¤çš„ï¼‰æ¶ˆæ¯åºåˆ—ï¼š\n\n- ç”¨æˆ·æ¶ˆæ¯\n- åŒ…å«å·¥å…·è°ƒç”¨çš„ AI æ¶ˆæ¯\n- åŒ…å«ç»“æœçš„å·¥å…·æ¶ˆæ¯\n\nå¦ä¸€äº›åˆ™éœ€è¦ä¸€ä¸ªæœ€ç»ˆçš„ AI æ¶ˆæ¯æ¥åŒ…å«æŸç§å“åº”ã€‚\n\nLangChain åŒ…å«ä¸€ä¸ªå®ç”¨å‡½æ•° [tool_example_to_messages](https://python.langchain.com/api_reference/core/utils/langchain_core.utils.function_calling.tool_example_to_messages.html)ï¼Œå®ƒèƒ½ä¸ºå¤§å¤šæ•°æ¨¡å‹æä¾›å•†ç”Ÿæˆæœ‰æ•ˆçš„åºåˆ—ã€‚è¯¥å‡½æ•°é€šè¿‡ä»…è¦æ±‚ Pydantic è¡¨ç¤ºæ³•æ¥ç®€åŒ–ç»“æ„åŒ–å°‘æ ·æœ¬ç¤ºä¾‹çš„ç”Ÿæˆã€‚\n\nè®©æˆ‘ä»¬è¯•ä¸€è¯•ã€‚æˆ‘ä»¬å¯ä»¥å°†è¾“å…¥å­—ç¬¦ä¸²å¯¹å’ŒæœŸæœ›çš„ Pydantic å¯¹è±¡è½¬æ¢ä¸ºä¸€ç³»åˆ—æ¶ˆæ¯ï¼Œæä¾›ç»™èŠå¤©æ¨¡å‹ã€‚åœ¨åº•å±‚ï¼ŒLangChain ä¼šå°†å·¥å…·è°ƒç”¨æ ¼å¼åŒ–ä¸ºæ¯ä¸ªæä¾›å•†æ‰€éœ€ çš„æ ¼å¼ã€‚\n\nè¯·æ³¨æ„ï¼šæ­¤ç‰ˆæœ¬çš„ `tool_example_to_messages` éœ€è¦ `langchain-core>=0.3.20`ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c604e476-a2be-4eda-b128-71399e280732",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.utils.function_calling import tool_example_to_messages\n",
        "\n",
        "examples = [\n",
        "    (\n",
        "        \"The ocean is vast and blue. It's more than 20,000 feet deep.\",\n",
        "        Data(people=[]),\n",
        "    ),\n",
        "    (\n",
        "        \"Fiona traveled far from France to Spain.\",\n",
        "        Data(people=[Person(name=\"Fiona\", height_in_meters=None, hair_color=None)]),\n",
        "    ),\n",
        "]\n",
        "\n",
        "\n",
        "messages = []\n",
        "\n",
        "for txt, tool_call in examples:\n",
        "    if tool_call.people:\n",
        "        # This final message is optional for some providers\n",
        "        ai_response = \"Detected people.\"\n",
        "    else:\n",
        "        ai_response = \"Detected no people.\"\n",
        "    messages.extend(tool_example_to_messages(txt, [tool_call], ai_response=ai_response))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "beecc7a6-e423-4ca1-82b7-c2a751362fd6",
      "metadata": {},
      "source": [
        "æ£€æŸ¥ç»“æœæ—¶ï¼Œæˆ‘ä»¬ä¼šçœ‹åˆ°è¿™ä¸¤ä¸ªç¤ºä¾‹å¯¹ç”Ÿæˆäº†å…«æ¡æ¶ˆæ¯ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "628f67dd-aee0-4200-ac38-24a9fb16f1d1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "The ocean is vast and blue. It's more than 20,000 feet deep.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  Data (d8f2e054-7fb9-417f-b28f-0447a775b2c3)\n",
            " Call ID: d8f2e054-7fb9-417f-b28f-0447a775b2c3\n",
            "  Args:\n",
            "    people: []\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "\n",
            "You have correctly called this tool.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Detected no people.\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Fiona traveled far from France to Spain.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  Data (0178939e-a4b1-4d2a-a93e-b87f665cdfd6)\n",
            " Call ID: 0178939e-a4b1-4d2a-a93e-b87f665cdfd6\n",
            "  Args:\n",
            "    people: [{'name': 'Fiona', 'hair_color': None, 'height_in_meters': None}]\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "\n",
            "You have correctly called this tool.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Detected people.\n"
          ]
        }
      ],
      "source": [
        "for message in messages:\n",
        "    message.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc8846f0-8bd1-48e1-bc4d-a62fbfa6a9f4",
      "metadata": {},
      "source": [
        "è®©æˆ‘ä»¬æ¥æ¯”è¾ƒä¸€ä¸‹æ˜¯å¦åŒ…å«è¿™äº›æ¶ˆæ¯æ—¶çš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œè®©æˆ‘ä»¬ä¼ é€’ä¸€ä¸ªæˆ‘ä»¬ä¸æ‰“ç®—æå–ä»»ä½•äººçš„æ¶ˆæ¯ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "6b73d4e2-d18d-4d47-89ec-99b5eb6b234f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Data(people=[Person(name='Earth', hair_color='None', height_in_meters='0.00')])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "message_no_extraction = {\n",
        "    \"role\": \"user\",\n",
        "    \"content\": \"The solar system is large, but earth has only 1 moon.\",\n",
        "}\n",
        "\n",
        "structured_llm = llm.with_structured_output(schema=Data)\n",
        "structured_llm.invoke([message_no_extraction])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "350e1298-14f1-48e4-b11c-534af643e3a6",
      "metadata": {},
      "source": [
        "åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œæ¨¡å‹å¯èƒ½ä¼šé”™è¯¯åœ°ç”Ÿæˆäººç‰©è®°å½•ã€‚\n\nç”±äºæˆ‘ä»¬çš„å°‘æ ·æœ¬ç¤ºä¾‹åŒ…å«â€œè´Ÿé¢â€ç¤ºä¾‹ï¼Œå› æ­¤æˆ‘ä»¬é¼“åŠ±æ¨¡å‹åœ¨è¿™ç§æƒ…å†µä¸‹è¡¨ç°æ­£ç¡®ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "eb1b3a99-4750-45bc-ad28-5d12751ed9f8",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Data(people=[])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "structured_llm.invoke(messages + [message_no_extraction])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d1ae320-14bc-45ee-aeeb-8a986f3e6808",
      "metadata": {},
      "source": [
        ":::tip\n\n[LangSmith](https://smith.langchain.com/public/b3433f57-7905-4430-923c-fed214525bf1/r) çš„è¿è¡Œè¿½è¸ªè®°å½•æ˜¾ç¤ºäº†å‘é€åˆ°èŠå¤©æ¨¡å‹çš„å‡†ç¡®æ¶ˆæ¯é¡ºåºã€ç”Ÿæˆçš„å·¥å…·è°ƒç”¨ã€å»¶è¿Ÿã€Token æ•°é‡ä»¥åŠå…¶ä»–å…ƒæ•°æ®ã€‚\n\n:::\n\næœ‰å…³æå–å·¥ä½œæµå’Œå‚è€ƒç¤ºä¾‹çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[æœ¬æŒ‡å—](/docs/how_to/extraction_examples/)ï¼Œå…¶ä¸­åŒ…æ‹¬å¦‚ä½•æ•´åˆ Prompt æ¨¡æ¿å’Œè‡ªå®šä¹‰ç¤ºä¾‹æ¶ˆæ¯çš„ç”Ÿæˆã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f07a7455-7de6-4a6f-9772-0477ef65e3dc",
      "metadata": {},
      "source": [
        "## åç»­æ­¥éª¤\n\næ—¢ç„¶æ‚¨å·²ç»äº†è§£äº† LangChain çš„æå–åŸºç¡€çŸ¥è¯†ï¼Œå°±å¯ä»¥ç»§ç»­é˜…è¯»å…¶ä½™çš„æ“ä½œæŒ‡å—äº†ï¼š\n\n- [æ·»åŠ ç¤ºä¾‹](/docs/how_to/extraction_examples)ï¼šå…³äºä½¿ç”¨**å‚è€ƒç¤ºä¾‹**æ¥æé«˜æ€§èƒ½çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ ã€‚\n- [å¤„ç†é•¿æ–‡æœ¬](/docs/how_to/extraction_long_text)ï¼šå¦‚æœæ–‡æœ¬ä¸é€‚åˆ LLM çš„ä¸Šä¸‹æ–‡çª—å£ï¼Œæ‚¨åº”è¯¥æ€ä¹ˆåšï¼Ÿ\n- [ä½¿ç”¨è§£ææ–¹æ³•](/docs/how_to/extraction_parse)ï¼šå¯¹äºä¸æ”¯æŒ**å·¥å…·/å‡½æ•°è°ƒç”¨**çš„æ¨¡å‹ï¼Œä½¿ç”¨åŸºäºæç¤ºçš„æ–¹æ³•è¿›è¡Œæå–ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3deb47ba",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}