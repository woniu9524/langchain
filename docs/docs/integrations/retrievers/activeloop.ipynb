{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Activeloop Deep Memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ">[Activeloop Deep Memory](https://docs.activeloop.ai/performance-features/deep-memory) 是一套工具，可让您针对特定用例优化向量存储，并在 LLM 应用中实现更高的准确性。\n\n`检索增强生成` (`RAG`) 近期备受关注。随着高级 RAG 技术和代理的出现，它们扩展了 RAG 的潜在能力。然而，在生产环境中集成 RAG 可能面临一些挑战。在生产环境中实施 RAG 时需要考虑的主要因素是准确性 (召回率)、成本和延迟。对于基本用例，OpenAI 的 Ada 模型搭配简单的相似性搜索可以产生令人满意的结果。然而，为了在搜索中获得更高的准确性或召回率，可能需要采用高级检索技术。这些方法可能涉及更改数据块大小、多次重写查询等，这可能会增加延迟和成本。Activeloop 的 [Deep Memory](https://www.activeloop.ai/resources/use-deep-memory-to-boost-rag-apps-accuracy-by-up-to-22/) 是 `Activeloop Deep Lake` 用户可用的一个功能，它通过引入一个微小的神经网络层来解决这些问题，该神经网络层经过训练，可以匹配用户查询与语料库中的相关数据。虽然此添加会在搜索过程中带来最小的延迟，但它可以将检索准确性提高多达 27%，并且仍然具有成本效益且易于使用，无需任何额外的先进 RAG 技术。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "在本教程中，我们将解析 `DeepLake` 文档，并创建一个 RAG 系统来回答文档中的问题。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 数据集创建"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "我们将在此教程中使用 `BeautifulSoup` 库以及 LangChain 的文档解析器，如 `Html2TextTransformer`、`AsyncHtmlLoader` 来解析 activeloop 的文档。因此，我们需要安装以下库："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet  tiktoken langchain-openai python-dotenv datasets langchain deeplake beautifulsoup4 html2text ragas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "您还需要创建一个 [Activeloop](https://activeloop.ai) 账户。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ORG_ID = \"...\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-08T04:01:35.753257Z",
          "iopub.status.busy": "2024-03-08T04:01:35.752712Z",
          "iopub.status.idle": "2024-03-08T04:01:35.756716Z",
          "shell.execute_reply": "2024-03-08T04:01:35.756265Z",
          "shell.execute_reply.started": "2024-03-08T04:01:35.753220Z"
        }
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain_community.vectorstores import DeepLake\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API token: \")\n",
        "# # activeloop token is needed if you are not signed in using CLI: `activeloop login -u <USERNAME> -p <PASSWORD>`\n",
        "if \"ACTIVELOOP_TOKEN\" not in os.environ:\n",
        "    os.environ[\"ACTIVELOOP_TOKEN\"] = getpass.getpass(\n",
        "        \"Enter your ActiveLoop API token: \"\n",
        "    )  # Get your API token from https://app.activeloop.ai, click on your profile picture in the top right corner, and select \"API Tokens\"\n",
        "\n",
        "token = os.getenv(\"ACTIVELOOP_TOKEN\")\n",
        "openai_embeddings = OpenAIEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "db = DeepLake(\n",
        "    dataset_path=f\"hub://{ORG_ID}/deeplake-docs-deepmemory\",  # org_id stands for your username or organization from activeloop\n",
        "    embedding=openai_embeddings,\n",
        "    runtime={\"tensor_db\": True},\n",
        "    token=token,\n",
        "    # overwrite=True, # user overwrite flag if you want to overwrite the full dataset\n",
        "    read_only=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "使用 `BeautifulSoup` 解析网页中的所有链接"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from urllib.parse import urljoin\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "def get_all_links(url):\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Failed to retrieve the page: {url}\")\n",
        "        return []\n",
        "\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "    # Finding all 'a' tags which typically contain href attribute for links\n",
        "    links = [\n",
        "        urljoin(url, a[\"href\"]) for a in soup.find_all(\"a\", href=True) if a[\"href\"]\n",
        "    ]\n",
        "\n",
        "    return links\n",
        "\n",
        "\n",
        "base_url = \"https://docs.deeplake.ai/en/latest/\"\n",
        "all_links = get_all_links(base_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "正在加载数据："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-08T04:02:37.919739Z",
          "iopub.status.busy": "2024-03-08T04:02:37.919328Z",
          "iopub.status.idle": "2024-03-08T04:02:37.933457Z",
          "shell.execute_reply": "2024-03-08T04:02:37.932716Z",
          "shell.execute_reply.started": "2024-03-08T04:02:37.919707Z"
        }
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders.async_html import AsyncHtmlLoader\n",
        "\n",
        "loader = AsyncHtmlLoader(all_links)\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-08T04:02:37.919739Z",
          "iopub.status.busy": "2024-03-08T04:02:37.919328Z",
          "iopub.status.idle": "2024-03-08T04:02:37.933457Z",
          "shell.execute_reply": "2024-03-08T04:02:37.932716Z",
          "shell.execute_reply.started": "2024-03-08T04:02:37.919707Z"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "将数据转换为用户可读的格式："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.document_transformers import Html2TextTransformer\n",
        "\n",
        "html2text = Html2TextTransformer()\n",
        "docs_transformed = html2text.transform_documents(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "现在，让我们进一步分割文档，因为其中一些文本过多："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "chunk_size = 4096\n",
        "docs_new = []\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=chunk_size,\n",
        ")\n",
        "\n",
        "for doc in docs_transformed:\n",
        "    if len(doc.page_content) < chunk_size:\n",
        "        docs_new.append(doc)\n",
        "    else:\n",
        "        docs = text_splitter.create_documents([doc.page_content])\n",
        "        docs_new.extend(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "填充 VectorStore："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "docs = db.add_documents(docs_new)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 生成合成查询和训练 Deep Memory\n\nTo train the Deep Memory model, we first need to generate a set of *synthetic queries*. These"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "下一步将训练一个 deep_memory 模型，该模型会将用户的查询与您已有的数据集进行匹配。如果您还没有用户查询，不用担心，我们将使用 LLM 来生成它们！"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 待办：添加图片"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "上面我们展示了 `deep_memory` 的整体工作流程。正如你所见，要训练它，你需要相关性数据、查询以及语料库数据（我们想要查询的数据）。语料库数据已在上一节中填充，在这里我们将生成问题和相关性数据。\n\n1. `questions` - 是一个字符串列表，其中每个字符串代表一个查询。\n2. `relevance` - 包含每个问题对应的真实相关性链接。可能有多篇文档包含对给定问题的答案。因此，`relevance` 是 `List[List[tuple[str, float]]]` 类型，其中外层列表代表查询，内层列表代表相关文档。元组包含字符串和浮点数对，字符串代表源文档的 ID（对应数据集中的 `id` 张量），而浮点数表示当前文档与该问题的相关程度。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "现在，让我们生成合成问题和相关性："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "from langchain.chains.openai_functions import (\n",
        "    create_structured_output_chain,\n",
        ")\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from pydantic import BaseModel, Field"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# fetch dataset docs and ids if they exist (optional you can also ingest)\n",
        "docs = db.vectorstore.dataset.text.data(fetch_chunks=True, aslist=True)[\"value\"]\n",
        "ids = db.vectorstore.dataset.id.data(fetch_chunks=True, aslist=True)[\"value\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If we pass in a model explicitly, we need to make sure it supports the OpenAI function-calling API.\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "\n",
        "class Questions(BaseModel):\n",
        "    \"\"\"Identifying information about a person.\"\"\"\n",
        "\n",
        "    question: str = Field(..., description=\"Questions about text\")\n",
        "\n",
        "\n",
        "prompt_msgs = [\n",
        "    SystemMessage(\n",
        "        content=\"You are a world class expert for generating questions based on provided context. \\\n",
        "                You make sure the question can be answered by the text.\"\n",
        "    ),\n",
        "    HumanMessagePromptTemplate.from_template(\n",
        "        \"Use the given text to generate a question from the following input: {input}\"\n",
        "    ),\n",
        "    HumanMessage(content=\"Tips: Make sure to answer in the correct format\"),\n",
        "]\n",
        "prompt = ChatPromptTemplate(messages=prompt_msgs)\n",
        "chain = create_structured_output_chain(Questions, llm, prompt, verbose=True)\n",
        "\n",
        "text = \"# Understanding Hallucinations and Bias ## **Introduction** In this lesson, we'll cover the concept of **hallucinations** in LLMs, highlighting their influence on AI applications and demonstrating how to mitigate them using techniques like the retriever's architectures. We'll also explore **bias** within LLMs with examples.\"\n",
        "questions = chain.run(input=text)\n",
        "print(questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def generate_queries(docs: List[str], ids: List[str], n: int = 100):\n",
        "    questions = []\n",
        "    relevances = []\n",
        "    pbar = tqdm(total=n)\n",
        "    while len(questions) < n:\n",
        "        # 1. randomly draw a piece of text and relevance id\n",
        "        r = random.randint(0, len(docs) - 1)\n",
        "        text, label = docs[r], ids[r]\n",
        "\n",
        "        # 2. generate queries and assign and relevance id\n",
        "        generated_qs = [chain.run(input=text).question]\n",
        "        questions.extend(generated_qs)\n",
        "        relevances.extend([[(label, 1)] for _ in generated_qs])\n",
        "        pbar.update(len(generated_qs))\n",
        "        if len(questions) % 10 == 0:\n",
        "            print(f\"q: {len(questions)}\")\n",
        "    return questions[:n], relevances[:n]\n",
        "\n",
        "\n",
        "chain = create_structured_output_chain(Questions, llm, prompt, verbose=False)\n",
        "questions, relevances = generate_queries(docs, ids, n=200)\n",
        "\n",
        "train_questions, train_relevances = questions[:100], relevances[:100]\n",
        "test_questions, test_relevances = questions[100:], relevances[100:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "现在我们创建了 100 个训练查询和 100 个测试查询。现在让我们来训练 `deep_memory`："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "job_id = db.vectorstore.deep_memory.train(\n",
        "    queries=train_questions,\n",
        "    relevance=train_relevances,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "让我们来跟踪训练进度："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------------------------------------------------\n",
            "|                  6538e02ecda4691033a51c5b                  |\n",
            "--------------------------------------------------------------\n",
            "| status                     | completed                     |\n",
            "--------------------------------------------------------------\n",
            "| progress                   | eta: 1.4 seconds              |\n",
            "|                            | recall@10: 79.00% (+34.00%)   |\n",
            "--------------------------------------------------------------\n",
            "| results                    | recall@10: 79.00% (+34.00%)   |\n",
            "--------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "db.vectorstore.deep_memory.status(\"6538939ca0b69a9ca45c528c\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 评估深度记忆性能"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "太棒了，我们已经训练好了模型！它的召回率有了显著提升，但我们现在该如何使用它并在未见过的新数据上进行评估呢？在本节中，我们将深入探讨模型评估和推理部分，看看它如何与 LangChain 一起使用以提高检索准确性。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 深度记忆评估"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "我们可以在开始时使用 `deep_memory` 的内置评估方法。\n它会计算几个 `recall` 指标。\n这可以很容易地在几行代码中完成。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Embedding queries took 0.81 seconds\n",
            "---- Evaluating without model ---- \n",
            "Recall@1:\t  9.0%\n",
            "Recall@3:\t  19.0%\n",
            "Recall@5:\t  24.0%\n",
            "Recall@10:\t  42.0%\n",
            "Recall@50:\t  93.0%\n",
            "Recall@100:\t  98.0%\n",
            "---- Evaluating with model ---- \n",
            "Recall@1:\t  19.0%\n",
            "Recall@3:\t  42.0%\n",
            "Recall@5:\t  49.0%\n",
            "Recall@10:\t  69.0%\n",
            "Recall@50:\t  97.0%\n",
            "Recall@100:\t  97.0%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "recall = db.vectorstore.deep_memory.evaluate(\n",
        "    queries=test_questions,\n",
        "    relevance=test_relevances,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "在未见过的新测试数据集上，它也显示出相当大的改进！！！"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 深度记忆 + RAGas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas.langchain import RagasEvaluatorChain\n",
        "from ragas.metrics import (\n",
        "    context_recall,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "让我们将召回（recall）转化为事实真相（ground truths）："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_relevance_to_ground_truth(docs, relevance):\n",
        "    ground_truths = []\n",
        "\n",
        "    for rel in relevance:\n",
        "        ground_truth = []\n",
        "        for doc_id, _ in rel:\n",
        "            ground_truth.append(docs[doc_id])\n",
        "        ground_truths.append(ground_truth)\n",
        "    return ground_truths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating with deep_memory = False\n",
            "===================================\n",
            "context_recall_score = 0.3763423145\n",
            "===================================\n",
            "\n",
            "Evaluating with deep_memory = True\n",
            "===================================\n",
            "context_recall_score = 0.5634545323\n",
            "===================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "ground_truths = convert_relevance_to_ground_truth(docs, test_relevances)\n",
        "\n",
        "for deep_memory in [False, True]:\n",
        "    print(\"\\nEvaluating with deep_memory =\", deep_memory)\n",
        "    print(\"===================================\")\n",
        "\n",
        "    retriever = db.as_retriever()\n",
        "    retriever.search_kwargs[\"deep_memory\"] = deep_memory\n",
        "\n",
        "    qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm=ChatOpenAI(model=\"gpt-3.5-turbo\"),\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=retriever,\n",
        "        return_source_documents=True,\n",
        "    )\n",
        "\n",
        "    metrics = {\n",
        "        \"context_recall_score\": 0,\n",
        "    }\n",
        "\n",
        "    eval_chains = {m.name: RagasEvaluatorChain(metric=m) for m in [context_recall]}\n",
        "\n",
        "    for question, ground_truth in zip(test_questions, ground_truths):\n",
        "        result = qa_chain({\"query\": question})\n",
        "        result[\"ground_truths\"] = ground_truth\n",
        "        for name, eval_chain in eval_chains.items():\n",
        "            score_name = f\"{name}_score\"\n",
        "            metrics[score_name] += eval_chain(result)[score_name]\n",
        "\n",
        "    for metric in metrics:\n",
        "        metrics[metric] /= len(test_questions)\n",
        "        print(f\"{metric}: {metrics[metric]}\")\n",
        "    print(\"===================================\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 深度记忆推理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### TODO：添加图片\n\n具有 deep_memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The base htype of the 'video_seq' tensor is 'video'.\n"
          ]
        }
      ],
      "source": [
        "retriever = db.as_retriever()\n",
        "retriever.search_kwargs[\"deep_memory\"] = True\n",
        "retriever.search_kwargs[\"k\"] = 10\n",
        "\n",
        "query = \"Deamination of cytidine to uridine on the minus strand of viral DNA results in catastrophic G-to-A mutations in the viral genome.\"\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=ChatOpenAI(model=\"gpt-4\"), chain_type=\"stuff\", retriever=retriever\n",
        ")\n",
        "print(qa.run(query))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "without deep_memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The text does not provide information on the base htype of the 'video_seq' tensor.\n"
          ]
        }
      ],
      "source": [
        "retriever = db.as_retriever()\n",
        "retriever.search_kwargs[\"deep_memory\"] = False\n",
        "retriever.search_kwargs[\"k\"] = 10\n",
        "\n",
        "query = \"Deamination of cytidine to uridine on the minus strand of viral DNA results in catastrophic G-to-A mutations in the viral genome.\"\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=ChatOpenAI(model=\"gpt-4\"), chain_type=\"stuff\", retriever=retriever\n",
        ")\n",
        "qa.run(query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.4 深度内存成本节省"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Deep Memory 可以在不改变您现有工作流程的情况下提高检索准确性。此外，通过减少输入到 LLM 的 `top_k`，您可以显著降低代币使用量，从而削减推理成本。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}