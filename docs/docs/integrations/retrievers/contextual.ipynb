{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Contextual AI Reranker\n\nContextual AI 的指令遵循 Reranker 是世界上第一个旨在根据时效性、来源和元数据等特定标准遵循自定义指令来优先排序文档的 reranker。它在 BEIR 基准测试中表现出色（得分 61.2，显著优于竞争对手），为企业 RAG 应用提供了前所未有的控制力和准确性。\n\n## 主要功能\n\n- **指令遵循**: 通过自然语言命令动态控制文档排名\n- **冲突解决**: 智能处理来自多个知识源的矛盾信息\n- **卓越的准确性**: 在行业基准测试中达到最先进的性能\n- **无缝集成**: 可直接替换您 RAG 管道中现有的 reranker\n\n该 reranker 能够出色地解决企业知识库中的实际挑战，例如优先考虑最新文档而不是过时文档，或者偏好内部文档而不是外部来源。\n\n要了解有关我们的指令遵循 reranker 的更多信息并查看其示例演示，请访问我们的[产品概述](https://contextual.ai/blog/introducing-instruction-following-reranker/)。\n\n有关 Contextual AI 产品的全面文档，请访问我们的[开发者门户](https://docs.contextual.ai/)。\n\n此集成需要 `contextual-client` Python SDK。在此[处](https://github.com/ContextualAI/contextual-client-python)了解更多信息。\n\n## 概述\n\n此集成会调用 Contextual AI 的 Grounded Language Model。\n\n### 集成详情\n\n| Class | Package | Local | Serializable | JS support | Package downloads | Package latest |\n| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\n| [ContextualRerank](https://python.langchain.com/api_reference/en/latest/chat_models/langchain_contextual.rerank.ContextualRerank.html) | [langchain-contextual](https://python.langchain.com/api_reference/en/latest/contextual_api_reference.html) | ❌ | beta | ❌ | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-contextual?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-contextual?style=flat-square&label=%20) |\n\n## 设置\n\n要访问 Contextual 的 reranker 模型，您需要创建一个 Contextual AI 账户，获取 API 密钥，并安装 `langchain-contextual` 集成包。\n\n### 凭据\n\n前往 [app.contextual.ai](https://app.contextual.ai) 注册 Contextual 并生成 API 密钥。完成此操作后，请设置 CONTEXTUAL_AI_API_KEY 环境变量："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if not os.getenv(\"CONTEXTUAL_AI_API_KEY\"):\n",
        "    os.environ[\"CONTEXTUAL_AI_API_KEY\"] = getpass.getpass(\n",
        "        \"Enter your Contextual API key: \"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 安装\n\nLangChain Contextual 集成位于 `langchain-contextual` 包中："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -qU langchain-contextual"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 实例化\n\nContextual Reranker 的参数为：\n\n| 参数 | 类型 | 描述 |\n| --- | --- | --- |\n| documents | list[Document] | 要重新排序的文档序列。文档中包含的任何元数据也将被用于重新排序。 |\n| query | str | 用于重新排序的查询。 |\n| model | str | 要使用的重新排序器版本。目前我们只有 \"ctxl-rerank-en-v1-instruct\"。 |\n| top\\_n | Optional[int] | 要返回的结果数量。如果为 None，则返回所有结果。默认为 self.top\\_n。 |\n| instruction | Optional[str] | 将用于重新排序器的指令。 |\n| callbacks | Optional[Callbacks] | 在压缩过程中运行的回调。 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_contextual import ContextualRerank\n",
        "\n",
        "api_key = \"\"\n",
        "model = \"ctxl-rerank-en-v1-instruct\"\n",
        "\n",
        "compressor = ContextualRerank(\n",
        "    model=model,\n",
        "    api_key=api_key,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 用法\n\n首先，我们将设置要使用的全局变量和示例，并实例化我们的重排器客户端。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "query = \"What is the current enterprise pricing for the RTX 5090 GPU for bulk orders?\"\n",
        "instruction = \"Prioritize internal sales documents over market analysis reports. More recent documents should be weighted higher. Enterprise portal content supersedes distributor communications.\"\n",
        "\n",
        "document_contents = [\n",
        "    \"Following detailed cost analysis and market research, we have implemented the following changes: AI training clusters will see a 15% uplift in raw compute performance, enterprise support packages are being restructured, and bulk procurement programs (100+ units) for the RTX 5090 Enterprise series will operate on a $2,899 baseline.\",\n",
        "    \"Enterprise pricing for the RTX 5090 GPU bulk orders (100+ units) is currently set at $3,100-$3,300 per unit. This pricing for RTX 5090 enterprise bulk orders has been confirmed across all major distribution channels.\",\n",
        "    \"RTX 5090 Enterprise GPU requires 450W TDP and 20% cooling overhead.\",\n",
        "]\n",
        "\n",
        "metadata = [\n",
        "    {\n",
        "        \"Date\": \"January 15, 2025\",\n",
        "        \"Source\": \"NVIDIA Enterprise Sales Portal\",\n",
        "        \"Classification\": \"Internal Use Only\",\n",
        "    },\n",
        "    {\"Date\": \"11/30/2023\", \"Source\": \"TechAnalytics Research Group\"},\n",
        "    {\n",
        "        \"Date\": \"January 25, 2025\",\n",
        "        \"Source\": \"NVIDIA Enterprise Sales Portal\",\n",
        "        \"Classification\": \"Internal Use Only\",\n",
        "    },\n",
        "]\n",
        "\n",
        "documents = [\n",
        "    Document(page_content=content, metadata=metadata[i])\n",
        "    for i, content in enumerate(document_contents)\n",
        "]\n",
        "reranked_documents = compressor.compress_documents(\n",
        "    query=query,\n",
        "    instruction=instruction,\n",
        "    documents=documents,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 在链式调用中使用\n\n示例即将推出。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## API 参考\n\n如需了解 ChatContextual 所有功能和配置的详细文档，请访问 Github 页面：https://github.com/ContextualAI//langchain-contextual"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}