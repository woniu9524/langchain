{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "fc0db1bc",
      "metadata": {},
      "source": [
        "# LOTR (Merger Retriever)\n\n> `Lord of the Retrievers (LOTR)`，也称为 `MergerRetriever`，它接受一个检索器列表作为输入，并将它们 `get_relevant_documents()` 方法的结果合并成一个列表。合并后的结果将是一个列表，其中包含与查询相关的、并已由不同检索器排好序的文档。\n\n`MergerRetriever` 类可以通过多种方式用于提高文档检索的准确性。首先，它可以组合多个检索器的结果，这有助于降低结果偏差的风险。其次，它可以对不同检索器的结果进行排序，这有助于确保最相关的文档首先被返回。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fbcc58f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import chromadb\n",
        "from langchain.retrievers import (\n",
        "    ContextualCompressionRetriever,\n",
        "    DocumentCompressorPipeline,\n",
        "    MergerRetriever,\n",
        ")\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.document_transformers import (\n",
        "    EmbeddingsClusteringFilter,\n",
        "    EmbeddingsRedundantFilter,\n",
        ")\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# Get 3 diff embeddings.\n",
        "all_mini = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "multi_qa_mini = HuggingFaceEmbeddings(model_name=\"multi-qa-MiniLM-L6-dot-v1\")\n",
        "filter_embeddings = OpenAIEmbeddings()\n",
        "\n",
        "ABS_PATH = os.path.dirname(os.path.abspath(__file__))\n",
        "DB_DIR = os.path.join(ABS_PATH, \"db\")\n",
        "\n",
        "# Instantiate 2 diff chromadb indexes, each one with a diff embedding.\n",
        "client_settings = chromadb.config.Settings(\n",
        "    is_persistent=True,\n",
        "    persist_directory=DB_DIR,\n",
        "    anonymized_telemetry=False,\n",
        ")\n",
        "db_all = Chroma(\n",
        "    collection_name=\"project_store_all\",\n",
        "    persist_directory=DB_DIR,\n",
        "    client_settings=client_settings,\n",
        "    embedding_function=all_mini,\n",
        ")\n",
        "db_multi_qa = Chroma(\n",
        "    collection_name=\"project_store_multi\",\n",
        "    persist_directory=DB_DIR,\n",
        "    client_settings=client_settings,\n",
        "    embedding_function=multi_qa_mini,\n",
        ")\n",
        "\n",
        "# Define 2 diff retrievers with 2 diff embeddings and diff search type.\n",
        "retriever_all = db_all.as_retriever(\n",
        "    search_type=\"similarity\", search_kwargs={\"k\": 5, \"include_metadata\": True}\n",
        ")\n",
        "retriever_multi_qa = db_multi_qa.as_retriever(\n",
        "    search_type=\"mmr\", search_kwargs={\"k\": 5, \"include_metadata\": True}\n",
        ")\n",
        "\n",
        "# The Lord of the Retrievers will hold the output of both retrievers and can be used as any other\n",
        "# retriever on different types of chains.\n",
        "lotr = MergerRetriever(retrievers=[retriever_all, retriever_multi_qa])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c152339d",
      "metadata": {},
      "source": [
        "## 从合并后的检索器中移除冗余结果"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "039faea6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# We can remove redundant results from both retrievers using yet another embedding.\n",
        "# Using multiples embeddings in diff steps could help reduce biases.\n",
        "filter = EmbeddingsRedundantFilter(embeddings=filter_embeddings)\n",
        "pipeline = DocumentCompressorPipeline(transformers=[filter])\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=pipeline, base_retriever=lotr\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c10022fa",
      "metadata": {},
      "source": [
        "## 从合并的检索器中选择具有代表性的文档样本。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3885482",
      "metadata": {},
      "outputs": [],
      "source": [
        "# This filter will divide the documents vectors into clusters or \"centers\" of meaning.\n",
        "# Then it will pick the closest document to that center for the final results.\n",
        "# By default the result document will be ordered/grouped by clusters.\n",
        "filter_ordered_cluster = EmbeddingsClusteringFilter(\n",
        "    embeddings=filter_embeddings,\n",
        "    num_clusters=10,\n",
        "    num_closest=1,\n",
        ")\n",
        "\n",
        "# If you want the final document to be ordered by the original retriever scores\n",
        "# you need to add the \"sorted\" parameter.\n",
        "filter_ordered_by_retriever = EmbeddingsClusteringFilter(\n",
        "    embeddings=filter_embeddings,\n",
        "    num_clusters=10,\n",
        "    num_closest=1,\n",
        "    sorted=True,\n",
        ")\n",
        "\n",
        "pipeline = DocumentCompressorPipeline(transformers=[filter_ordered_by_retriever])\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=pipeline, base_retriever=lotr\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "8f68956e",
      "metadata": {},
      "source": [
        "## 重新排序结果以避免性能下降。\n无论您的模型采用何种架构，当包含 10 篇以上检索到的文档时，都会出现明显的性能下降。\n简而言之：当模型必须在长上下文的中间访问相关信息时，它们往往会忽略提供的文档。\n参见：https://arxiv.org/abs//2307.03172"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "007283f3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# You can use an additional document transformer to reorder documents after removing redundancy.\n",
        "from langchain_community.document_transformers import LongContextReorder\n",
        "\n",
        "filter = EmbeddingsRedundantFilter(embeddings=filter_embeddings)\n",
        "reordering = LongContextReorder()\n",
        "pipeline = DocumentCompressorPipeline(transformers=[filter, reordering])\n",
        "compression_retriever_reordered = ContextualCompressionRetriever(\n",
        "    base_compressor=pipeline, base_retriever=lotr\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}