---
sidebar_label: Graph RAG
description: 使用文档元数据在任何向量存储上进行图遍历。
---

import ChatModelTabs from "@theme/ChatModelTabs";
import EmbeddingTabs from "@theme/EmbeddingTabs";
import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';


# Graph RAG

本指南提供 Graph RAG 的简介。有关所有支持的功能和配置的详细文档，请参阅
[Graph RAG 项目页面](https://datastax.github.io/graph-rag/)。

## 概述

`langchain-graph-retriever` 包中的 `GraphRetriever` 提供了一个 LangChain
[retriever](/docs/concepts/retrievers/)，它将向量上的**非结构化**相似性搜索与
元数据属性的**结构化**遍历相结合。这使得可以在**现有**向量存储上进行基于图的检索。

### 集成详情

| Retriever | Source | PyPI Package | Latest | Project Page |
| :--- | :--- | :---: | :---: | :---: |
| GraphRetriever | [github.com/datastax/graph-rag](https://github.com/datastax/graph-rag/tree/main/packages/langchain-graph-retriever) | [langchain-graph-retriever](https://pypi.org/project/langchain-graph-retriever/) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-graph-retriever?style=flat-square&label=%20&color=orange) | [Graph RAG](https://datastax.github.io/graph-rag/) |


## 优势

* [**基于现有元数据链接：**](https://datastax.github.io/graph-rag/guide/get-started/)
  无需额外处理即可使用现有元数据字段。从现有向量存储中检索更多内容！

* [**按需更改链接：**](https://datastax.github.io/graph-rag/guide/edges/)
  可以即时指定边，从而允许根据问题遍历不同的关系。


* [**可插拔的遍历策略：**](https://datastax.github.io/graph-rag/guide/strategies/)
  使用内置的遍历策略，如 Eager 或 MMR，或定义自定义逻辑来选择要探索的节点。

* [**广泛的兼容性：**](https://datastax.github.io/graph-rag/guide/adapters/)
  为各种向量存储提供了适配器，并且可以轻松添加对其他存储的支持。

## 设置

### 安装

此检索器位于 `langchain-graph-retriever` 包中。

```bash
pip install -qU langchain-graph-retriever
```
## 实例化

以下示例将展示如何遍历有关动物的示例
Documents 来填充各种向量存储。

### 先决条件

<details>
  <summary>点击展开详情</summary>
  <div>
    1. 确保您已安装 Python 3.10+

    1. 安装提供示例数据的以下包。
        ```bash
        pip install -qU graph_rag_example_helpers
        ```

    1. 下载测试文档：
        ```python
        from graph_rag_example_helpers.datasets.animals import fetch_documents
        animals = fetch_documents()
        ```

    1. <EmbeddingTabs/>
  </div>
</details>

### 填充向量存储

本节展示如何将各种向量存储填充入示例数据。

有关选择以下任一向量存储的帮助，或添加对您的
向量存储的支持，请参阅有关
[适配器和支持的存储](https://datastax.github.io/graph-rag/guide/adapters/) 的文档。

<Tabs groupId="vector-store" queryString>
  <TabItem value="astra-db" label="AstraDB" default>
    <div style={{ paddingLeft: '30px' }}>
      使用 `astra` 额外包安装 `langchain-graph-retriever` 包：

      ```bash
      pip install "langchain-graph-retriever[astra]"
      ```

      然后创建一个向量存储并加载测试文档：

      ```python
      from langchain_astradb import AstraDBVectorStore

      vector_store = AstraDBVectorStore.from_documents(
          documents=animals,
          embedding=embeddings,
          collection_name="animals",
          api_endpoint=ASTRA_DB_API_ENDPOINT,
          token=ASTRA_DB_APPLICATION_TOKEN,
      )
      ```
      有关 `ASTRA_DB_API_ENDPOINT` 和 `ASTRA_DB_APPLICATION_TOKEN` 凭证，
      请参阅 [AstraDB 向量存储指南](/docs/integrations/vectorstores/astradb)。

      :::note
      为了进行更快的初步测试，请考虑使用 **内存中 (InMemory)** 向量存储。
      :::
    </div>
  </TabItem>
  <TabItem value="cassandra" label="Apache Cassandra">
    <div style={{ paddingLeft: '30px' }}>
      使用 `cassandra` 额外包安装 `langchain-graph-retriever` 包：

      ```bash
      pip install "langchain-graph-retriever[cassandra]"
      ```

      然后创建一个向量存储并加载测试文档：

      ```python
      from langchain_community.vectorstores.cassandra import Cassandra
      from langchain_graph_retriever.transformers import ShreddingTransformer

      vector_store = Cassandra.from_documents(
          documents=list(ShreddingTransformer().transform_documents(animals)),
          embedding=embeddings,
          table_name="animals",
      )
      ```

      有关创建 Cassandra 连接的帮助，请参阅
      [Apache Cassandra 向量存储指南](/docs/integrations/vectorstores/cassandra#connection-parameters)

      :::note
      Apache Cassandra 不支持在嵌套元数据中搜索。因此，
      在插入文档时有必要使用 [`ShreddingTransformer`](https://datastax.github.io/graph-rag/reference/langchain_graph_retriever/transformers/#langchain_graph_retriever.transformers.shredding.ShreddingTransformer)。
      :::
    </div>
  </TabItem>
  <TabItem value="opensearch" label="OpenSearch">
    <div style={{ paddingLeft: '30px' }}>
      使用 `opensearch` 额外包安装 `langchain-graph-retriever` 包：

      ```bash
      pip install "langchain-graph-retriever[opensearch]"
      ```

      然后创建一个向量存储并加载测试文档：

      ```python
      from langchain_community.vectorstores import OpenSearchVectorSearch

      vector_store = OpenSearchVectorSearch.from_documents(
          documents=animals,
          embedding=embeddings,
          engine="faiss",
          index_name="animals",
          opensearch_url=OPEN_SEARCH_URL,
          bulk_size=500,
      )
      ```

      有关创建 OpenSearch 连接的帮助，请参阅
      [OpenSearch 向量存储指南](/docs/integrations/vectorstores/opensearch)。
    </div>
  </TabItem>
  <TabItem value="chroma" label="Chroma">
    <div style={{ paddingLeft: '30px' }}>
      使用 `chroma` 额外包安装 `langchain-graph-retriever` 包：

      ```bash
      pip install "langchain-graph-retriever[chroma]"
      ```

      然后创建一个向量存储并加载测试文档：

      ```python
      from langchain_chroma.vectorstores import Chroma
      from langchain_graph_retriever.transformers import ShreddingTransformer

      vector_store = Chroma.from_documents(
          documents=list(ShreddingTransformer().transform_documents(animals)),
          embedding=embeddings,
          collection_name="animals",
      )
      ```

      有关创建 Chroma 连接的帮助，请参阅
      [Chroma 向量存储指南](/docs/integrations/vectorstores/chroma)。

      :::note
      Chroma 不支持在嵌套元数据中搜索。因此，
      在插入文档时有必要使用 [`ShreddingTransformer`](https://datastax.github.io/graph-rag/reference/langchain_graph_retriever/transformers/#langchain_graph_retriever.transformers.shredding.ShreddingTransformer)。
      :::
    </div>
  </TabItem>
  <TabItem value="in-memory" label="InMemory" default>
    <div style={{ paddingLeft: '30px' }}>
      安装 `langchain-graph-retriever` 包：

      ```bash
      pip install "langchain-graph-retriever"
      ```

      然后创建一个向量存储并加载测试文档：

      ```python
      from langchain_core.vectorstores import InMemoryVectorStore

      vector_store = InMemoryVectorStore.from_documents(
          documents=animals,
          embedding=embeddings,
      )
      ```

      :::tip
      使用 `InMemoryVectorStore` 是开始使用 Graph RAG 最快的方法，
      但它不推荐用于生产环境。建议改用
      **AstraDB** 或 **OpenSearch**。
      :::
    </div>
  </TabItem>
</Tabs>

### 图遍历

此图检索器从一个与查询最匹配的动物开始，然后
遍历具有相同 `habitat` 和/或 `origin` 的其他动物。

  ```python
  from graph_retriever.strategies import Eager
  from langchain_graph_retriever import GraphRetriever

  traversal_retriever = GraphRetriever(
      store = vector_store,
      edges = [("habitat", "habitat"), ("origin", "origin")],
      strategy = Eager(k=5, start_k=1, max_depth=2),
  )
  ```

上述代码创建了一个图遍历检索器，它从最近的
动物 (`start_k=1`) 开始，检索 5 个文档 (`k=5`)，并将搜索限制在距离第一只动物最多 2 步的文档 (`max_depth=2`) 中。

`edges` 定义了如何使用元数据值进行遍历。在此案例中，每只
动物都与具有相同 `habitat` 和/或 `origin` 的其他动物相连接。

```python
results = traversal_retriever.invoke("what animals could be found near a capybara?")

for doc in results:
    print(f"{doc.id}: {doc.page_content}")
```

```output
capybara: capybaras are the largest rodents in the world and are highly social animals.
heron: herons are wading birds known for their long legs and necks, often seen near water.
crocodile: crocodiles are large reptiles with powerful jaws and a long lifespan, often living over 70 years.
frog: frogs are amphibians known for their jumping ability and croaking sounds.
duck: ducks are waterfowl birds known for their webbed feet and quacking sounds.
```

图遍历通过利用数据中的结构化关系来提高检索质量。与标准的相似性搜索（如下所示）不同，它提供了清晰、可解释的原因来说明检索到的文档。

在此示例中，`capybara`、`heron`、`frog`、`crocodile` 和 `newt` 文档都具有相同的 `habitat=wetlands`（根据它们的元数据定义）。这应能提高文档相关性并增加 LLM 回答的质量。

### 与标准检索的比较

当 `max_depth=0` 时，图遍历检索器的行为类似于标准检索器：

```python
standard_retriever = GraphRetriever(
    store = vector_store,
    edges = [("habitat", "habitat"), ("origin", "origin")],
    strategy = Eager(k=5, start_k=5, max_depth=0),
)
```

这将创建一个检索器，它以最近的 5 只动物 (`start_k=5`) 开始，
并在没有任何遍历的情况下返回它们 (`max_depth=0`)。在此情况下将忽略边定义。

这本质上与以下代码相同：

```python
standard_retriever = vector_store.as_retriever(search_kwargs={"k":5})
```

在这两种情况下，调用检索器都会返回：

```python
results = standard_retriever.invoke("what animals could be found near a capybara?")

for doc in results:
    print(f"{doc.id}: {doc.page_content}")
```

```output
capybara: capybaras are the largest rodents in the world and are highly social animals.
iguana: iguanas are large herbivorous lizards often found basking in trees and near water.
guinea pig: guinea pigs are small rodents often kept as pets due to their gentle and social nature.
hippopotamus: hippopotamuses are large semi-aquatic mammals known for their massive size and territorial behavior.
boar: boars are wild relatives of pigs, known for their tough hides and tusks.
```

这些文档仅基于相似性进行联接。存储中存在的任何结构化数据都会被忽略。与图检索相比，这可能会降低文档相关性，因为返回的结果对回答查询的帮助可能性较低。

## 用法

按照上面的示例，使用 `.invoke` 来根据查询启动检索。

## 在链中使用

与其他检索器一样，`GraphRetriever` 可以通过
[chains](/docs/how_to/sequence/) 集成到 LLM 应用程序中。

<ChatModelTabs customVarName="llm" />

```python
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough

prompt = ChatPromptTemplate.from_template(
"""根据提供的上下文回答问题。

上下文： {context}

问题： {question}"""
)

def format_docs(docs):
    return "\n\n".join(f"text: {doc.page_content} metadata: {doc.metadata}" for doc in docs)

chain = (
    {"context": traversal_retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)
```

```python
chain.invoke("what animals could be found near a capybara?")
```

```output
生活在水边的动物，如水鸟、鳄鱼、青蛙和鸭子，可能在水豚附近被发现。
```

## API 参考

要查看所有可用的参数和高级配置，请参阅
[Graph RAG API 参考](https://datastax.github.io/graph-rag/reference/)。