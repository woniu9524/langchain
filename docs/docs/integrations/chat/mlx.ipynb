{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MLX\n\n本 Notebook 展示如何开始使用 `MLX` LLM 作为聊天模型。\n\n具体来说，我们将：\n1. 使用 [MLXPipeline](https://github.com/langchain-ai/langchain/blob/master/libs/community/langchain_community/llms/mlx_pipeline.py)，\n2. 使用 `ChatMLX` 类来使任何这些 LLM 能够与 LangChain 的 [Chat Messages](https://python.langchain.com/docs/modules/model_io/chat/#messages) 抽象进行接口连接。\n3. 演示如何使用开源 LLM 来驱动 `ChatAgent` 管道。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet  mlx-lm transformers huggingface_hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 实例化一个 LLM\n\n有三种 LLM 选项可供选择。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.llms.mlx_pipeline import MLXPipeline\n",
        "\n",
        "llm = MLXPipeline.from_model_id(\n",
        "    \"mlx-community/quantized-gemma-2b-it\",\n",
        "    pipeline_kwargs={\"max_tokens\": 10, \"temp\": 0.1},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 实例化 `ChatMLX` 应用聊天模板"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "实例化聊天模型和要传递的一些消息。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.chat_models.mlx import ChatMLX\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "messages = [\n",
        "    HumanMessage(\n",
        "        content=\"What happens when an unstoppable force meets an immovable object?\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "chat_model = ChatMLX(llm=llm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "检查聊天消息的 LLM 调用格式。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "chat_model._to_chat_prompt(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "调用模型。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "res = chat_model.invoke(messages)\n",
        "print(res.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 将其作为代理进行试用！\n\n在这里，我们将测试 `gemma-2b-it` 作为零样本 `ReAct` Agent。下面的示例摘自[此处](https://python.langchain.com/docs/modules/agents/agent_types/react#using-chat-models)。\n\n> 注意：要运行此部分，您需要将一个 [SerpAPI Token](https://serpapi.com/) 保存为环境变量：`SERPAPI_API_KEY`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain import hub\n",
        "from langchain.agents import AgentExecutor, load_tools\n",
        "from langchain.agents.format_scratchpad import format_log_to_str\n",
        "from langchain.agents.output_parsers import (\n",
        "    ReActJsonSingleInputOutputParser,\n",
        ")\n",
        "from langchain.tools.render import render_text_description\n",
        "from langchain_community.utilities import SerpAPIWrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "配置代理，使其使用 `react-json` 风格的提示，并能访问搜索引擎和计算器。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# setup tools\n",
        "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
        "\n",
        "# setup ReAct style prompt\n",
        "# Based on 'hwchase17/react' prompt modification, cause mlx does not support the `System` role\n",
        "human_prompt = \"\"\"\n",
        "Answer the following questions as best you can. You have access to the following tools:\n",
        "\n",
        "{tools}\n",
        "\n",
        "The way you use the tools is by specifying a json blob.\n",
        "Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n",
        "\n",
        "The only values that should be in the \"action\" field are: {tool_names}\n",
        "\n",
        "The $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\n",
        "\n",
        "```\n",
        "{{\n",
        "  \"action\": $TOOL_NAME,\n",
        "  \"action_input\": $INPUT\n",
        "}}\n",
        "```\n",
        "\n",
        "ALWAYS use the following format:\n",
        "\n",
        "Question: the input question you must answer\n",
        "Thought: you should always think about what to do\n",
        "Action:\n",
        "```\n",
        "$JSON_BLOB\n",
        "```\n",
        "Observation: the result of the action\n",
        "... (this Thought/Action/Observation can repeat N times)\n",
        "Thought: I now know the final answer\n",
        "Final Answer: the final answer to the original input question\n",
        "\n",
        "Begin! Reminder to always use the exact characters `Final Answer` when responding.\n",
        "\n",
        "{input}\n",
        "\n",
        "{agent_scratchpad}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "prompt = human_prompt.partial(\n",
        "    tools=render_text_description(tools),\n",
        "    tool_names=\", \".join([t.name for t in tools]),\n",
        ")\n",
        "\n",
        "# define the agent\n",
        "chat_model_with_stop = chat_model.bind(stop=[\"\\nObservation\"])\n",
        "agent = (\n",
        "    {\n",
        "        \"input\": lambda x: x[\"input\"],\n",
        "        \"agent_scratchpad\": lambda x: format_log_to_str(x[\"intermediate_steps\"]),\n",
        "    }\n",
        "    | prompt\n",
        "    | chat_model_with_stop\n",
        "    | ReActJsonSingleInputOutputParser()\n",
        ")\n",
        "\n",
        "# instantiate AgentExecutor\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "agent_executor.invoke(\n",
        "    {\n",
        "        \"input\": \"Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?\"\n",
        "    }\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}