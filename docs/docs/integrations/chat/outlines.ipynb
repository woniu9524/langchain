{
  "cells": [
    {
      "cell_type": "raw",
      "id": "afaf8039",
      "metadata": {},
      "source": [
        "---\n",
        "sidebar_label: Outlines\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e49f1e0d",
      "metadata": {},
      "source": [
        "# ChatOutlines\n\n该指南将帮助您开始使用 Outlines [chat models](/docs/concepts/chat_models/)。如需获取 ChatOutlines 所有功能和配置的详细文档，请访问 [API reference](https://python.langchain.com/api_reference/community/chat_models/langchain_community.chat_models.outlines.ChatOutlines.html)。\n\n[Outlines](https://github.com/outlines-dev/outlines) 是一个用于受限语言生成的库。它允许您使用各种后端的大型语言模型（LLMs），同时对生成的输出应用约束。\n\n## 概览\n### 集成详情\n\n| Class | Package | Local | Serializable | JS support | Package downloads | Package latest |\n| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\n| [ChatOutlines](https://python.langchain.com/api_reference/community/chat_models/langchain_community.chat_models.outlines.ChatOutlines.html) | [langchain-community](https://python.langchain.com/api_reference/community/index.html) | ✅ | ❌ | ❌ | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-community?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-community?style=flat-square&label=%20) |\n\n### 模型特性\n| [Tool calling](/docs/how_to/tool_calling) | [Structured output](/docs/how_to/structured_output/) | JSON mode | [Image input](/docs/how_to/multimodal_inputs/) | Audio input | Video input | [Token-level streaming](/docs/how_to/chat_streaming/) | Native async | [Token usage](/docs/how_to/chat_token_usage_tracking/) | [Logprobs](/docs/how_to/logprobs/) |\n| :---: | :---: | :---: | :---: |  :---: | :---: | :---: | :---: | :---: | :---: |\n| ✅ | ✅ | ✅ | ✅ | ❌ | ❌ | ✅ | ❌ | ❌ | ❌ | \n\n## 设置\n\n要访问 Outlines 模型，您需要有互联网连接以下载模型权重从 huggingface。根据不同的后端，您需要安装所需的依赖项（请参阅 [Outlines docs](https://dottxt-ai.github.io/outlines/latest/installation/)）。\n\n### 凭证\n\nOutlines 没有内置的身份验证机制。\n\n### 安装\n\nLangChain Outlines 集成位于 `langchain-community` 包中，并且需要 `outlines` 库："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "652d6238-1f87-422a-b135-f5abbb8652fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -qU langchain-community outlines"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a38cde65-254d-4219-a441-068766c0d4b5",
      "metadata": {},
      "source": [
        "## 实例化\n\n现在我们可以实例化我们的模型对象并生成聊天补全："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb09c344-1836-4e0c-acf8-11d13ac1dbae",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.chat_models.outlines import ChatOutlines\n",
        "\n",
        "# For llamacpp backend\n",
        "model = ChatOutlines(model=\"TheBloke/phi-2-GGUF/phi-2.Q4_K_M.gguf\", backend=\"llamacpp\")\n",
        "\n",
        "# For vllm backend (not available on Mac)\n",
        "model = ChatOutlines(model=\"meta-llama/Llama-3.2-1B\", backend=\"vllm\")\n",
        "\n",
        "# For mlxlm backend (only available on Mac)\n",
        "model = ChatOutlines(model=\"mistralai/Ministral-8B-Instruct-2410\", backend=\"mlxlm\")\n",
        "\n",
        "# For huggingface transformers backend\n",
        "model = ChatOutlines(model=\"microsoft/phi-2\")  # defaults to transformers backend"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b4f3e15",
      "metadata": {},
      "source": [
        "## 调用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62e0dbc3",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "messages = [HumanMessage(content=\"What will the capital of mars be called?\")]\n",
        "response = model.invoke(messages)\n",
        "\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18e2bfc0-7e78-4528-a73f-499ac150dca8",
      "metadata": {},
      "source": [
        "## 流式传输\n\nChatOutlines 支持向外流式传输 token："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e197d1d7-a070-4c96-9f8a-a0e86d046e0b",
      "metadata": {},
      "outputs": [],
      "source": [
        "messages = [HumanMessage(content=\"Count to 10 in French:\")]\n",
        "\n",
        "for chunk in model.stream(messages):\n",
        "    print(chunk.content, end=\"\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccc3e2f6",
      "metadata": {},
      "source": [
        "## 链式调用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a032003",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a helpful assistant that translates {input_language} to {output_language}.\",\n",
        "        ),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt | model\n",
        "chain.invoke(\n",
        "    {\n",
        "        \"input_language\": \"English\",\n",
        "        \"output_language\": \"German\",\n",
        "        \"input\": \"I love programming.\",\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1ee55bc-ffc8-4cfa-801c-993953a08cfd",
      "metadata": {},
      "source": [
        "## 受约束的生成\n\nChatOutlines 允许你对生成的输出应用各种约束：\n\n### 正则表达式约束"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a5bb5ca-c3ae-4a58-be67-2cd18574b9a3",
      "metadata": {},
      "outputs": [],
      "source": [
        "model.regex = r\"((25[0-5]|2[0-4]\\d|[01]?\\d\\d?)\\.){3}(25[0-5]|2[0-4]\\d|[01]?\\d\\d?)\"\n",
        "\n",
        "response = model.invoke(\"What is the IP address of Google's DNS server?\")\n",
        "\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a5bb5ca-c3ae-4a58-be67-2cd18574b9a3",
      "metadata": {},
      "source": [
        "### 类型约束"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a5bb5ca-c3ae-4a58-be67-2cd18574b9a3",
      "metadata": {},
      "outputs": [],
      "source": [
        "model.type_constraints = int\n",
        "response = model.invoke(\"What is the answer to life, the universe, and everything?\")\n",
        "\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a5bb5ca-c3ae-4a58-be67-2cd18574b9a3",
      "metadata": {},
      "source": [
        "### Pydantic 和 JSON Schemas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a5bb5ca-c3ae-4a58-be67-2cd18574b9a3",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "\n",
        "class Person(BaseModel):\n",
        "    name: str\n",
        "\n",
        "\n",
        "model.json_schema = Person\n",
        "response = model.invoke(\"Who are the main contributors to LangChain?\")\n",
        "person = Person.model_validate_json(response.content)\n",
        "\n",
        "person"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a5bb5ca-c3ae-4a58-be67-2cd18574b9a3",
      "metadata": {},
      "source": [
        "### 上下文无关文法"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a5bb5ca-c3ae-4a58-be67-2cd18574b9a3",
      "metadata": {},
      "outputs": [],
      "source": [
        "model.grammar = \"\"\"\n",
        "?start: expression\n",
        "?expression: term ((\"+\" | \"-\") term)*\n",
        "?term: factor ((\"*\" | \"/\") factor)*\n",
        "?factor: NUMBER | \"-\" factor | \"(\" expression \")\"\n",
        "%import common.NUMBER\n",
        "%import common.WS\n",
        "%ignore WS\n",
        "\"\"\"\n",
        "response = model.invoke(\"Give me a complex arithmetic expression:\")\n",
        "\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa5bb5ca-c3ae-4a58-be67-2cd18574b9a3",
      "metadata": {},
      "source": [
        "## LangChain 的结构化输出\n\n你也可以将 LangChain 的结构化输出与 ChatOutlines 结合使用："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba5bb5ca-c3ae-4a58-be67-2cd18574b9a3",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "\n",
        "class AnswerWithJustification(BaseModel):\n",
        "    answer: str\n",
        "    justification: str\n",
        "\n",
        "\n",
        "_model = model.with_structured_output(AnswerWithJustification)\n",
        "result = _model.invoke(\"What weighs more, a pound of bricks or a pound of feathers?\")\n",
        "\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca5bb5ca-c3ae-4a58-be67-2cd18574b9a3",
      "metadata": {},
      "source": [
        "## API 参考\n\n如需了解 ChatOutlines 所有功能和配置的详细文档，请前往 API 参考：https://python.langchain.com/api_reference/community/chat_models/langchain_community.chat_models.outlines.ChatOutlines.html\n\n## Outlines 全套文档：\n\nhttps://dottxt-ai.github.io/outlines/latest/"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}