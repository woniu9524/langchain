{
  "cells": [
    {
      "cell_type": "raw",
      "id": "53fbf15f",
      "metadata": {},
      "source": [
        "---\n",
        "sidebar_label: MistralAI\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d295c2a2",
      "metadata": {},
      "source": [
        "# ChatMistralAI\n\n这将帮助您开始使用 Mistral [聊天模型](/docs/concepts/chat_models)。有关 `ChatMistralAI` 所有功能和配置的详细文档，请前往 [API 参考](https://python.langchain.com/api_reference/mistralai/chat_models/langchain_mistralai.chat_models.ChatMistralAI.html)。`ChatMistralAI` 类建立在 [Mistral API](https://docs.mistral.ai/api/) 之上。有关 Mistral 支持的所有模型列表，请查看 [此页面](https://docs.mistral.ai/getting-started/models/)。\n\n## 概述\n### 集成详情\n\n| 类 | 包 | 本地支持 | 可序列化 | [JS 支持](https://js.langchain.com/docs/integrations/chat/mistral) | 包下载量 | 包最新版本 |\n| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\n| [ChatMistralAI](https://python.langchain.com/api_reference/mistralai/chat_models/langchain_mistralai.chat_models.ChatMistralAI.html) | [langchain_mistralai](https://python.langchain.com/api_reference/mistralai/index.html) | ❌ | beta | ✅ | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain_mistralai?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain_mistralai?style=flat-square&label=%20) |\n\n### 模型特性\n| [工具调用](/docs/how_to/tool_calling) | [结构化输出](/docs/how_to/structured_output/) | JSON 模式 | [图像输入](/docs/how_to/multimodal_inputs/) | 音频输入 | 视频输入 | [Token 级流式输出](/docs/how_to/chat_streaming/) | 原生异步 | [Token 使用量](/docs/how_to/chat_token_usage_tracking/) | [Logprobs](/docs/how_to/logprobs/) |\n| :---: | :---: | :---: | :---: |  :---: | :---: | :---: | :---: | :---: | :---: |\n| ✅ | ✅ | ✅ | ❌ | ❌ | ❌ | ✅ | ✅ | ✅ | ❌ |\n\n## 设置\n\n要访问 `ChatMistralAI` 模型，您需要创建一个 Mistral 帐户，获取 API 密钥，并安装 `langchain_mistralai` 集成包。\n\n### 凭据\n\n需要有效的 [API 密钥](https://console.mistral.ai/api-keys/)才能与 API 通信。完成此操作后，请设置 MISTRAL_API_KEY 环境变量："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2461605e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"MISTRAL_API_KEY\" not in os.environ:\n",
        "    os.environ[\"MISTRAL_API_KEY\"] = getpass.getpass(\"Enter your Mistral API key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "788f37ac",
      "metadata": {},
      "source": "为了启用模型调用的自动化跟踪，请设置您的 [LangSmith](https://docs.smith.langchain.com/) API 密钥："
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "007209d5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n",
        "# os.environ[\"LANGSMITH_TRACING\"] = \"true\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f5c74f9",
      "metadata": {},
      "source": [
        "### 安装\n\nLangChain Mistral 集成位于 `langchain_mistralai` 包中："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ab11a65",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -qU langchain_mistralai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb1a335e",
      "metadata": {},
      "source": [
        "## 实例化\n\n现在我们可以实例化我们的模型对象并生成聊天补全了："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e6c38580",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_mistralai import ChatMistralAI\n",
        "\n",
        "llm = ChatMistralAI(\n",
        "    model=\"mistral-large-latest\",\n",
        "    temperature=0,\n",
        "    max_retries=2,\n",
        "    # other params...\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aec79099",
      "metadata": {},
      "source": [
        "## 调用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8838c3cc",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Sure, I\\'d be happy to help you translate that sentence into French! The English sentence \"I love programming\" translates to \"J\\'aime programmer\" in French. Let me know if you have any other questions or need further assistance!', response_metadata={'token_usage': {'prompt_tokens': 32, 'total_tokens': 84, 'completion_tokens': 52}, 'model': 'mistral-small', 'finish_reason': 'stop'}, id='run-64bac156-7160-4b68-b67e-4161f63e021f-0', usage_metadata={'input_tokens': 32, 'output_tokens': 52, 'total_tokens': 84})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages = [\n",
        "    (\n",
        "        \"system\",\n",
        "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
        "    ),\n",
        "    (\"human\", \"I love programming.\"),\n",
        "]\n",
        "ai_msg = llm.invoke(messages)\n",
        "ai_msg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bbf6a048",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sure, I'd be happy to help you translate that sentence into French! The English sentence \"I love programming\" translates to \"J'aime programmer\" in French. Let me know if you have any other questions or need further assistance!\n"
          ]
        }
      ],
      "source": [
        "print(ai_msg.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32b87f87",
      "metadata": {},
      "source": [
        "## Chaining\n\n我们可以像这样将我们的模型与提示模板进行 [链接](/docs/how_to/sequence/)："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "24e2c51c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Ich liebe Programmierung. (German translation)', response_metadata={'token_usage': {'prompt_tokens': 26, 'total_tokens': 38, 'completion_tokens': 12}, 'model': 'mistral-small', 'finish_reason': 'stop'}, id='run-dfd4094f-e347-47b0-9056-8ebd7ea35fe7-0', usage_metadata={'input_tokens': 26, 'output_tokens': 12, 'total_tokens': 38})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a helpful assistant that translates {input_language} to {output_language}.\",\n",
        "        ),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt | llm\n",
        "chain.invoke(\n",
        "    {\n",
        "        \"input_language\": \"English\",\n",
        "        \"output_language\": \"German\",\n",
        "        \"input\": \"I love programming.\",\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb9b5834",
      "metadata": {},
      "source": [
        "## API 参考\n\n请前往 [API 参考](https://python.langchain.com/api_reference/mistralai/chat_models/langchain_mistralai.chat_models.ChatMistralAI.html) 获取所有属性和方法的详细文档。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}