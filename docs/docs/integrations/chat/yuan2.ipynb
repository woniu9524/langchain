{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% raw\n"
        }
      },
      "source": [
        "---\n",
        "sidebar_label: Yuan2.0\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Yuan2.0\n\n本 Notebook 展示了如何在 LangChain 中使用 [YUAN2 API](https://github.com/IEIT-Yuan/Yuan-2.0/blob/main/docs/inference_server.md)，通过 langchain.chat_models.ChatYuan2。\n\n[*Yuan2.0*](https://github.com/IEIT-Yuan/Yuan-2.0/blob/main/README-EN.md) 是由 IEIT System 开发的新一代基础大语言模型。我们已发布了 Yuan 2.0-102B、Yuan 2.0-51B 和 Yuan 2.0-2B 这三个模型，并为其他开发者提供了预训练、微调和推理服务的相关脚本。Yuan2.0 基于 Yuan1.0，利用了更广泛的高质量预训练数据和指令微调数据集，以增强模型在语义、数学、推理、代码、知识等方面的理解能力。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## 入门\n\n### 安装\n\n首先，Yuan2.0 提供了一个与 OpenAI 兼容的 API，我们通过 OpenAI 客户端将 ChatYuan2 集成到 langchain 的 chat 模型中。\n\n因此，请确保你的 Python 环境中已安装 openai 包。运行以下命令："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### 导入所需模块\n安装完成后，请将必要的模块导入到您的 Python 脚本中："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from langchain_community.chat_models import ChatYuan2\n",
        "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### 设置您的 API 服务器\n按照 [yuan2 openai api server](https://github.com/IEIT-Yuan/Yuan-2.0/blob/main/docs/Yuan2_fastchat.md) 的说明设置您的 OpenAI 兼容 API 服务器。\n如果您在本地部署了 API 服务器，您可以将 `yuan2_api_key` 设置为 `\"EMPTY\"` 或任何您想要的值。\n请确保 `yuan2_api_base` 设置正确。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "yuan2_api_key = \"your_api_key\"\n",
        "yuan2_api_base = \"http://127.0.0.1:8001/v1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### 初始化 ChatYuan2 模型\n以下是如何初始化聊天模型："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "chat = ChatYuan2(\n",
        "    yuan2_api_base=\"http://127.0.0.1:8001/v1\",\n",
        "    temperature=1.0,\n",
        "    model_name=\"yuan2\",\n",
        "    max_retries=3,\n",
        "    streaming=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### 基本用法\n像这样使用系统和用户消息来调用模型："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "messages = [\n",
        "    SystemMessage(content=\"你是一个人工智能助手。\"),\n",
        "    HumanMessage(content=\"你好，你是谁？\"),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "print(chat.invoke(messages))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### 基础用法（流式输出）\n如需实现持续互动，请使用流式输出功能："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from langchain_core.callbacks import StreamingStdOutCallbackHandler\n",
        "\n",
        "chat = ChatYuan2(\n",
        "    yuan2_api_base=\"http://127.0.0.1:8001/v1\",\n",
        "    temperature=1.0,\n",
        "    model_name=\"yuan2\",\n",
        "    max_retries=3,\n",
        "    streaming=True,\n",
        "    callbacks=[StreamingStdOutCallbackHandler()],\n",
        ")\n",
        "messages = [\n",
        "    SystemMessage(content=\"你是个旅游小助手。\"),\n",
        "    HumanMessage(content=\"给我介绍一下北京有哪些好玩的。\"),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "chat.invoke(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## 高级功能\n### 配合异步调用使用\n\n像这样，使用非阻塞调用来调用模型："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "async def basic_agenerate():\n",
        "    chat = ChatYuan2(\n",
        "        yuan2_api_base=\"http://127.0.0.1:8001/v1\",\n",
        "        temperature=1.0,\n",
        "        model_name=\"yuan2\",\n",
        "        max_retries=3,\n",
        "    )\n",
        "    messages = [\n",
        "        [\n",
        "            SystemMessage(content=\"你是个旅游小助手。\"),\n",
        "            HumanMessage(content=\"给我介绍一下北京有哪些好玩的。\"),\n",
        "        ]\n",
        "    ]\n",
        "\n",
        "    result = await chat.agenerate(messages)\n",
        "    print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "\n",
        "asyncio.run(basic_agenerate())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### 与提示词模板结合使用\n\n使用非阻塞调用并像这样使用聊天模板来调用模型："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "async def ainvoke_with_prompt_template():\n",
        "    from langchain_core.prompts.chat import (\n",
        "        ChatPromptTemplate,\n",
        "    )\n",
        "\n",
        "    chat = ChatYuan2(\n",
        "        yuan2_api_base=\"http://127.0.0.1:8001/v1\",\n",
        "        temperature=1.0,\n",
        "        model_name=\"yuan2\",\n",
        "        max_retries=3,\n",
        "    )\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", \"你是一个诗人，擅长写诗。\"),\n",
        "            (\"human\", \"给我写首诗，主题是{theme}。\"),\n",
        "        ]\n",
        "    )\n",
        "    chain = prompt | chat\n",
        "    result = await chain.ainvoke({\"theme\": \"明月\"})\n",
        "    print(f\"type(result): {type(result)}; {result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "asyncio.run(ainvoke_with_prompt_template())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### 在流式处理中使用异步调用\n对于具有流式输出的非阻塞调用，请使用 `astream` 方法："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "async def basic_astream():\n",
        "    chat = ChatYuan2(\n",
        "        yuan2_api_base=\"http://127.0.0.1:8001/v1\",\n",
        "        temperature=1.0,\n",
        "        model_name=\"yuan2\",\n",
        "        max_retries=3,\n",
        "    )\n",
        "    messages = [\n",
        "        SystemMessage(content=\"你是个旅游小助手。\"),\n",
        "        HumanMessage(content=\"给我介绍一下北京有哪些好玩的。\"),\n",
        "    ]\n",
        "    result = chat.astream(messages)\n",
        "    async for chunk in result:\n",
        "        print(chunk.content, end=\"\", flush=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        },
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "\n",
        "asyncio.run(basic_astream())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}