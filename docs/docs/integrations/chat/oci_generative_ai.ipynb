{
  "cells": [
    {
      "cell_type": "raw",
      "id": "afaf8039",
      "metadata": {},
      "source": [
        "---\n",
        "sidebar_label: OCIGenAI\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e49f1e0d",
      "metadata": {},
      "source": [
        "# ChatOCIGenAI\n\n本笔记本提供了关于 OCIGenAI [chat models](/docs/concepts/chat_models) 的快速入门指南。如需了解 ChatOCIGenAI 的所有功能和配置的详细文档，请前往 [API reference](https://python.langchain.com/api_reference/community/chat_models/langchain_community.chat_models.oci_generative_ai.ChatOCIGenAI.html)。\n\nOracle Cloud Infrastructure (OCI) Generative AI 是一项完全托管的服务，提供一系列先进的、可定制的大型语言模型 (LLMs)，可满足广泛的应用场景，并通过单一 API 进行访问。\n使用 OCI Generative AI 服务，您可以访问现成的预训练模型，或者根据您自己的数据，在专用的 AI 集群上创建和托管您自己的微调自定义模型。有关服务和 API 的详细文档，请__[在此](https://docs.oracle.com/en-us/iaas/Content/generative-ai/home.htm)__ 和__[此](https://docs.oracle.com/en-us/iaas/api/#/en/generative-ai/20231130/)__ 链接中查看。\n\n\n## 概览\n### 集成详情\n\n| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/docs/integrations/chat/oci_generative_ai) |\n| :--- | :--- | :---: | :---: |  :---: |\n| [ChatOCIGenAI](https://python.langchain.com/api_reference/community/chat_models/langchain_community.chat_models.oci_generative_ai.ChatOCIGenAI.html) | [langchain-community](https://python.langchain.com/api_reference/community/index.html) | ❌ | ❌ | ❌ |\n\n### 模型功能\n| [Tool calling](/docs/how_to/tool_calling/) | [Structured output](/docs/how_to/structured_output/) | [JSON mode](/docs/how_to/structured_output/#advanced-specifying-the-method-for-structuring-outputs) | [Image input](/docs/how_to/multimodal_inputs/) | Audio input | Video input | [Token-level streaming](/docs/how_to/chat_streaming/) | Native async | [Token usage](/docs/how_to/chat_token_usage_tracking/) | [Logprobs](/docs/how_to/logprobs/) |\n| :---: | :---: | :---: | :---: |  :---: | :---: | :---: | :---: | :---: | :---: |\n| ✅ | ✅ | ✅ | ✅ | ❌ | ❌ | ✅ | ❌ | ❌ | ❌ | \n\n## 设置\n\n要访问 OCIGenAI 模型，您需要安装 `oci` 和 `langchain-community` 包。\n\n### 凭证\n\n此集成支持的凭证和身份验证方法等同于用于其他 OCI 服务的凭证和身份验证方法，并遵循__标准 SDK 身份验证（Standard SDK Authentication）__方法，特别是 API Key、session token、instance principal 和 resource principal。\n\nAPI Key 是上述示例中默认使用的身份验证方法。以下示例展示了如何使用其他身份验证方法（session token）"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0730d6a1-c893-4840-9817-5e5251676d5d",
      "metadata": {},
      "source": [
        "### 安装\n\nLangChain OCIGenAI 集成位于 `langchain-community` 包中，您还需要安装 `oci` 包："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "652d6238-1f87-422a-b135-f5abbb8652fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -qU langchain-community oci"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a38cde65-254d-4219-a441-068766c0d4b5",
      "metadata": {},
      "source": [
        "## 实例化\n\n现在我们可以实例化我们的模型对象并生成聊天补全："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb09c344-1836-4e0c-acf8-11d13ac1dbae",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.chat_models.oci_generative_ai import ChatOCIGenAI\n",
        "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
        "\n",
        "chat = ChatOCIGenAI(\n",
        "    model_id=\"cohere.command-r-16k\",\n",
        "    service_endpoint=\"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\",\n",
        "    compartment_id=\"MY_OCID\",\n",
        "    model_kwargs={\"temperature\": 0.7, \"max_tokens\": 500},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b4f3e15",
      "metadata": {},
      "source": [
        "## 调用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62e0dbc3",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "messages = [\n",
        "    SystemMessage(content=\"your are an AI assistant.\"),\n",
        "    AIMessage(content=\"Hi there human!\"),\n",
        "    HumanMessage(content=\"tell me a joke.\"),\n",
        "]\n",
        "response = chat.invoke(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d86145b3-bfef-46e8-b227-4dda5c9c2705",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18e2bfc0-7e78-4528-a73f-499ac150dca8",
      "metadata": {},
      "source": [
        "## 链式调用\n\n我们可以像下面这样，将我们的模型与提示模板链式调用："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e197d1d7-a070-4c96-9f8a-a0e86d046e0b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
        "chain = prompt | chat\n",
        "\n",
        "response = chain.invoke({\"topic\": \"dogs\"})\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a5bb5ca-c3ae-4a58-be67-2cd18574b9a3",
      "metadata": {},
      "source": [
        "## API 参考\n\n有关所有 ChatOCIGenAI 功能和配置的详细文档，请访问 API 参考：https://python.langchain.com/api_reference/community/chat_models/langchain_community.chat_models.oci_generative_ai.ChatOCIGenAI.html"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}