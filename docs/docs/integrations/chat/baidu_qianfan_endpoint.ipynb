{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "sidebar_label: Baidu Qianfan\n",
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# QianfanChatEndpoint\n\n百度智能云千帆平台是面向企业开发者的一站式大模型开发与服务运营平台。千帆不仅提供文心一言（ERNIE-Bot）等模型及第三方开源模型，还提供各种 AI 开发工具和完整的开发环境，方便客户轻松使用和开发大模型应用。\n\n基本上，这些模型分为以下几种类型：\n\n- Embedding\n- Chat\n- Completion\n\n在本 Notebook 中，我们将介绍如何在 langchain 中使用 [Qianfan](https://cloud.baidu.com/doc/WENXINWORKSHOP/index.html)，主要针对 langchain 中 `langchain/chat_models` 包对应的 `Chat` 模型：\n\n## API 初始化\n\n要使用基于百度千帆的 LLM 服务，您必须初始化以下参数：\n\n您可以选择在环境变量中初始化 AK、SK 或通过初始化参数传入：\n\n```base\nexport QIANFAN_AK=XXX\nexport QIANFAN_SK=XXX\n```\n\n## 当前支持的模型：\n\n- ERNIE-Bot-turbo （默认模型）\n- ERNIE-Bot\n- BLOOMZ-7B\n- Llama-2-7b-chat\n- Llama-2-13b-chat\n- Llama-2-70b-chat\n- Qianfan-BLOOMZ-7B-compressed\n- Qianfan-Chinese-Llama-2-7B\n- ChatGLM2-6B-32K\n- AquilaChat-7B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 设置"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"For basic init and call\"\"\"\n",
        "import os\n",
        "\n",
        "from langchain_community.chat_models import QianfanChatEndpoint\n",
        "from langchain_core.language_models.chat_models import HumanMessage\n",
        "\n",
        "os.environ[\"QIANFAN_AK\"] = \"Your_api_key\"\n",
        "os.environ[\"QIANFAN_SK\"] = \"You_secret_Key\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 用法"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='您好！请问您需要什么帮助？我将尽力回答您的问题。')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat = QianfanChatEndpoint(streaming=True)\n",
        "messages = [HumanMessage(content=\"Hello\")]\n",
        "chat.invoke(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='您好！有什么我可以帮助您的吗？')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "await chat.ainvoke(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[AIMessage(content='您好！有什么我可以帮助您的吗？')]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat.batch([messages])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 流式传输"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "您好！有什么我可以帮助您的吗？\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    for chunk in chat.stream(messages):\n",
        "        print(chunk.content, end=\"\", flush=True)\n",
        "except TypeError as e:\n",
        "    print(\"\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 在千帆使用不同的模型\n\n默认模型是 ERNIE-Bot-turbo。如果你想部署基于文心大模型或其他第三方开源模型自研的模型，可以遵循以下步骤：\n\n1. (可选，如果模型包含在默认模型中，则跳过此步骤) 在千帆控制台中部署你的模型，并获取自定义部署的Endpoint。\n2. 在初始化时设置 `endpoint` 字段："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Hello，可以回答问题了，我会竭尽全力为您解答，请问有什么问题吗？')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chatBot = QianfanChatEndpoint(\n",
        "    streaming=True,\n",
        "    model=\"ERNIE-Bot\",\n",
        ")\n",
        "\n",
        "messages = [HumanMessage(content=\"Hello\")]\n",
        "chatBot.invoke(messages)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 模型参数：\n\n目前，只有 `ERNIE-Bot` 和 `ERNIE-Bot-turbo` 支持以下模型参数，未来我们可能会支持更多模型。\n\n- temperature\n- top_p\n- penalty_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='您好！有什么我可以帮助您的吗？')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat.invoke(\n",
        "    [HumanMessage(content=\"Hello\")],\n",
        "    **{\"top_p\": 0.4, \"temperature\": 0.1, \"penalty_score\": 1},\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "vscode": {
      "interpreter": {
        "hash": "58f7cb64c3a06383b7f18d2a11305edccbad427293a2b4afa7abe8bfc810d4bb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}