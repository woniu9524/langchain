{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "sidebar_label: ZHIPU AI\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ZHIPU AI\n\n本 Notebook 展示了如何在 LangChain 中使用 [ZHIPU AI API](https://open.bigmodel.cn/dev/api) 以及 langchain.chat_models.ChatZhipuAI。\n\n>[*GLM-4*](https://open.bigmodel.cn/) 是一个多语言、符合人类意图的大语言模型，具备问答、多轮对话和代码生成等能力。新一代基础模型 GLM-4 的整体性能相比上一代得到显著提升，支持更长的上下文；更强的多模态能力；支持更快的推理速度、更多的并发，大幅降低推理成本；同时，GLM-4 增强了智能体的能力。\n\n## 开始使用\n### 安装\n首先，请确保您的 Python 环境已安装 zhipuai 包。运行以下命令："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install --upgrade httpx httpx-sse PyJWT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 导入所需模块\n安装完成后，请将必要的模块导入您的 Python 脚本："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.chat_models import ChatZhipuAI\n",
        "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 设置你的 API 密钥\n请登录 [ZHIPU AI](https://open.bigmodel.cn/login?redirect=%2Fusercenter%2Fapikeys) 以获取 API 密钥，从而访问我们的模型。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"ZHIPUAI_API_KEY\"] = \"zhipuai_api_key\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 初始化 ZHIPU AI 聊天模型\n以下是如何初始化聊天模型的步骤："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "chat = ChatZhipuAI(\n",
        "    model=\"glm-4\",\n",
        "    temperature=0.5,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 基本用法\n像这样使用系统消息和用户消息来调用模型："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "messages = [\n",
        "    AIMessage(content=\"Hi.\"),\n",
        "    SystemMessage(content=\"Your role is a poet.\"),\n",
        "    HumanMessage(content=\"Write a short poem about AI in four lines.\"),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = chat.invoke(messages)\n",
        "print(response.content)  # Displays the AI-generated poem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 高级特性\n### 流式支持\n为了实现连续交互，请使用流式特性："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.callbacks.manager import CallbackManager\n",
        "from langchain_core.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "streaming_chat = ChatZhipuAI(\n",
        "    model=\"glm-4\",\n",
        "    temperature=0.5,\n",
        "    streaming=True,\n",
        "    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "streaming_chat(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 异步调用\n对于非阻塞调用，请使用异步方法："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "async_chat = ChatZhipuAI(\n",
        "    model=\"glm-4\",\n",
        "    temperature=0.5,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "response = await async_chat.agenerate([messages])\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "### 结合函数调用使用\n\nGLM-4 模型也可以结合函数调用使用。使用以下代码运行一个简单的 LangChain json_chat_agent。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "os.environ[\"TAVILY_API_KEY\"] = \"tavily_api_key\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from langchain import hub\n",
        "from langchain.agents import AgentExecutor, create_json_chat_agent\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "tools = [TavilySearchResults(max_results=1)]\n",
        "prompt = hub.pull(\"hwchase17/react-chat-json\")\n",
        "llm = ChatZhipuAI(temperature=0.01, model=\"glm-4\")\n",
        "\n",
        "agent = create_json_chat_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=agent, tools=tools, verbose=True, handle_parsing_errors=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "agent_executor.invoke({\"input\": \"what is LangChain?\"})"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}