{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Xorbits 推理（Xinference）\n\n本教程将介绍如何在 LangChain 中使用 Xinference 嵌入。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 安装\n\n通过 PyPI 安装 `Xinference`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet  \"xinference[all]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 在本地或分布式集群中部署 Xinference。\n\n如需本地部署，请运行 `xinference`。\n\n要在集群中部署 Xinference，请首先使用 `xinference-supervisor` 启动一个 Xinference supervisor。您还可以使用 `-p` 参数指定端口，并使用 `-H` 参数指定主机。默认端口为 9997。\n\n然后，在您希望运行 Xinference 的服务器上使用 `xinference-worker` 启动 Xinference workers。\n\n您可以在 [Xinference](https://github.com/xorbitsai/inference) 的 README 文件中查阅更多信息。\n\n## Wrapper\n\n要将 Xinference 与 LangChain 一起使用，您需要先启动一个模型。您可以使用命令行界面（CLI）来实现："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model uid: 915845ee-2a04-11ee-8ed4-d29396a3f064\n"
          ]
        }
      ],
      "source": [
        "!xinference launch -n vicuna-v1.3 -f ggmlv3 -q q4_0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "模型 UID 已返回供您使用。现在您可以在 LangChain 中使用 Xinference embeddings 了："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.embeddings import XinferenceEmbeddings\n",
        "\n",
        "xinference = XinferenceEmbeddings(\n",
        "    server_url=\"http://0.0.0.0:9997\", model_uid=\"915845ee-2a04-11ee-8ed4-d29396a3f064\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "query_result = xinference.embed_query(\"This is a test query\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "doc_result = xinference.embed_documents([\"text A\", \"text B\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "最后，当您不再需要该模型时，请终止它："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "!xinference terminate --model-uid \"915845ee-2a04-11ee-8ed4-d29396a3f064\""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}