{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8543d632",
      "metadata": {},
      "source": [
        "---\nsidebar_label: Google Gemini\nkeywords: [google gemini embeddings]\n---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afab8b36-10bb-4795-bc98-75ab2d2081bb",
      "metadata": {},
      "source": [
        "# Google 生成式 AI 嵌入 (AI Studio & Gemini API)\n\n使用 `langchain-google-genai` 包中的 `GoogleGenerativeAIEmbeddings` 类连接到 Google 的生成式 AI 嵌入服务。\n\n这将帮助您使用 LangChain 开始使用 Google 的生成式 AI 嵌入模型（如 Gemini）。有关 `GoogleGenerativeAIEmbeddings` 功能和配置选项的详细文档，请参阅 API 参考 [https://python.langchain.com/v0.2/api_reference/google_genai/embeddings/langchain_google_genai.embeddings.GoogleGenerativeAIEmbeddings.html](https://python.langchain.com/v0.2/api_reference/google_genai/embeddings/langchain_google_genai.embeddings.GoogleGenerativeAIEmbeddings.html)。\n\n## 概述\n### 集成详情\n\nimport { ItemTable } from \"@theme/FeatureTables\";\n\n<ItemTable category=\"text_embedding\" item=\"Google Gemini\" />\n\n## 设置\n\n要访问 Google 生成式 AI 嵌入模型，您需要创建一个 Google Cloud 项目，启用 Generative Language API，获取 API 密钥，并安装 `langchain-google-genai` 集成包。\n\n### 凭证\n\n要使用 Google 生成式 AI 模型，您必须拥有一个 API 密钥。您可以在 Google AI Studio 中创建它。有关说明，请参阅 Google 文档 [https://ai.google.dev/gemini-api/docs/api-key](https://ai.google.dev/gemini-api/docs/api-key)。\n\n获得密钥后，将其设置为环境变量 `GOOGLE_API_KEY`："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47652620",
      "metadata": {},
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67283790",
      "metadata": {},
      "source": [
        "为启用模型调用的自动跟踪，请设置您的 [LangSmith](https://docs.smith.langchain.com/) API 密钥："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eccf1968",
      "metadata": {},
      "outputs": [],
      "source": [
        "# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63545b38-9d56-4312-8f61-8d4f1e7a3b1b",
      "metadata": {},
      "source": [
        "## 安装"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2f6a3cd-379f-4dff-a449-d3a9f3196f2a",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet  langchain-google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2437b22-e364-418a-8c13-490a026cb7b5",
      "metadata": {},
      "source": [
        "## 用法"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "eedc551e-a1f3-4fd8-8d65-4e0784c4441b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-0.024917153641581535,\n",
              " 0.012005362659692764,\n",
              " -0.003886754624545574,\n",
              " -0.05774897709488869,\n",
              " 0.0020742062479257584]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-exp-03-07\")\n",
        "vector = embeddings.embed_query(\"hello, world!\")\n",
        "vector[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b2bed60-e7bd-4e48-83d6-1c87001f98bd",
      "metadata": {},
      "source": [
        "## 批量处理\n\n你也可以一次性嵌入多个字符串以加快处理速度："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6ec53aba-404f-4778-acd9-5d6664e79ed2",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3, 3072)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectors = embeddings.embed_documents(\n",
        "    [\n",
        "        \"Today is Monday\",\n",
        "        \"Today is Tuesday\",\n",
        "        \"Today is April Fools day\",\n",
        "    ]\n",
        ")\n",
        "len(vectors), len(vectors[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c362bfbf",
      "metadata": {},
      "source": [
        "## 索引与检索\n\n嵌入模型常用于检索增强生成（RAG）流程中，既可以作为索引数据的一部分，也可以用于后续的数据检索。更多详细说明，请参阅我们的 [RAG 教程](/docs/tutorials/)。\n\n下方展示了如何使用我们上面初始化的 `embeddings` 对象来索引和检索数据。在本示例中，我们将在 `InMemoryVectorStore` 中索引和检索一个示例文档。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "606a7f65",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'LangChain is the framework for building context-aware reasoning applications'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a vector store with a sample text\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "\n",
        "text = \"LangChain is the framework for building context-aware reasoning applications\"\n",
        "\n",
        "vectorstore = InMemoryVectorStore.from_texts(\n",
        "    [text],\n",
        "    embedding=embeddings,\n",
        ")\n",
        "\n",
        "# Use the vectorstore as a retriever\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "# Retrieve the most similar text\n",
        "retrieved_documents = retriever.invoke(\"What is LangChain?\")\n",
        "\n",
        "# show the retrieved document's content\n",
        "retrieved_documents[0].page_content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1482486f-5617-498a-8a44-1974d3212dda",
      "metadata": {},
      "source": [
        "## 任务类型\n`GoogleGenerativeAIEmbeddings` 可选支持 `task_type`，目前它必须是以下值之一：\n\n- `SEMANTIC_SIMILARITY`: 用于生成经过优化的文本相似性评估的嵌入。\n- `CLASSIFICATION`: 用于生成经过优化的、根据预设标签对文本进行分类的嵌入。\n- `CLUSTERING`: 用于生成经过优化的、基于相似性对文本进行聚类的嵌入。\n- `RETRIEVAL_DOCUMENT`, `RETRIEVAL_QUERY`, `QUESTION_ANSWERING`, and `FACT_VERIFICATION`: 用于生成经过优化的、用于文档搜索或信息检索的嵌入。\n- `CODE_RETRIEVAL_QUERY`: 用于根据自然语言查询检索代码块，例如“排序数组”或“反转链表”。代码块的嵌入将使用 `RETRIEVAL_DOCUMENT` 计算。\n\n默认情况下，我们在 `embed_documents` 方法中使用 `RETRIEVAL_DOCUMENT`，在 `embed_query` 方法中使用 `RETRIEVAL_QUERY`。如果您提供了任务类型，我们将将其用于所有方法。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7acc5c2",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet  matplotlib scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "f1f077db-8eb4-49f7-8866-471a8528dcdb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document 1\n",
            "Cosine similarity with query: 0.7892893360164779\n",
            "---\n",
            "Document 2\n",
            "Cosine similarity with query: 0.5438283285204146\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "query_embeddings = GoogleGenerativeAIEmbeddings(\n",
        "    model=\"models/gemini-embedding-exp-03-07\", task_type=\"RETRIEVAL_QUERY\"\n",
        ")\n",
        "doc_embeddings = GoogleGenerativeAIEmbeddings(\n",
        "    model=\"models/gemini-embedding-exp-03-07\", task_type=\"RETRIEVAL_DOCUMENT\"\n",
        ")\n",
        "\n",
        "q_embed = query_embeddings.embed_query(\"What is the capital of France?\")\n",
        "d_embed = doc_embeddings.embed_documents(\n",
        "    [\"The capital of France is Paris.\", \"Philipp is likes to eat pizza.\"]\n",
        ")\n",
        "\n",
        "for i, d in enumerate(d_embed):\n",
        "    print(f\"Document {i+1}:\")\n",
        "    print(f\"Cosine similarity with query: {cosine_similarity([q_embed], [d])[0][0]}\")\n",
        "    print(\"---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f45ea7b1",
      "metadata": {},
      "source": [
        "## API 参考\n\n有关 `GoogleGenerativeAIEmbeddings` 的详细文档说明和配置选项，请参阅 [API 参考](https://python.langchain.com/api_reference/google_genai/embeddings/langchain_google_genai.embeddings.GoogleGenerativeAIEmbeddings.html)。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e7857e5",
      "metadata": {},
      "source": [
        "## 其他配置\n\n您可以将以下参数传递给 `ChatGoogleGenerativeAI` 以自定义 SDK 的行为：\n\n- `client_options`: 要传递给 Google API Client 的 [Client Options](https://googleapis.dev/python/google-api-core/latest/client_options.html#module-google.api_core.client_options)，例如自定义的 `client_options[\"api_endpoint\"]`\n- `transport`: 要使用的传输方法，例如 `rest`、`grpc` 或 `grpc_asyncio`。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}