{
  "cells": [
    {
      "cell_type": "raw",
      "id": "afaf8039",
      "metadata": {},
      "source": [
        "---\n",
        "sidebar_label: Nomic\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a3d6f34",
      "metadata": {},
      "source": [
        "# NomicEmbeddings\n\n这将帮助您开始使用 LangChain 的 Nomic 嵌入模型。有关 `NomicEmbeddings` 功能和配置选项的详细文档，请参阅 [API 参考](https://python.langchain.com/api_reference/nomic/embeddings/langchain_nomic.embeddings.NomicEmbeddings.html)。\n\n## 概览\n### 集成详情\n\nimport { ItemTable } from \"@theme/FeatureTables\";\n\n<ItemTable category=\"text_embedding\" item=\"Nomic\" />\n\n## 设置\n\n要访问 Nomic 嵌入模型，您需要创建一个 Nomic 账户，获取 API 密钥，并安装 `langchain-nomic` 集成包。\n\n### 凭证\n\n前往 [https://atlas.nomic.ai/](https://atlas.nomic.ai/) 注册 Nomic 并生成 API 密钥。完成此操作后，请设置 `NOMIC_API_KEY` 环境变量："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "36521c2a",
      "metadata": {},
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if not os.getenv(\"NOMIC_API_KEY\"):\n",
        "    os.environ[\"NOMIC_API_KEY\"] = getpass.getpass(\"Enter your Nomic API key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c84fb993",
      "metadata": {},
      "source": "为了实现模型调用的自动化追踪，请设置您的 [LangSmith](https://docs.smith.langchain.com/) API 密钥："
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "39a4953b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9664366",
      "metadata": {},
      "source": [
        "### 安装\n\nLangChain Nomic 集成位于 `langchain-nomic` 包中："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "64853226",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -qU langchain-nomic"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45dd1724",
      "metadata": {},
      "source": [
        "## 实例化\n\n现在我们可以实例化我们的模型对象并生成聊天补全："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9ea7a09b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_nomic import NomicEmbeddings\n",
        "\n",
        "embeddings = NomicEmbeddings(\n",
        "    model=\"nomic-embed-text-v1.5\",\n",
        "    # dimensionality=256,\n",
        "    # Nomic's `nomic-embed-text-v1.5` model was [trained with Matryoshka learning](https://blog.nomic.ai/posts/nomic-embed-matryoshka)\n",
        "    # to enable variable-length embeddings with a single model.\n",
        "    # This means that you can specify the dimensionality of the embeddings at inference time.\n",
        "    # The model supports dimensionality from 64 to 768.\n",
        "    # inference_mode=\"remote\",\n",
        "    # One of `remote`, `local` (Embed4All), or `dynamic` (automatic). Defaults to `remote`.\n",
        "    # api_key=... , # if using remote inference,\n",
        "    # device=\"cpu\",\n",
        "    # The device to use for local embeddings. Choices include\n",
        "    # `cpu`, `gpu`, `nvidia`, `amd`, or a specific device name. See\n",
        "    # the docstring for `GPT4All.__init__` for more info. Typically\n",
        "    # defaults to CPU. Do not use on macOS.\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77d271b6",
      "metadata": {},
      "source": [
        "## 索引和检索\n\n嵌入模型经常在检索增强生成（RAG）流程中使用，既可以作为索引数据的一部分，也可以在之后检索数据。有关更详细的说明，请参阅我们的[RAG 教程](/docs/tutorials/)。\n\n下面将展示如何使用我们上面初始化的 `embeddings` 对象来索引和检索数据。在此示例中，我们将在 `InMemoryVectorStore` 中索引和检索一个示例文档。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d817716b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'LangChain is the framework for building context-aware reasoning applications'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a vector store with a sample text\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "\n",
        "text = \"LangChain is the framework for building context-aware reasoning applications\"\n",
        "\n",
        "vectorstore = InMemoryVectorStore.from_texts(\n",
        "    [text],\n",
        "    embedding=embeddings,\n",
        ")\n",
        "\n",
        "# Use the vectorstore as a retriever\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "# Retrieve the most similar text\n",
        "retrieved_documents = retriever.invoke(\"What is LangChain?\")\n",
        "\n",
        "# show the retrieved document's content\n",
        "retrieved_documents[0].page_content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e02b9855",
      "metadata": {},
      "source": [
        "## 直接使用\n\n底层实现中，vectorstore 和 retriever 会分别调用 `embeddings.embed_documents(...)` 和 `embeddings.embed_query(...)` 来为 `from_texts` 和检索 `invoke` 操作中使用的文本（们）创建 embeddings。\n\n您可以直接调用这些方法来为自己的用例获取 embeddings。\n\n### 嵌入单个文本\n\n您可以使用 `embed_query` 来嵌入单个文本或文档："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0d2befcd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.024642944, 0.029083252, -0.14013672, -0.09082031, 0.058898926, -0.07489014, -0.0138168335, 0.0037\n"
          ]
        }
      ],
      "source": [
        "single_vector = embeddings.embed_query(text)\n",
        "print(str(single_vector)[:100])  # Show the first 100 characters of the vector"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b5a7d03",
      "metadata": {},
      "source": [
        "### 嵌入多个文本\n\n您可以使用 `embed_documents` 嵌入多个文本："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2f4d6e97",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.012771606, 0.023727417, -0.12365723, -0.083740234, 0.06530762, -0.07110596, -0.021896362, -0.0068\n",
            "[-0.019058228, 0.04058838, -0.15222168, -0.06842041, -0.012130737, -0.07128906, -0.04534912, 0.00522\n"
          ]
        }
      ],
      "source": [
        "text2 = (\n",
        "    \"LangGraph is a library for building stateful, multi-actor applications with LLMs\"\n",
        ")\n",
        "two_vectors = embeddings.embed_documents([text, text2])\n",
        "for vector in two_vectors:\n",
        "    print(str(vector)[:100])  # Show the first 100 characters of the vector"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98785c12",
      "metadata": {},
      "source": [
        "## API 参考\n\n有关 `NomicEmbeddings` 功能和配置选项的详细文档，请参阅[API 参考](https://python.langchain.com/api_reference/nomic/embeddings/langchain_nomic.embeddings.NomicEmbeddings.html)。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}