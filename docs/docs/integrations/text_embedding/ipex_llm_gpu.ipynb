{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# IPEX-LLM：在 Intel GPU 上本地运行 BGE 嵌入模型\n\n> [IPEX-LLM](https://github.com/intel-analytics/ipex-llm) 是一个 PyTorch 库，用于在 Intel CPU 和 GPU（例如，本地 PC 的 iGPU，以及 Arc、Flex 和 Max 等独立 GPU）上以极低的延迟运行 LLM。\n\n本示例将介绍如何使用 LangChain，在 Intel GPU 上通过 `ipex-llm` 优化来执行嵌入任务。这将有助于实现 RAG、文档问答等应用。\n\n> **注意**\n>\n> 建议只有拥有 Intel Arc A 系列 GPU（Intel Arc A300 系列或 Pro A60 除外）的 Windows 用户直接运行此 Jupyter notebook。对于其他情况（例如 Linux 用户、Intel iGPU 等），建议在终端中使用 Python 脚本运行代码以获得最佳体验。\n\n## 安装先决条件\n要在 Intel GPU 上利用 IPEX-LLM，需要完成几个工具安装和环境准备的先决步骤。\n\n如果您是 Windows 用户，请访问 [在 Windows 和 Intel GPU 上安装 IPEX-LLM 指南](https://github.com/intel-analytics/ipex-llm/blob/main/docs/mddocs/Quickstart/install_windows_gpu.md)，然后按照 [安装先决条件](https://github.com/intel-analytics/ipex-llm/blob/main/docs/mddocs/Quickstart/install_windows_gpu.md#install-prerequisites) 更新 GPU 驱动程序（可选）并安装 Conda。\n\n如果您是 Linux 用户，请访问 [在 Linux 和 Intel GPU 上安装 IPEX-LLM](https://github.com/intel-analytics/ipex-llm/blob/main/docs/mddocs/Quickstart/install_linux_gpu.md)，然后按照 [**安装先决条件**](https://github.com/intel-analytics/ipex-llm/blob/main/docs/mddocs/Quickstart/install_linux_gpu.md#install-prerequisites) 安装 GPU 驱动程序、Intel® oneAPI Base Toolkit 2024.0 和 Conda。\n\n## 设置\n\n在安装完先决条件后，您应该已经创建了一个已安装所有先决条件的 conda 环境。**在此 conda 环境中启动 jupyter 服务**："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -qU langchain langchain-community"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "安装 IPEX-LLM 以优化 Intel GPU，以及 `sentence-transformers`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install --pre --upgrade ipex-llm[xpu] --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/xpu/us/\n",
        "%pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **注意**\n>\n> 你也可以使用 `https://pytorch-extension.intel.com/release-whl/stable/xpu/cn/` 作为 `extra-indel-url`。\n\n## 运行时配置\n\n为了达到最佳性能，建议根据你的设备设置几个环境变量：\n\n### 适用于使用 Intel Core Ultra 集成 GPU 的 Windows 用户"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"SYCL_CACHE_PERSISTENT\"] = \"1\"\n",
        "os.environ[\"BIGDL_LLM_XMX_DISABLED\"] = \"1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 适用于拥有 Intel Arc A 系列 GPU 的 Windows 用户"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"SYCL_CACHE_PERSISTENT\"] = \"1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **注意**\n>\n> 首次在 Intel iGPU/Intel Arc A300 系列或 Pro A60 上运行模型时，编译可能需要几分钟时间。\n>\n> 对于其他 GPU 类型，Windows 用户请参考[此处](https://github.com/intel-analytics/ipex-llm/blob/main/docs/mddocs/Overview/install_gpu.md#runtime-configuration)，Linux 用户请参考[此处](https://github.com/intel-analytics/ipex-llm/blob/main/docs/mddocs/Overview/install_gpu.md#runtime-configuration-1)。\n\n## 基本用法\n\n在初始化 `IpexLLMBgeEmbeddings` 时，将 `model_kwargs` 中的 `device` 设置为 `\"xpu\"` 会将嵌入模型放在 Intel GPU 上，并受益于 IPEX-LLM 的优化："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.embeddings import IpexLLMBgeEmbeddings\n",
        "\n",
        "embedding_model = IpexLLMBgeEmbeddings(\n",
        "    model_name=\"BAAI/bge-large-en-v1.5\",\n",
        "    model_kwargs={\"device\": \"xpu\"},\n",
        "    encode_kwargs={\"normalize_embeddings\": True},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "API 参考\n- [IpexLLMBgeEmbeddings](https://python.langchain.com/api_reference/community/embeddings/langchain_community.embeddings.ipex_llm.IpexLLMBgeEmbeddings.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentence = \"IPEX-LLM is a PyTorch library for running LLM on Intel CPU and GPU (e.g., local PC with iGPU, discrete GPU such as Arc, Flex and Max) with very low latency.\"\n",
        "query = \"What is IPEX-LLM?\"\n",
        "\n",
        "text_embeddings = embedding_model.embed_documents([sentence, query])\n",
        "print(f\"text_embeddings[0][:10]: {text_embeddings[0][:10]}\")\n",
        "print(f\"text_embeddings[1][:10]: {text_embeddings[1][:10]}\")\n",
        "\n",
        "query_embedding = embedding_model.embed_query(query)\n",
        "print(f\"query_embedding[:10]: {query_embedding[:10]}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}