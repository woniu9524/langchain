{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# IPEX-LLM: 在 Intel CPU 上本地运行 BGE Embeddings\n\n> [IPEX-LLM](https://github.com/intel-analytics/ipex-llm) 是一个 PyTorch 库，用于在 Intel CPU 和 GPU（例如带有 iGPU 的本地 PC、Arc、Flex 和 Max 等独立 GPU）上以非常低的延迟运行 LLM。\n\n本示例将介绍如何使用 LangChain 结合 `ipex-llm` 优化在 Intel CPU 上执行嵌入任务。这对于 RAG、文档问答等应用非常有帮助。\n\n## 设置"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -qU langchain langchain-community"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "为在 Intel CPU 上进行优化而安装 IPEX-LLM，以及 `sentence-transformers`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install --pre --upgrade ipex-llm[all] --extra-index-url https://download.pytorch.org/whl/cpu\n",
        "%pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **注意**\n>\n> 对于 Windows 用户，安装 `ipex-llm` 时不需要 `--extra-index-url https://download.pytorch.org/whl/cpu`。\n\n## 基本用法"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.embeddings import IpexLLMBgeEmbeddings\n",
        "\n",
        "embedding_model = IpexLLMBgeEmbeddings(\n",
        "    model_name=\"BAAI/bge-large-en-v1.5\",\n",
        "    model_kwargs={},\n",
        "    encode_kwargs={\"normalize_embeddings\": True},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "API 参考\n- [IpexLLMBgeEmbeddings](https://python.langchain.com/api_reference/community/embeddings/langchain_community.embeddings.ipex_llm.IpexLLMBgeEmbeddings.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentence = \"IPEX-LLM is a PyTorch library for running LLM on Intel CPU and GPU (e.g., local PC with iGPU, discrete GPU such as Arc, Flex and Max) with very low latency.\"\n",
        "query = \"What is IPEX-LLM?\"\n",
        "\n",
        "text_embeddings = embedding_model.embed_documents([sentence, query])\n",
        "print(f\"text_embeddings[0][:10]: {text_embeddings[0][:10]}\")\n",
        "print(f\"text_embeddings[1][:10]: {text_embeddings[1][:10]}\")\n",
        "\n",
        "query_embedding = embedding_model.embed_query(query)\n",
        "print(f\"query_embedding[:10]: {query_embedding[:10]}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}