{
  "cells": [
    {
      "cell_type": "raw",
      "id": "afaf8039",
      "metadata": {},
      "source": [
        "---\n",
        "sidebar_label: GreenNode\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a3d6f34",
      "metadata": {},
      "source": [
        "# GreenNodeEmbeddings\n\n>[GreenNode](https://greennode.ai/)是一家全球性人工智能解决方案提供商，也是 **NVIDIA 优选合作伙伴**，为美国、中东和北非以及亚太地区的各类企业提供从基础设施到应用的端到端人工智能能力。GreenNode 在**世界一流的基础设施**（LEED Gold, TIA‑942, Uptime Tier III）上运行，通过一套全面的 AI 服务赋能企业、初创公司和研究人员。\n\n本 Notebook 提供了开始使用 `GreenNodeEmbeddings` 的指南。它通过生成高质量的文本向量表示，使您能够使用各种内置连接器或您自己的自定义数据源执行语义文档搜索。\n\n## 对接详情\n\n| Provider | Package |\n|:--------:|:-------:|\n| [GreenNode](/docs/integrations/providers/greennode/) | [langchain-greennode](https://python.langchain.com/v0.2/api_reference/langchain_greennode/embeddings/langchain_greennode.embeddingsGreenNodeEmbeddings.html) |\n\n## 设置\n\n要访问 GreenNode 嵌入模型，您需要创建一个 GreenNode 账户，获取 API 密钥，并安装 `langchain-greennode` 集成包。\n\n### 凭证\n\nGreenNode 需要 API 密钥进行身份验证，该密钥可以在初始化期间作为 `api_key` 参数提供，也可以设置为环境变量 `GREENNODE_API_KEY`。您可以通过在 [GreenNode Serverless AI](https://aiplatform.console.greennode.ai/playground) 上注册账户来获取 API 密钥。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "36521c2a",
      "metadata": {},
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if not os.getenv(\"GREENNODE_API_KEY\"):\n",
        "    os.environ[\"GREENNODE_API_KEY\"] = getpass.getpass(\"Enter your GreenNode API key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c84fb993",
      "metadata": {},
      "source": [
        "如果你想获取模型调用的自动化追踪，也可以通过取消下面代码的注释来设置你的 [LangSmith](https://docs.smith.langchain.com/) API 密钥："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39a4953b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9664366",
      "metadata": {},
      "source": [
        "### 安装\n\nLangChain GreenNode 集成位于 `langchain-greennode` 包中："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "64853226",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -qU langchain-greennode"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45dd1724",
      "metadata": {},
      "source": [
        "## 实例化\n\n`GreenNodeEmbeddings` 类可以通过可选的 API 密钥和模型名称参数进行实例化："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9ea7a09b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_greennode import GreenNodeEmbeddings\n",
        "\n",
        "# Initialize the embeddings model\n",
        "embeddings = GreenNodeEmbeddings(\n",
        "    # api_key=\"YOUR_API_KEY\",  # You can pass the API key directly\n",
        "    model=\"BAAI/bge-m3\"  # The default embedding model\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77d271b6",
      "metadata": {},
      "source": [
        "## 索引和检索\n\n嵌入模型在检索增强生成 (RAG) 工作流程中发挥着关键作用，它们能够对内容进行索引和高效检索。\n下面，我们将展示如何使用我们上面初始化的 `embeddings` 对象来索引和检索数据。在此示例中，我们将使用 `InMemoryVectorStore` 索引和检索一个示例文档。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "23df9f54",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'LangChain is the framework for building context-aware reasoning applications'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a vector store with a sample text\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "\n",
        "text = \"LangChain is the framework for building context-aware reasoning applications\"\n",
        "\n",
        "vectorstore = InMemoryVectorStore.from_texts(\n",
        "    [text],\n",
        "    embedding=embeddings,\n",
        ")\n",
        "\n",
        "# Use the vectorstore as a retriever\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "# Retrieve the most similar text\n",
        "retrieved_documents = retriever.invoke(\"What is LangChain?\")\n",
        "\n",
        "# show the retrieved document's content\n",
        "retrieved_documents[0].page_content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e02b9855",
      "metadata": {},
      "source": [
        "## 直接使用\n\n`GreenNodeEmbeddings` 类可以独立使用，无需向量存储即可生成文本嵌入。这对于诸如相似度评分、聚类或自定义处理管道等任务非常有用。\n\n### 嵌入单个文本\n\n您可以使用 `embed_query` 嵌入单个文本或文档："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d2befcd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.01104736328125, -0.0281982421875, 0.0035858154296875, -0.0311279296875, -0.0106201171875, -0.039\n"
          ]
        }
      ],
      "source": [
        "single_vector = embeddings.embed_query(text)\n",
        "print(str(single_vector)[:100])  # Show the first 100 characters of the vector"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b5a7d03",
      "metadata": {},
      "source": [
        "### 嵌入多个文本\n\n您可以使用 `embed_documents` 嵌入多个文本："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f4d6e97",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.01104736328125, -0.0281982421875, 0.0035858154296875, -0.0311279296875, -0.0106201171875, -0.039\n",
            "[-0.07177734375, -0.00017452239990234375, -0.002044677734375, -0.0299072265625, -0.0184326171875, -0\n"
          ]
        }
      ],
      "source": [
        "text2 = (\n",
        "    \"LangGraph is a library for building stateful, multi-actor applications with LLMs\"\n",
        ")\n",
        "two_vectors = embeddings.embed_documents([text, text2])\n",
        "for vector in two_vectors:\n",
        "    print(str(vector)[:100])  # Show the first 100 characters of the vector"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be19dda0",
      "metadata": {},
      "source": [
        "### 异步支持\n\nGreenNodeEmbeddings 支持异步操作："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d556e655",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Async query embedding dimension: 1024\n",
            "Async document embeddings count: 3\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "\n",
        "\n",
        "async def generate_embeddings_async():\n",
        "    # Embed a single query\n",
        "    query_result = await embeddings.aembed_query(\"What is the capital of France?\")\n",
        "    print(f\"Async query embedding dimension: {len(query_result)}\")\n",
        "\n",
        "    # Embed multiple documents\n",
        "    docs = [\n",
        "        \"Paris is the capital of France\",\n",
        "        \"Berlin is the capital of Germany\",\n",
        "        \"Rome is the capital of Italy\",\n",
        "    ]\n",
        "    docs_result = await embeddings.aembed_documents(docs)\n",
        "    print(f\"Async document embeddings count: {len(docs_result)}\")\n",
        "\n",
        "\n",
        "await generate_embeddings_async()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "207a7966",
      "metadata": {},
      "source": [
        "### 文档相似度示例"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bdb003b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document Similarity Matrix:\n",
            "Document 1: ['1.0000', '0.6005', '0.3542', '0.5788']\n",
            "Document 2: ['0.6005', '1.0000', '0.4154', '0.6170']\n",
            "Document 3: ['0.3542', '0.4154', '1.0000', '0.3528']\n",
            "Document 4: ['0.5788', '0.6170', '0.3528', '1.0000']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# Create some documents\n",
        "documents = [\n",
        "    \"Machine learning algorithms build mathematical models based on sample data\",\n",
        "    \"Deep learning uses neural networks with many layers\",\n",
        "    \"Climate change is a major global environmental challenge\",\n",
        "    \"Neural networks are inspired by the human brain's structure\",\n",
        "]\n",
        "\n",
        "# Embed the documents\n",
        "embeddings_list = embeddings.embed_documents(documents)\n",
        "\n",
        "\n",
        "# Function to calculate similarity\n",
        "def calculate_similarity(embedding1, embedding2):\n",
        "    return 1 - cosine(embedding1, embedding2)\n",
        "\n",
        "\n",
        "# Print similarity matrix\n",
        "print(\"Document Similarity Matrix:\")\n",
        "for i, emb_i in enumerate(embeddings_list):\n",
        "    similarities = []\n",
        "    for j, emb_j in enumerate(embeddings_list):\n",
        "        similarity = calculate_similarity(emb_i, emb_j)\n",
        "        similarities.append(f\"{similarity:.4f}\")\n",
        "    print(f\"Document {i + 1}: {similarities}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98785c12",
      "metadata": {},
      "source": [
        "## API 参考\n\n有关 GreenNode 无服务器 AI API 的更多详细信息，请访问 [GreenNode 无服务器 AI 文档](https://aiplatform.console.greennode.ai/api-docs/maas)。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tradingagents",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}