{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Baidu Qianfan\n\nBaidu AI Cloud 千帆平台是面向企业开发者的一站式大模型开发部署运营平台。千帆不仅提供文心一言（ERNIE-Bot）及第三方开源模型，还提供各种 AI 开发工具和全套开发环境，方便客户轻松使用和开发大模型应用。\n\n基本上，这些模型分为以下几类：\n\n- Embedding\n- Chat\n- Completion\n\n在本 Notebook 中，我们将介绍如何将 langchain 与 [Qianfan](https://cloud.baidu.com/doc/WENXINWORKSHOP/index.html) 结合使用，主要针对 `Embedding`，对应于 langchain 中的 `langchain/embeddings` 包：\n\n## API 初始化\n\n要使用基于 Baidu Qianfan 的 LLM 服务，您必须初始化这些参数：\n\n您可以选择在环境变量中初始化 AK、SK 或在初始化参数中进行设置：\n\n```base\nexport QIANFAN_AK=XXX\nexport QIANFAN_SK=XXX\n```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[INFO] [09-15 20:01:35] logging.py:55 [t:140292313159488]: trying to refresh access_token\n",
            "[INFO] [09-15 20:01:35] logging.py:55 [t:140292313159488]: successfully refresh access_token\n",
            "[INFO] [09-15 20:01:35] logging.py:55 [t:140292313159488]: requesting llm api endpoint: /embeddings/embedding-v1\n",
            "[INFO] [09-15 20:01:35] logging.py:55 [t:140292313159488]: async requesting llm api endpoint: /embeddings/embedding-v1\n",
            "[INFO] [09-15 20:01:35] logging.py:55 [t:140292313159488]: async requesting llm api endpoint: /embeddings/embedding-v1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.03313107788562775, 0.052325375378131866, 0.04951248690485954, 0.0077608139254152775, -0.05907672271132469, -0.010798933915793896, 0.03741293027997017, 0.013969100080430508]\n",
            " [0.0427522286772728, -0.030367236584424973, -0.14847028255462646, 0.055074431002140045, -0.04177454113960266, -0.059512972831726074, -0.043774791061878204, 0.0028191760648041964]\n",
            " [0.03803155943751335, -0.013231384567916393, 0.0032379645854234695, 0.015074018388986588, -0.006529552862048149, -0.13813287019729614, 0.03297128155827522, 0.044519297778606415]\n"
          ]
        }
      ],
      "source": [
        "\"\"\"For basic init and call\"\"\"\n",
        "import os\n",
        "\n",
        "from langchain_community.embeddings import QianfanEmbeddingsEndpoint\n",
        "\n",
        "os.environ[\"QIANFAN_AK\"] = \"your_ak\"\n",
        "os.environ[\"QIANFAN_SK\"] = \"your_sk\"\n",
        "\n",
        "embed = QianfanEmbeddingsEndpoint(\n",
        "    # qianfan_ak='xxx',\n",
        "    # qianfan_sk='xxx'\n",
        ")\n",
        "res = embed.embed_documents([\"hi\", \"world\"])\n",
        "\n",
        "\n",
        "async def aioEmbed():\n",
        "    res = await embed.aembed_query(\"qianfan\")\n",
        "    print(res[:8])\n",
        "\n",
        "\n",
        "await aioEmbed()\n",
        "\n",
        "\n",
        "async def aioEmbedDocs():\n",
        "    res = await embed.aembed_documents([\"hi\", \"world\"])\n",
        "    for r in res:\n",
        "        print(\"\", r[:8])\n",
        "\n",
        "\n",
        "await aioEmbedDocs()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 在千帆中使用不同的模型\n\n如果你想部署自己的模型，无论是基于文心大模型还是第三方开源模型，都可以按照以下步骤进行：\n\n- 1. （可选，如果模型包含在默认模型中，则跳过此步骤）在千帆控制台中部署你的模型，并获取你自己定制的部署端点。\n- 2. 在初始化时设置名为 `endpoint` 的字段："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[INFO] [09-15 20:01:40] logging.py:55 [t:140292313159488]: requesting llm api endpoint: /embeddings/bge_large_zh\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.0001582596160005778, -0.025089964270591736, -0.03997539356350899, 0.013156415894627571, 0.000135212714667432, 0.012428865768015385, 0.016216561198234558, -0.04126659780740738]\n",
            "[0.0019113451708108187, -0.008625439368188381, -0.0531032420694828, -0.0018436014652252197, -0.01818147301673889, 0.010310115292668343, -0.008867680095136166, -0.021067561581730843]\n"
          ]
        }
      ],
      "source": [
        "embed = QianfanEmbeddingsEndpoint(model=\"bge_large_zh\", endpoint=\"bge_large_zh\")\n",
        "\n",
        "res = embed.embed_documents([\"hi\", \"world\"])\n",
        "for r in res:\n",
        "    print(r[:8])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "6fa70026b407ae751a5c9e6bd7f7d482379da8ad616f98512780b705c84ee157"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}