# LangChain Decorators âœ¨

~~~
å…è´£å£°æ˜ï¼š`LangChain decorators` å¹¶éç”± LangChain å›¢é˜Ÿåˆ›å»ºï¼Œä¹Ÿä¸å—å…¶æ”¯æŒã€‚
~~~

>`LangChain decorators` æ˜¯ LangChain ä¹‹ä¸Šçš„ä¸€ä¸ªå°è£…ï¼Œå®ƒæä¾›äº†è¯­æ³•ç³– ğŸ­ï¼Œç”¨äºç¼–å†™è‡ªå®šä¹‰çš„ langchain æç¤ºå’Œé“¾
>
>æœ‰å…³åé¦ˆã€é—®é¢˜ã€è´¡çŒ®ï¼Œè¯·åœ¨æ­¤å¤„æå‡º issueï¼š 
>[ju-bezdek/langchain-decorators](https://github.com/ju-bezdek/langchain-decorators)


ä¸»è¦åŸåˆ™å’Œä¼˜åŠ¿ï¼š

- æ›´å…· `pythonic` é£æ ¼çš„ä»£ç ç¼–å†™æ–¹å¼
- ç¼–å†™å¤šè¡Œæç¤ºï¼Œè€Œä¸ç ´åä»£ç æµç¨‹çš„ç¼©è¿›
- åˆ©ç”¨ IDE å†…ç½®çš„ **æç¤º**ã€**ç±»å‹æ£€æŸ¥** å’Œ **å¸¦æ–‡æ¡£çš„å¼¹å‡ºçª—å£** åŠŸèƒ½ï¼Œå¿«é€ŸæŸ¥çœ‹å‡½æ•°ä»¥äº†è§£æç¤ºã€å®ƒä½¿ç”¨çš„å‚æ•°ç­‰
- åˆ©ç”¨ ğŸ¦œğŸ”— LangChain ç”Ÿæ€ç³»ç»Ÿçš„æ‰€æœ‰å¼ºå¤§åŠŸèƒ½
- æ·»åŠ å¯¹ **å¯é€‰å‚æ•°** çš„æ”¯æŒ
- é€šè¿‡å°†å‚æ•°ç»‘å®šåˆ°ä¸€ä¸ªç±»æ¥è½»æ¾å…±äº«å®ƒä»¬

ä»¥ä¸‹æ˜¯ä½¿ç”¨ **LangChain Decorators âœ¨** ç¼–å†™çš„ä»£ç çš„ç®€å•ç¤ºä¾‹

``` python

@llm_prompt
def write_me_short_post(topic:str, platform:str="twitter", audience:str = "developers")->str:
    """
    ä¸ºæˆ‘å…³äº {topic} çš„å¸–å­å†™ä¸€ä¸ªçŸ­æ ‡é¢˜ï¼Œç›®æ ‡å¹³å°æ˜¯ {platform}ã€‚
    å—ä¼—æ˜¯ {audience}ã€‚
    (æœ€å¤š 15 ä¸ªè¯)
    """
    return

# è‡ªç„¶è¿è¡Œ
write_me_short_post(topic="starwars")
# æˆ–è€…
write_me_short_post(topic="starwars", platform="redit")
```

# å¿«é€Ÿå…¥é—¨
## å®‰è£…
```bash
pip install langchain_decorators
```

## ç¤ºä¾‹

ä¸€ä¸ªäº†è§£å¦‚ä½•å¼€å§‹çš„å¥½æ–¹æ³•æ˜¯æŸ¥çœ‹è¿™é‡Œçš„ç¤ºä¾‹ï¼š
 - [Jupyter Notebook](https://github.com/ju-bezdek/langchain-decorators/blob/main/example_notebook.ipynb)
 - [Colab Notebook](https://colab.research.google.com/drive/1no-8WfeP6JaLD9yUtkPgym6x0G9ZYZOG#scrollTo=N4cf__D0E2Yk)

# å®šä¹‰å…¶ä»–å‚æ•°
è¿™é‡Œæˆ‘ä»¬åªæ˜¯ç”¨ `llm_prompt` è£…é¥°å™¨å°†ä¸€ä¸ªå‡½æ•°æ ‡è®°ä¸ºä¸€ä¸ªæç¤ºï¼Œä»è€Œæœ‰æ•ˆåœ°å°†å…¶è½¬æ¢ä¸ºä¸€ä¸ª LLMChainã€‚è€Œä¸æ˜¯è¿è¡Œå®ƒ

æ ‡å‡†çš„ LLMchain é™¤äº† inputs_variables å’Œ prompt ä¹‹å¤–è¿˜éœ€è¦æ›´å¤šçš„ init å‚æ•°â€¦â€¦è¿™é‡Œæ˜¯éšè—åœ¨è£…é¥°å™¨ä¸­çš„å®ç°ç»†èŠ‚ã€‚
è¿™æ˜¯å®ƒçš„å·¥ä½œåŸç†ï¼š

1. ä½¿ç”¨ **å…¨å±€è®¾ç½®**ï¼š

```python
# ä¸ºæ‰€æœ‰æç¤ºå®šä¹‰å…¨å±€è®¾ç½®ï¼ˆå¦‚æœæœªè®¾ç½® - chatGPT æ˜¯å½“å‰é»˜è®¤å€¼ï¼‰
from langchain_decorators import GlobalSettings

GlobalSettings.define_settings(
    default_llm=ChatOpenAI(temperature=0.0), è¿™æ˜¯é»˜è®¤å€¼... å¯ä»¥åœ¨è¿™é‡Œå…¨å±€æ›´æ”¹
    default_streaming_llm=ChatOpenAI(temperature=0.0,streaming=True), è¿™æ˜¯é»˜è®¤å€¼... å¯ä»¥åœ¨è¿™é‡Œä¸ºæ‰€æœ‰å†…å®¹æ›´æ”¹... å°†ç”¨äºæµå¼ä¼ è¾“
)
```

2. ä½¿ç”¨é¢„å®šä¹‰çš„ **æç¤ºç±»å‹**

```python
#æ‚¨å¯ä»¥æ›´æ”¹é»˜è®¤æç¤ºç±»å‹
from langchain_decorators import PromptTypes, PromptTypeSettings

PromptTypes.AGENT_REASONING.llm = ChatOpenAI()

# æˆ–è€…æ‚¨å¯ä»¥è‡ªå·±å®šä¹‰ï¼š
class MyCustomPromptTypes(PromptTypes):
    GPT4=PromptTypeSettings(llm=ChatOpenAI(model="gpt-4"))

@llm_prompt(prompt_type=MyCustomPromptTypes.GPT4) 
def write_a_complicated_code(app_idea:str)->str:
    ...

```

3. åœ¨è£…é¥°å™¨ä¸­ **ç›´æ¥å®šä¹‰è®¾ç½®** 

```python
from langchain_openai import OpenAI

@llm_prompt(
    llm=OpenAI(temperature=0.7),
    stop_tokens=["\nObservation"],
    ...
    )
def creative_writer(book_title:str)->str:
    ...
```

## ä¼ é€’å†…å­˜å’Œ/æˆ–å›è°ƒï¼š

è¦ä¼ é€’ä»»ä½•è¿™äº›ï¼Œåªéœ€åœ¨å‡½æ•°ä¸­å£°æ˜å®ƒä»¬ï¼ˆæˆ–ä½¿ç”¨ kwargs ä¼ é€’ä»»ä½•å†…å®¹ï¼‰

```python

@llm_prompt()
async def write_me_short_post(topic:str, platform:str="twitter", memory:SimpleMemory = None):
    """
    {history_key}
    ä¸ºæˆ‘å…³äº {topic} çš„å¸–å­å†™ä¸€ä¸ªçŸ­æ ‡é¢˜ï¼Œç›®æ ‡å¹³å°æ˜¯ {platform}ã€‚
    å—ä¼—æ˜¯ {audience}ã€‚
    (æœ€å¤š 15 ä¸ªè¯)
    """
    pass

await write_me_short_post(topic="old movies")

```

# ç®€åŒ–æµå¼ä¼ è¾“

å¦‚æœæˆ‘ä»¬æƒ³åˆ©ç”¨æµå¼ä¼ è¾“ï¼š
 - æˆ‘ä»¬éœ€è¦å°†æç¤ºå®šä¹‰ä¸ºå¼‚æ­¥å‡½æ•° 
 - åœ¨è£…é¥°å™¨ä¸Šæ‰“å¼€æµå¼ä¼ è¾“ï¼Œæˆ–è€…æˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸€ä¸ªå¸¦æœ‰æµå¼ä¼ è¾“çš„ PromptType 
 - ä½¿ç”¨ StreamingContext æ•è·æµ

è¿™æ ·æˆ‘ä»¬åªéœ€è¦æ ‡è®°å“ªä¸ªæç¤ºåº”è¯¥è¢«æµå¼ä¼ è¾“ï¼Œè€Œæ— éœ€è°ƒæ•´æˆ‘ä»¬åº”è¯¥ä½¿ç”¨å“ªä¸ª LLMï¼Œåœ¨é“¾çš„ç‰¹å®šéƒ¨åˆ†ä¼ é€’åˆ›å»ºå’Œåˆ†å‘æµå¤„ç†ç¨‹åºâ€¦â€¦åªéœ€æ‰“å¼€/å…³é—­æç¤º/æç¤ºç±»å‹çš„æµå¼ä¼ è¾“â€¦â€¦

åªæœ‰åœ¨æˆ‘ä»¬æµå¼ä¼ è¾“ä¸Šä¸‹æ–‡ä¸­è°ƒç”¨å®ƒæ—¶ï¼Œæ‰ä¼šå‘ç”Ÿæµå¼ä¼ è¾“â€¦â€¦åœ¨é‚£é‡Œæˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸€ä¸ªç®€å•çš„å‡½æ•°æ¥å¤„ç†æµ

```python
# è¿™ä¸ªä»£ç ç¤ºä¾‹æ˜¯å®Œæ•´çš„ï¼Œåº”è¯¥å¯ä»¥è¿è¡Œ
from langchain_decorators import StreamingContext, llm_prompt

# è¿™å°†ä¸ºæµå¼ä¼ è¾“æ ‡è®°æç¤ºï¼ˆå¦‚æœæˆ‘ä»¬åªæƒ³åœ¨åº”ç”¨ç¨‹åºä¸­æµå¼ä¼ è¾“æŸäº›æç¤ºï¼Œä½†ä¸æƒ³åˆ†å‘å›è°ƒå¤„ç†ç¨‹åºï¼Œè¿™å¾ˆæœ‰ç”¨ï¼‰
# æ³¨æ„åªæœ‰å¼‚æ­¥å‡½æ•°æ‰èƒ½æµå¼ä¼ è¾“ï¼ˆå¦‚æœä¸æ˜¯ï¼Œå°†ä¼šæ”¶åˆ°é”™è¯¯ï¼‰
@llm_prompt(capture_stream=True) 
async def write_me_short_post(topic:str, platform:str="twitter", audience:str = "developers"):
    """
    ä¸ºæˆ‘å…³äº {topic} çš„å¸–å­å†™ä¸€ä¸ªçŸ­æ ‡é¢˜ï¼Œç›®æ ‡å¹³å°æ˜¯ {platform}ã€‚
    å—ä¼—æ˜¯ {audience}ã€‚
    (æœ€å¤š 15 ä¸ªè¯)
    """
    pass



# åªæ˜¯ä¸€ä¸ªæ¼”ç¤ºæµçš„ä»»æ„å‡½æ•°... åœ¨å®é™…ä¸–ç•Œä¸­ä¼šæ˜¯ä¸€äº› WebSocket ä»£ç 
tokens=[]
def capture_stream_func(new_token:str):
    tokens.append(new_token)

# å¦‚æœæˆ‘ä»¬æƒ³æ•è·æµï¼Œæˆ‘ä»¬éœ€è¦å°†æ‰§è¡ŒåŒ…è£…åœ¨ StreamingContext ä¸­... 
# è¿™å°†å…è®¸æˆ‘ä»¬æ•è·æµï¼Œå³ä½¿æç¤ºè°ƒç”¨éšè—åœ¨é«˜å±‚æ–¹æ³•ä¸­
# è¿™é‡Œåªæ•è·ç”¨ capture_stream æ ‡è®°çš„æç¤º
with StreamingContext(stream_to_stdout=True, callback=capture_stream_func):
    result = await run_prompt()
    print("Stream finished ... æˆ‘ä»¬å¯ä»¥é€šè¿‡äº¤æ›¿çš„é¢œè‰²åŒºåˆ† token")


print("\nWe've captured",len(tokens),"tokensğŸ‰\n")
print("Here is the result:")
print(result)
```

# æç¤ºå£°æ˜
é»˜è®¤æƒ…å†µä¸‹ï¼Œæç¤ºæ˜¯æ•´ä¸ªå‡½æ•°æ–‡æ¡£å­—ç¬¦ä¸²ï¼Œé™¤éä½ æ ‡è®°ä½ çš„æç¤º 

## æ–‡æ¡£åŒ–ä½ çš„æç¤º

é€šè¿‡æŒ‡å®šä¸€ä¸ªå¸¦æœ‰ `<prompt>` è¯­è¨€æ ‡ç­¾çš„ä»£ç å—ï¼Œæˆ‘ä»¬å¯ä»¥æŒ‡å®šæ–‡æ¡£å­—ç¬¦ä¸²çš„å“ªä¸ªéƒ¨åˆ†æ˜¯æç¤ºå®šä¹‰

```python
@llm_prompt
def write_me_short_post(topic:str, platform:str="twitter", audience:str = "developers"):
    """
    è¿™æ˜¯å°†æç¤ºä½œä¸ºå‡½æ•°æ–‡æ¡£å­—ç¬¦ä¸²ä¸€éƒ¨åˆ†çš„å¥½æ–¹æ³•ï¼Œå¹¶é™„æœ‰å¼€å‘äººå‘˜çš„é¢å¤–æ–‡æ¡£ã€‚

    å®ƒéœ€è¦æ˜¯ä¸€ä¸ªä»£ç å—ï¼Œæ ‡è®°ä¸º `<prompt>` è¯­è¨€
    ```<prompt>
    ä¸ºæˆ‘å…³äº {topic} çš„å¸–å­å†™ä¸€ä¸ªçŸ­æ ‡é¢˜ï¼Œç›®æ ‡å¹³å°æ˜¯ {platform}ã€‚
    å—ä¼—æ˜¯ {audience}ã€‚
    (æœ€å¤š 15 ä¸ªè¯)
    ```

    ç°åœ¨åªæœ‰ä¸Šé¢çš„ä»£ç å—å°†è¢«ç”¨ä½œæç¤ºï¼Œè€Œæ–‡æ¡£å­—ç¬¦ä¸²çš„å…¶ä½™éƒ¨åˆ†å°†è¢«ç”¨ä½œå¼€å‘äººå‘˜çš„æè¿°ã€‚
    (å®ƒè¿˜æœ‰ä¸€ä¸ªå¾ˆå¥½çš„å¥½å¤„æ˜¯ IDEï¼ˆå¦‚ VS codeï¼‰å°†æ­£ç¡®æ˜¾ç¤ºæç¤ºï¼ˆä¸å°è¯•å°†å…¶è§£æä¸º markdownï¼Œå› æ­¤ä¸ä¼šæ­£ç¡®æ˜¾ç¤ºæ–°è¡Œï¼‰ï¼‰
    """
    return 
```

## Chat æ¶ˆæ¯æç¤º

å¯¹äºèŠå¤©æ¨¡å‹ï¼Œå°†æç¤ºå®šä¹‰ä¸ºä¸€ç»„æ¶ˆæ¯æ¨¡æ¿éå¸¸æœ‰ç”¨â€¦â€¦æ–¹æ³•å¦‚ä¸‹ï¼š

```python
@llm_prompt
def simulate_conversation(human_input:str, agent_role:str="a pirate"):
    """
    ## ç³»ç»Ÿæ¶ˆæ¯
     - æ³¨æ„ `<prompt:_role_>` æ ‡ç­¾å†…çš„ `:system` åç¼€
     

    ```<prompt:system>
    You are a {agent_role} hacker. You mus act like one.
    You reply always in code, using python or javascript code block...
    for example:
    
    ... do not reply with anything else.. just with code - respecting your role.
    ```

    # äººç±»æ¶ˆæ¯ 
    (æˆ‘ä»¬æ­£åœ¨ä½¿ç”¨ LLM å¼ºåˆ¶æ‰§è¡Œçš„çœŸå®è§’è‰² - GPT æ”¯æŒ system, assistant, user)
    ``` <prompt:user>
    Helo, who are you
    ```
    å›å¤ï¼š
    

    ``` <prompt:assistant>
    \``` python <<- ä½¿ç”¨ \ è½¬ä¹‰å†…éƒ¨ä»£ç å—ï¼Œè¯¥ä»£ç å—åº”æˆä¸ºæç¤ºçš„ä¸€éƒ¨åˆ†
    def hello():
        print("Argh... hello you pesky pirate")
    \```
    ```
    
    æˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨å ä½ç¬¦æ·»åŠ ä¸€äº›å†å²è®°å½•
    ```<prompt:placeholder>
    {history}
    ```
    ```<prompt:user>
    {human_input}
    ```

    ç°åœ¨åªæœ‰ä¸Šé¢çš„ä»£ç å—å°†è¢«ç”¨ä½œæç¤ºï¼Œè€Œæ–‡æ¡£å­—ç¬¦ä¸²çš„å…¶ä½™éƒ¨åˆ†å°†è¢«ç”¨ä½œå¼€å‘äººå‘˜çš„æè¿°ã€‚
    (å®ƒè¿˜æœ‰ä¸€ä¸ªå¾ˆå¥½çš„å¥½å¤„æ˜¯ IDEï¼ˆå¦‚ VS codeï¼‰å°†æ­£ç¡®æ˜¾ç¤ºæç¤ºï¼ˆä¸å°è¯•å°†å…¶è§£æä¸º markdownï¼Œå› æ­¤ä¸ä¼šæ­£ç¡®æ˜¾ç¤ºæ–°è¡Œï¼‰ï¼‰
    """
    pass

```

è¿™é‡Œçš„è§’è‰²æ˜¯æ¨¡å‹åŸç”Ÿè§’è‰²ï¼ˆchatGPT çš„ assistant, user, systemï¼‰

# å¯é€‰éƒ¨åˆ†
- æ‚¨å¯ä»¥å®šä¹‰æç¤ºçš„æ•´ä¸ªéƒ¨åˆ†ä¸ºå¯é€‰
- å¦‚æœéƒ¨åˆ†ä¸­çš„ä»»ä½•è¾“å…¥ç¼ºå¤±ï¼Œåˆ™æ•´ä¸ªéƒ¨åˆ†éƒ½ä¸ä¼šè¢«æ¸²æŸ“

è¯­æ³•å¦‚ä¸‹ï¼š

```python
@llm_prompt
def prompt_with_optional_partials():
    """
    è¿™äº›æ–‡æœ¬å°†å§‹ç»ˆè¢«æ¸²æŸ“ï¼Œä½†æ˜¯

    {?æ­¤å—ä¸­çš„ä»»ä½•å†…å®¹ä»…åœ¨æ‰€æœ‰ {value} å‚æ•°å‡ä¸ä¸ºç©ºï¼ˆNone | ""ï¼‰æ—¶æ‰ä¼šè¢«æ¸²æŸ“ï¼Ÿ}

    æ‚¨ä¹Ÿå¯ä»¥å°†å…¶æ”¾åœ¨å•è¯ä¹‹é—´
    è¿™ä¹Ÿå°†è¢«æ¸²æŸ“{?ï¼Œä½†æ˜¯
        æ­¤å—ä»…åœ¨ {this_value} å’Œ {this_value}
        ä¸ä¸ºç©ºæ—¶æ‰ä¼šè¢«æ¸²æŸ“ï¼Ÿ} ï¼
    """
```

# è¾“å‡ºè§£æå™¨

- llm_prompt è£…é¥°å™¨æ ¹æ®è¾“å‡ºç±»å‹æœ¬åœ°å°è¯•æ£€æµ‹æœ€ä½³è¾“å‡ºè§£æå™¨ã€‚ï¼ˆå¦‚æœæœªè®¾ç½®ï¼Œåˆ™è¿”å›åŸå§‹å­—ç¬¦ä¸²ï¼‰
- åˆ—è¡¨ã€å­—å…¸å’Œ pydantic è¾“å‡ºä¹Ÿå¾—åˆ°æœ¬åœ°æ”¯æŒï¼ˆè‡ªåŠ¨ï¼‰ã€‚

```python
# è¿™ä¸ªä»£ç ç¤ºä¾‹æ˜¯å®Œæ•´çš„ï¼Œåº”è¯¥å¯ä»¥è¿è¡Œ
from langchain_decorators import llm_prompt

@llm_prompt
def write_name_suggestions(company_business:str, count:int)->list:
    """ ä¸ºé”€å”® {company_business} çš„å…¬å¸å†™ {count} ä¸ªå¥½çš„åå­—å»ºè®®
    """
    pass

write_name_suggestions(company_business="sells cookies", count=5)
```

## æ›´å¤æ‚çš„ç»“æ„

å¯¹äºå­—å…¸/pydanticï¼Œæ‚¨éœ€è¦æŒ‡å®šæ ¼å¼è¯´æ˜â€¦â€¦è¿™å¯èƒ½å¾ˆä¹å‘³ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆæ‚¨å¯ä»¥è®©è¾“å‡ºè§£æå™¨æ ¹æ®æ¨¡å‹ï¼ˆpydanticï¼‰ä¸ºæ‚¨ç”Ÿæˆè¯´æ˜

```python
from langchain_decorators import llm_prompt
from pydantic import BaseModel, Field


class TheOutputStructureWeExpect(BaseModel):
    name:str = Field (description="å…¬å¸çš„åç§°")
    headline:str = Field( description="å…¬å¸æè¿°ï¼ˆç”¨äºç™»å½•é¡µï¼‰")
    employees:list[str] = Field(description="5-8 ä¸ªè™šæ„çš„å‘˜å·¥å§“ååŠèŒä½")

@llm_prompt()
def fake_company_generator(company_business:str)->TheOutputStructureWeExpect:
    """ ç”Ÿæˆä¸€å®¶é”€å”® {company_business} çš„è™šæ„å…¬å¸
    {FORMAT_INSTRUCTIONS}
    """
    return

company = fake_company_generator(company_business="sells cookies")

# å¥½åœ°æ ¼å¼åŒ–æ‰“å°ç»“æœ
print("Company name: ",company.name)
print("company headline: ",company.headline)
print("company employees: ",company.employees)

```

# å°†æç¤ºç»‘å®šåˆ°å¯¹è±¡

```python
from pydantic import BaseModel
from langchain_decorators import llm_prompt

class AssistantPersonality(BaseModel):
    assistant_name:str
    assistant_role:str
    field:str

    @property
    def a_property(self):
        return "whatever"

    def hello_world(self, function_kwarg:str=None):
        """
        æˆ‘ä»¬å¯ä»¥åœ¨æˆ‘ä»¬çš„æç¤ºä¸­å¼•ç”¨ä»»ä½• {field} æˆ– {a_property}â€¦â€¦å¹¶ä¸æ–¹æ³•ä¸­çš„ {function_kwarg} ç»“åˆä½¿ç”¨
        """

    
    @llm_prompt
    def introduce_your_self(self)->str:
        """
        ``` <prompt:system>
        You are an assistant named {assistant_name}. 
        Your role is to act as {assistant_role}
        ```
        ```<prompt:user>
        Introduce your self (in less than 20 words)
        ```
        """

    

personality = AssistantPersonality(assistant_name="John", assistant_role="a pirate")

print(personality.introduce_your_self(personality))
```

# æ›´å¤šç¤ºä¾‹ï¼š

- è¿™äº›ä»¥åŠå…¶ä»–ä¸€äº›ç¤ºä¾‹ä¹Ÿå¯åœ¨ [colab notebook here](https://colab.research.google.com/drive/1no-8WfeP6JaLD9yUtkPgym6x0G9ZYZOG#scrollTo=N4cf__D0E2Yk) ä¸­æ‰¾åˆ°
- åŒ…æ‹¬ä½¿ç”¨çº¯ç²¹çš„ langchain è£…é¥°å™¨é‡æ–°å®ç°çš„ [ReAct Agent](https://colab.research.google.com/drive/1no-8WfeP6JaLD9yUtkPgym6x0G9ZYZOG#scrollTo=3bID5fryE2Yp)