{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Runpod\n\n[RunPod](https://www.runpod.io/) 提供 GPU 云基础设施，包括针对部署和扩展 AI 模型而优化的 Serverless 端点。\n\n本指南涵盖了如何使用 `langchain-runpod` 集成包将 LangChain 应用程序连接到托管在 [RunPod Serverless](https://www.runpod.io/serverless-gpu) 上的模型。\n\n该集成提供了标准语言模型（LLMs）和聊天模型的接口。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 安装\n\n安装专属的合作伙伴包："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "%pip install -qU langchain-runpod"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 设置\n### 1. 在 RunPod 上部署一个端点\n- 导航到你的 [RunPod Serverless Console](https://www.runpod.io/console/serverless/user/endpoints)。\n- 创建一个“New Endpoint”，选择一个适合你的模型和预期输入/输出格式的 GPU 和模板（例如 vLLM、TGI、text-generation-webui）（请参阅组件指南或包的 [README](https://github.com/runpod/langchain-runpod)）。\n- 配置设置并部署。\n- **关键是，部署后复制 Endpoint ID**。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. 设置 API 凭据\n集成需要你的 RunPod API 密钥和 Endpoint ID。将它们设置为环境变量以安全访问："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"RUNPOD_API_KEY\"] = getpass.getpass(\"Enter your RunPod API Key: \")\n",
        "os.environ[\"RUNPOD_ENDPOINT_ID\"] = input(\"Enter your RunPod Endpoint ID: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*(可选)* 如果为 LLM 模型和 Chat 模型使用不同的端点，则可能需要设置 `RUNPOD_CHAT_ENDPOINT_ID` 或在初始化期间直接传递 ID。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 组件\n本包提供两个主要组件："
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. LLM\n\n用于与标准文本补全模型进行交互。\n\n请参阅 [RunPod LLM 集成指南](/docs/integrations/llms/runpod) 以了解详细用法。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "from langchain_runpod import RunPod\n",
        "\n",
        "# Example initialization (uses environment variables)\n",
        "llm = RunPod(model_kwargs={\"max_new_tokens\": 100})  # Add generation params here\n",
        "\n",
        "# Example Invocation\n",
        "try:\n",
        "    response = llm.invoke(\"Write a short poem about the cloud.\")\n",
        "    print(response)\n",
        "except Exception as e:\n",
        "    print(\n",
        "        f\"Error invoking LLM: {e}. Ensure endpoint ID and API key are correct and endpoint is active.\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Chat Model\n\n用于与对话模型进行交互。\n\n请参阅 [RunPod Chat Model 集成指南](/docs/integrations/chat/runpod) 以获取详细用法和功能支持。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_runpod import ChatRunPod\n",
        "\n",
        "# Example initialization (uses environment variables)\n",
        "chat = ChatRunPod(model_kwargs={\"temperature\": 0.8})  # Add generation params here\n",
        "\n",
        "# Example Invocation\n",
        "try:\n",
        "    response = chat.invoke(\n",
        "        [HumanMessage(content=\"Explain RunPod Serverless in one sentence.\")]\n",
        "    )\n",
        "    print(response.content)\n",
        "except Exception as e:\n",
        "    print(\n",
        "        f\"Error invoking Chat Model: {e}. Ensure endpoint ID and API key are correct and endpoint is active.\"\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}