# Llama.cpp

>[llama.cpp python](https://github.com/abetlen/llama-cpp-python) 库是 `@ggerganov`
>[llama.cpp](https://github.com/ggerganov/llama.cpp) 的简单 Python 绑定。
>
>此包提供：
>
> - 通过 ctypes 接口的 C API 低级访问。
> - 用于文本补全的高级 Python API
>   - 类似 `OpenAI` 的 API
>   - `LangChain` 兼容性
>   - `LlamaIndex` 兼容性
> - 类似 OpenAI 的 Web 服务器
>   - 本地 Copilot 替代方案
>   - 函数调用支持
>   - Vision API 支持
>   - 多模型

## 安装和设置

- 安装 Python 包
  ```bash
  pip install llama-cpp-python
  ````
- 下载其中一个[支持的模型](https://github.com/ggerganov/llama.cpp#description)，并按照[说明](https://github.com/ggerganov/llama.cpp)将其转换为 llama.cpp 格式。


## Chat models

请参阅[用法示例](/docs/integrations/chat/llamacpp)。

```python
from langchain_community.chat_models import ChatLlamaCpp
```

## LLMs

请参阅[用法示例](/docs/integrations/llms/llamacpp)。

```python
from langchain_community.llms import LlamaCpp
```

## Embedding models

请参阅[用法示例](/docs/integrations/text_embedding/llamacpp)。

```python
from langchain_community.embeddings import LlamaCppEmbeddings
```