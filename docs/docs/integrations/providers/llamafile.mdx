# llamafile

>[llamafile](https://github.com/Mozilla-Ocho/llamafile) 允许你通过单个文件分发和运行 LLM。

>`llamafile` 使开放式 LLM 对开发者和终端用户都更加易于访问。
>`llamafile` 通过将 [llama.cpp](https://github.com/ggerganov/llama.cpp) 与
>[Cosmopolitan Libc](https://github.com/jart/cosmopolitan) 结合到一个框架中，
> 将 LLM 的所有复杂性压缩成一个名为“llamafile”的单一文件可执行程序，
> 该程序可以在大多数计算机上本地运行，无需安装。


## 安装和设置

请参阅 [安装说明](https://github.com/Mozilla-Ocho/llamafile?tab=readme-ov-file#quickstart)。

## LLMs

请参阅 [使用示例](/docs/integrations/llms/llamafile)。

```python
from langchain_community.llms.llamafile import Llamafile
```

## 嵌入模型

请参阅 [使用示例](/docs/integrations/text_embedding/llamafile)。

```python
from langchain_community.embeddings import LlamafileEmbeddings
```