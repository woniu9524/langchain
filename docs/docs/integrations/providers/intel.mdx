# Intel

>[Optimum Intel](https://github.com/huggingface/optimum-intel?tab=readme-ov-file#optimum-intel) æ˜¯ ğŸ¤— Transformers å’Œ Diffusers åº“ä¸ Intel æä¾›çš„å„ç§å·¥å…·å’Œåº“ä¹‹é—´çš„æ¥å£ï¼Œå¯åœ¨ Intel æ¶æ„ä¸ŠåŠ é€Ÿç«¯åˆ°ç«¯æµæ°´çº¿ã€‚

>[IntelÂ® Extension for Transformers](https://github.com/intel/intel-extension-for-transformers?tab=readme-ov-file#intel-extension-for-transformers) (ITREX) æ˜¯ä¸€ä¸ªåˆ›æ–°çš„å·¥å…·åŒ…ï¼Œæ—¨åœ¨é€šè¿‡ Transformer æ¨¡å‹åœ¨å„ç§ Intel å¹³å°ï¼ˆåŒ…æ‹¬ Intel Gaudi2ã€Intel CPU å’Œ Intel GPUï¼‰ä¸Šçš„æœ€ä½³æ€§èƒ½æ¥åŠ é€Ÿå„åœ°çš„ GenAI/LLMã€‚

æœ¬æ–‡æ¡£ä»‹ç»å¦‚ä½•å°† optimum-intel å’Œ ITREX ä¸ LangChain ç»“åˆä½¿ç”¨ã€‚

## Optimum-intel

ä¸ [optimum-intel](https://github.com/huggingface/optimum-intel.git) å’Œ [IPEX](https://github.com/intel/intel-extension-for-pytorch) ç›¸å…³çš„æ‰€æœ‰åŠŸèƒ½ã€‚

### å®‰è£…

ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£… optimum-intel å’Œ ipexï¼š

```bash
pip install optimum[neural-compressor]
pip install intel_extension_for_pytorch
```

è¯·æŒ‰ç…§å¦‚ä¸‹å®‰è£…è¯´æ˜è¿›è¡Œæ“ä½œï¼š

* æŒ‰ç…§ [æ­¤å¤„](https://github.com/huggingface/optimum-intel) çš„è¯´æ˜å®‰è£… optimum-intelã€‚
* æŒ‰ç…§ [æ­¤å¤„](https://intel.github.io/intel-extension-for-pytorch/index.html#installation?platform=cpu&version=v2.2.0%2Bcpu) çš„è¯´æ˜å®‰è£… IPEXã€‚

### Embedding Models

è¯·å‚é˜… [ä½¿ç”¨ç¤ºä¾‹](/docs/integrations/text_embedding/optimum_intel)ã€‚
æˆ‘ä»¬è¿˜åœ¨ cookbook ç›®å½•ä¸­æä¾›äº†ä¸€ä¸ªå®Œæ•´çš„æ•™ç¨‹ç¬”è®°æœ¬ "rag_with_quantized_embeddings.ipynb"ï¼Œç”¨äºåœ¨ RAG æµæ°´çº¿ä¸­ä½¿ç”¨ embedderã€‚

```python
from langchain_community.embeddings import QuantizedBiEncoderEmbeddings
```

## IntelÂ® Extension for Transformers (ITREX)
(ITREX) æ˜¯ä¸€ä¸ªåˆ›æ–°çš„å·¥å…·åŒ…ï¼Œç”¨äºåœ¨ Intel å¹³å°ä¸ŠåŠ é€Ÿ Transformer æ¨¡å‹ï¼Œå°¤å…¶åœ¨ç¬¬å››ä»£ Intel Xeon å¯æ‰©å±•å¤„ç†å™¨ Sapphire Rapidsï¼ˆä»£å· Sapphire Rapidsï¼‰ä¸Šæ•ˆæœæ˜¾è‘—ã€‚

é‡åŒ–æ˜¯ä¸€ä¸ªè¿‡ç¨‹ï¼Œé€šè¿‡ä½¿ç”¨è¾ƒå°‘æ•°é‡çš„æ¯”ç‰¹æ¥è¡¨ç¤ºè¿™äº›æƒé‡ï¼Œä»è€Œé™ä½å®ƒä»¬çš„ç²¾åº¦ã€‚ä»…æƒé‡é‡åŒ–ä¸“é—¨ä¾§é‡äºé‡åŒ–ç¥ç»ç½‘ç»œçš„æƒé‡ï¼ŒåŒæ—¶å°†æ¿€æ´»ç­‰å…¶ä»–ç»„ä»¶ä¿æŒå…¶åŸå§‹ç²¾åº¦ã€‚

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ—¥ç›Šæ™®åŠï¼Œå¯¹æ–°çš„å’Œæ”¹è¿›çš„é‡åŒ–æ–¹æ³•çš„éœ€æ±‚ä¸æ–­å¢é•¿ï¼Œè¿™äº›æ–¹æ³•å¯ä»¥æ»¡è¶³è¿™äº›ç°ä»£æ¶æ„çš„è®¡ç®—éœ€æ±‚ï¼ŒåŒæ—¶ä¿æŒå‡†ç¡®æ€§ã€‚ä¸ W8A8 ç­‰[å¸¸è§„é‡åŒ–](https://github.com/intel/intel-extension-for-transformers/blob/main/docs/quantization.md)ç›¸æ¯”ï¼Œä»…æƒé‡é‡åŒ–å¯èƒ½æ˜¯å¹³è¡¡æ€§èƒ½å’Œå‡†ç¡®æ€§çš„æ›´å¥½æƒè¡¡ï¼Œå› ä¸ºæˆ‘ä»¬å°†åœ¨ä¸‹é¢çœ‹åˆ°éƒ¨ç½² LLM çš„ç“¶é¢ˆæ˜¯å†…å­˜å¸¦å®½ï¼Œè€Œä»…æƒé‡é‡åŒ–é€šå¸¸å¯ä»¥å¸¦æ¥æ›´å¥½çš„å‡†ç¡®æ€§ã€‚

åœ¨æ­¤ï¼Œæˆ‘ä»¬å°†ä»‹ç»é’ˆå¯¹ ITREX çš„ Transformer å¤§å‹è¯­è¨€æ¨¡å‹çš„ Embedding Models å’Œä»…æƒé‡é‡åŒ–ã€‚ä»…æƒé‡é‡åŒ–æ˜¯ä¸€ç§ç”¨äºæ·±åº¦å­¦ä¹ çš„æŠ€æœ¯ï¼Œç”¨äºå‡å°‘ç¥ç»ç½‘ç»œçš„å†…å­˜å’Œè®¡ç®—éœ€æ±‚ã€‚åœ¨æ·±åº¦ç¥ç»ç½‘ç»œçš„ä¸Šä¸‹æ–‡ä¸­ï¼Œæ¨¡å‹å‚æ•°ï¼Œä¹Ÿç§°ä¸ºæƒé‡ï¼Œé€šå¸¸ä½¿ç”¨æµ®ç‚¹æ•°è¡¨ç¤ºï¼Œè¿™ä¼šæ¶ˆè€—å¤§é‡çš„å†…å­˜å¹¶éœ€è¦å¯†é›†çš„è®¡ç®—èµ„æºã€‚

ä¸ [optimum-intel](https://github.com/huggingface/optimum-intel.git) å’Œ [IPEX](https://github.com/intel/intel-extension-for-pytorch) ç›¸å…³çš„æ‰€æœ‰åŠŸèƒ½ã€‚

### å®‰è£…

å®‰è£… intel-extension-for-transformersã€‚æœ‰å…³ç³»ç»Ÿè¦æ±‚å’Œå…¶ä»–å®‰è£…æŠ€å·§ï¼Œè¯·å‚é˜…[å®‰è£…æŒ‡å—](https://github.com/intel/intel-extension-for-transformers/blob/main/docs/installation.md)

```bash
pip install intel-extension-for-transformers
```
å®‰è£…å…¶ä»–å¿…éœ€çš„åŒ…ã€‚

```bash
pip install -U torch onnx accelerate datasets
```

### Embedding Models

è¯·å‚é˜… [ä½¿ç”¨ç¤ºä¾‹](/docs/integrations/text_embedding/itrex)ã€‚

```python
from langchain_community.embeddings import QuantizedBgeEmbeddings
```

### Weight-Only Quantization with ITREX

è¯·å‚é˜… [ä½¿ç”¨ç¤ºä¾‹](/docs/integrations/llms/weight_only_quantization)ã€‚

## é…ç½®å‚æ•°è¯¦è§£

ä»¥ä¸‹æ˜¯ `WeightOnlyQuantConfig` ç±»çš„è¯¦ç»†ä¿¡æ¯ã€‚

#### weight_dtype (string): æƒé‡æ•°æ®ç±»å‹ï¼Œé»˜è®¤ä¸º "nf4"ã€‚
æˆ‘ä»¬æ”¯æŒå°†æƒé‡é‡åŒ–ä¸ºä»¥ä¸‹æ•°æ®ç±»å‹è¿›è¡Œå­˜å‚¨ï¼ˆWeightOnlyQuantConfig ä¸­çš„ weight_dtypeï¼‰ï¼š
* **int8**: ä½¿ç”¨ 8 ä½æ•°æ®ç±»å‹ã€‚
* **int4_fullrange**: ç›¸å¯¹äºå¸¸è§„çš„ int4 èŒƒå›´ [-7,7]ï¼Œä½¿ç”¨ int4 çš„ -8 å€¼ã€‚
* **int4_clip**: å°†å€¼è£å‰ªå¹¶ä¿ç•™åœ¨ int4 èŒƒå›´å†…ï¼Œå°†å…¶ä»–å€¼è®¾ç½®ä¸ºé›¶ã€‚
* **nf4**: ä½¿ç”¨å½’ä¸€åŒ– 4 ä½æµ®ç‚¹æ•°æ®ç±»å‹ã€‚
* **fp4_e2m1**: ä½¿ç”¨å¸¸è§„ 4 ä½æµ®ç‚¹æ•°æ®ç±»å‹ã€‚"e2" è¡¨ç¤ºæŒ‡æ•°ä½¿ç”¨ 2 ä½ï¼Œ"m1" è¡¨ç¤ºå°¾æ•°ä½¿ç”¨ 1 ä½ã€‚

#### compute_dtype (string): è®¡ç®—æ•°æ®ç±»å‹ï¼Œé»˜è®¤ä¸º "fp32"ã€‚
è™½ç„¶è¿™äº›æŠ€æœ¯å°†æƒé‡å­˜å‚¨ä¸º 4 ä½æˆ– 8 ä½ï¼Œä½†è®¡ç®—ä»ç„¶ä»¥ float32ã€bfloat16 æˆ– int8ï¼ˆWeightOnlyQuantConfig ä¸­çš„ compute_dtypeï¼‰è¿›è¡Œï¼š
* **fp32**: ä½¿ç”¨ float32 æ•°æ®ç±»å‹è¿›è¡Œè®¡ç®—ã€‚
* **bf16**: ä½¿ç”¨ bfloat16 æ•°æ®ç±»å‹è¿›è¡Œè®¡ç®—ã€‚
* **int8**: ä½¿ç”¨ 8 ä½æ•°æ®ç±»å‹è¿›è¡Œè®¡ç®—ã€‚

#### llm_int8_skip_modules (list of module's name): è·³è¿‡é‡åŒ–çš„æ¨¡å—ï¼Œé»˜è®¤ä¸º Noneã€‚
è¿™æ˜¯ä¸€ä¸ªè¦è·³è¿‡é‡åŒ–çš„æ¨¡å—åˆ—è¡¨ã€‚

#### scale_dtype (string): Scale æ•°æ®ç±»å‹ï¼Œé»˜è®¤ä¸º "fp32"ã€‚
ç›®å‰ä»…æ”¯æŒ "fp32"ï¼ˆfloat32ï¼‰ã€‚

#### mse_range (boolean): æ˜¯å¦æœç´¢æœ€ä½³è£å‰ªèŒƒå›´ [0.805, 1.0, 0.005]ï¼Œé»˜è®¤ä¸º Falseã€‚
#### use_double_quant (boolean): æ˜¯å¦é‡åŒ– Scaleï¼Œé»˜è®¤ä¸º Falseã€‚
æš‚ä¸æ”¯æŒã€‚
#### double_quant_dtype (string): é¢„ç•™ç»™åŒé‡åŒ–ã€‚
#### double_quant_scale_dtype (string): é¢„ç•™ç»™åŒé‡åŒ–ã€‚
#### group_size (int): é‡åŒ–æ—¶çš„ç»„å¤§å°ã€‚
#### scheme (string): æƒé‡å°†è¢«é‡åŒ–æˆçš„æ ¼å¼ã€‚é»˜è®¤ä¸º "sym"ã€‚
* **sym**: å¯¹ç§°é‡åŒ–ã€‚
* **asym**: éå¯¹ç§°é‡åŒ–ã€‚
#### algorithm (string): ç”¨äºæé«˜å‡†ç¡®æ€§çš„ç®—æ³•ã€‚é»˜è®¤ä¸º "RTN"ã€‚
* **RTN**: å››èˆäº”å…¥åˆ°æœ€è¿‘å€¼ (RTN) æ˜¯ä¸€ç§æˆ‘ä»¬å¯ä»¥ç›´è§‚ç†è§£çš„é‡åŒ–æ–¹æ³•ã€‚
* **AWQ**: åªä¿æŠ¤ 1% çš„æ˜¾è‘—æƒé‡å°±å¯ä»¥å¤§å¤§å‡å°‘é‡åŒ–è¯¯å·®ã€‚æ˜¾è‘—æƒé‡é€šé“æ˜¯é€šè¿‡è§‚å¯Ÿæ¯ä¸ªé€šé“çš„æ¿€æ´»å’Œæƒé‡çš„åˆ†å¸ƒæ¥é€‰æ‹©çš„ã€‚æ˜¾è‘—æƒé‡åœ¨é‡åŒ–å‰ä¹˜ä»¥ä¸€ä¸ªå¤§çš„ç¼©æ”¾å› å­è¿›è¡Œä¿æŠ¤åå†è¿›è¡Œé‡åŒ–ã€‚
* **TEQ**: åœ¨ä»…æƒé‡é‡åŒ–ä¸­ä¿ç•™ FP32 ç²¾åº¦çš„å¯è®­ç»ƒç­‰æ•ˆå˜æ¢ã€‚