{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Upstage\n\n>[Upstage](https://upstage.ai) 是一家领先的人工智能 (AI) 公司，专注于提供超越人类水平的 LLM 组件。\n>\n>**Solar Pro** 是一款企业级 LLM，针对单 GPU 部署进行了优化，在指令遵循和处理 HTML、Markdown 等结构化格式方面表现出色。它支持英语、韩语和日语，具有顶级的多语言性能，并在金融、医疗和法律领域拥有专业知识。\n\n>除了 Solar，Upstage 还为真实世界的 RAG（检索增强生成）提供功能，例如 **Document Parse** 和 **Groundedness Check**。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Upstage LangChain 集成\n\n| API | 描述 | 导入 | 示例用法 |\n| --- | --- | --- | --- |\n| Chat | 使用 Solar Chat 构建助手 | `from langchain_upstage import ChatUpstage` | [前往](../../chat/upstage) |\n| Text Embedding | 将字符串嵌入为向量 | `from langchain_upstage import UpstageEmbeddings` | [前往](../../text_embedding/upstage) |\n| Groundedness Check | 验证助手响应的 groundedness | `from langchain_upstage import UpstageGroundednessCheck` | [前往](../../tools/upstage_groundedness_check) |\n| Document Parse | 序列化带表格和图形的文档 | `from langchain_upstage import UpstageDocumentParseLoader` | [前往](../../document_loaders/upstage) |\n\n更多关于模型和功能详情，请参阅[文档](https://console.upstage.ai/docs/getting-started/overview)。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 安装与设置\n\n安装 `langchain-upstage` 包：\n\n```bash\npip install -qU langchain-core langchain-upstage\n```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "获取 [API Keys](https://console.upstage.ai) 并设置环境变量 `UPSTAGE_API_KEY`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"UPSTAGE_API_KEY\"] = \"YOUR_API_KEY\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 聊天模型\n\n### Solar LLM\n\n请参阅[使用示例](/docs/integrations/chat/upstage)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_upstage import ChatUpstage\n",
        "\n",
        "chat = ChatUpstage()\n",
        "response = chat.invoke(\"Hello, how are you?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 嵌入式模型\n\n请参阅 [用法示例](/docs/integrations/text_embedding/upstage)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_upstage import UpstageEmbeddings\n",
        "\n",
        "embeddings = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
        "doc_result = embeddings.embed_documents(\n",
        "    [\"Sung is a professor.\", \"This is another document\"]\n",
        ")\n",
        "print(doc_result)\n",
        "\n",
        "query_result = embeddings.embed_query(\"What does Sung do?\")\n",
        "print(query_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "## 文档加载器\n\n### 文档解析\n\n请参阅 [使用示例](/docs/integrations/document_loaders/upstage)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_upstage import UpstageDocumentParseLoader\n",
        "\n",
        "file_path = \"/PATH/TO/YOUR/FILE.pdf\"\n",
        "layzer = UpstageDocumentParseLoader(file_path, split=\"page\")\n",
        "\n",
        "# For improved memory efficiency, consider using the lazy_load method to load documents page by page.\n",
        "docs = layzer.load()  # or layzer.lazy_load()\n",
        "\n",
        "for doc in docs[:3]:\n",
        "    print(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "## 工具\n\n### 基于事实的检查\n\n请参见 [使用示例](/docs/integrations/tools/upstage_groundedness_check)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [],
      "source": [
        "from langchain_upstage import UpstageGroundednessCheck\n",
        "\n",
        "groundedness_check = UpstageGroundednessCheck()\n",
        "\n",
        "request_input = {\n",
        "    \"context\": \"Mauna Kea is an inactive volcano on the island of Hawaii. Its peak is 4,207.3 m above sea level, making it the highest point in Hawaii and second-highest peak of an island on Earth.\",\n",
        "    \"answer\": \"Mauna Kea is 5,207.3 meters tall.\",\n",
        "}\n",
        "response = groundedness_check.invoke(request_input)\n",
        "print(response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}