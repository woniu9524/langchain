{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2970dd75-8ebf-4b51-8282-9b454b8f356d",
      "metadata": {},
      "source": [
        "# Together AI\n\n[Together AI](https://www.together.ai/) 提供了一个 API，可以用几行代码查询 [50 多个领先的开源模型](https://docs.together.ai/docs/inference-models)。\n\n本示例将介绍如何使用 LangChain 与 Together AI 模型进行交互。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c47fc36",
      "metadata": {},
      "source": [
        "## 安装"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ecdb29d",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install --upgrade langchain-together"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89883202",
      "metadata": {},
      "source": [
        "## 环境\n\n要使用 Together AI，您需要一个 API 密钥，您可以在此处找到：\nhttps://api.together.ai/settings/api-keys。这可以通过 `together_api_key` 作为初始化参数传入，\n或者设置为环境变量 `TOGETHER_API_KEY`。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8304b4d9",
      "metadata": {},
      "source": [
        "## 示例"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "637bb53f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Querying chat models with Together AI\n",
        "\n",
        "from langchain_together import ChatTogether\n",
        "\n",
        "# choose from our 50+ models here: https://docs.together.ai/docs/inference-models\n",
        "chat = ChatTogether(\n",
        "    # together_api_key=\"YOUR_API_KEY\",\n",
        "    model=\"meta-llama/Llama-3-70b-chat-hf\",\n",
        ")\n",
        "\n",
        "# stream the response back from the model\n",
        "for m in chat.stream(\"Tell me fun things to do in NYC\"):\n",
        "    print(m.content, end=\"\", flush=True)\n",
        "\n",
        "# if you don't want to do streaming, you can use the invoke method\n",
        "# chat.invoke(\"Tell me fun things to do in NYC\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7b7170d-d7c5-4890-9714-a37238343805",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Querying code and language models with Together AI\n",
        "\n",
        "from langchain_together import Together\n",
        "\n",
        "llm = Together(\n",
        "    model=\"codellama/CodeLlama-70b-Python-hf\",\n",
        "    # together_api_key=\"...\"\n",
        ")\n",
        "\n",
        "print(llm.invoke(\"def bubble_sort(): \"))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}