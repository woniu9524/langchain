# DeepInfra

>[DeepInfra](https://deepinfra.com/docs) 允许我们轻松运行[最新的机器学习模型](https://deepinfra.com/models)。
>DeepInfra 负责运行、扩展和监控模型的所有繁重工作。用户可以专注于你的应用程序，并通过简单的 REST API 调用集成模型。

>DeepInfra 提供了与 LangChain 集成的[示例](https://deepinfra.com/docs/advanced/langchain)。

本页面介绍如何在 `LangChain` 中使用 `DeepInfra` 生态系统。
它分为两部分：安装和设置，然后是特定 DeepInfra 封装器的参考。

## 安装和设置

- 从此链接[此处](https://deepinfra.com/)获取你的 DeepInfra api 密钥。
- 获取 DeepInfra api 密钥并将其设置为环境变量 (`DEEPINFRA_API_TOKEN`)

## 可用模型

DeepInfra 提供了一系列可供部署的开源 LLM。

你可以查看支持的[文本生成](https://deepinfra.com/models?type=text-generation)和[嵌入](https://deepinfra.com/models?type=embeddings)的模型。

你可以查看[请求和响应参数列表](https://deepinfra.com/meta-llama/Llama-2-70b-chat-hf/api)。

聊天模型[遵循 openai api](https://deepinfra.com/meta-llama/Llama-2-70b-chat-hf/api?example=openai-http)


## LLM

请参阅[使用示例](/docs/integrations/llms/deepinfra)。

```python
from langchain_community.llms import DeepInfra
```

## Embeddings

请参阅[使用示例](/docs/integrations/text_embedding/deepinfra)。

```python
from langchain_community.embeddings import DeepInfraEmbeddings
```

## Chat Models

请参阅[使用示例](/docs/integrations/chat/deepinfra)。

```python
from langchain_community.chat_models import ChatDeepInfra
```