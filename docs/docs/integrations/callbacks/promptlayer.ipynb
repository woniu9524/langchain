{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PromptLayer\n\n>[PromptLayer](https://docs.promptlayer.com/introduction) 是一个用于 Prompt Engineering 的平台。它还提供 LLM 可观测性，用于可视化请求、版本化 Prompt 以及跟踪使用情况。\n\n虽然 `PromptLayer` 确实有与 LangChain 直接集成的 LLM（例如 [`PromptLayerOpenAI`](/docs/integrations/llms/promptlayer_openai)），但使用回调是集成 `PromptLayer` 与 LangChain 的推荐方式。\n\n在本指南中，我们将介绍如何设置 `PromptLayerCallbackHandler`。\n\n更多信息请参阅 [PromptLayer 文档](https://docs.promptlayer.com/languages/langchain)。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "tags": []
      },
      "source": [
        "## 安装与设置"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet  langchain-community promptlayer --upgrade"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 获取 API 凭证\n\n如果您还没有 PromptLayer 账户，请先在 [promptlayer.com](https://www.promptlayer.com) 上创建一个。然后，点击导航栏中的设置齿轮图标来获取 API 密钥，并将其设置为名为 `PROMPTLAYER_API_KEY` 的环境变量。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 用法\n\n开始使用 `PromptLayerCallbackHandler` 非常简单，它接受两个可选参数：\n1. `pl_tags` - 一个可选的字符串列表，将在 PromptLayer 上作为标签进行跟踪。\n2. `pl_id_callback` - 一个可选的函数，它将以 `promptlayer_request_id` 作为参数。此 ID 可与 PromptLayer 的所有跟踪功能一起用于跟踪、元数据、分数和提示使用情况。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 简单的 OpenAI 示例\n\n在这个简单的示例中，我们使用 `ChatOpenAI` 和 `PromptLayerCallbackHandler`。我们添加一个名为 `chatopenai` 的 PromptLayer 标签。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-06T19:10:56.673622Z",
          "iopub.status.busy": "2024-03-06T19:10:56.673421Z",
          "iopub.status.idle": "2024-03-06T19:10:56.887519Z",
          "shell.execute_reply": "2024-03-06T19:10:56.886895Z",
          "shell.execute_reply.started": "2024-03-06T19:10:56.673608Z"
        }
      },
      "outputs": [],
      "source": [
        "import promptlayer  # Don't forget this 🍰\n",
        "from langchain_community.callbacks.promptlayer_callback import (\n",
        "    PromptLayerCallbackHandler,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat_llm = ChatOpenAI(\n",
        "    temperature=0,\n",
        "    callbacks=[PromptLayerCallbackHandler(pl_tags=[\"chatopenai\"])],\n",
        ")\n",
        "llm_results = chat_llm.invoke(\n",
        "    [\n",
        "        HumanMessage(content=\"What comes after 1,2,3 ?\"),\n",
        "        HumanMessage(content=\"Tell me another joke?\"),\n",
        "    ]\n",
        ")\n",
        "print(llm_results)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GPT4All 示例"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.llms import GPT4All\n",
        "\n",
        "model = GPT4All(model=\"./models/gpt4all-model.bin\", n_ctx=512, n_threads=8)\n",
        "callbacks = [PromptLayerCallbackHandler(pl_tags=[\"langchain\", \"gpt4all\"])]\n",
        "\n",
        "response = model.invoke(\n",
        "    \"Once upon a time, \",\n",
        "    config={\"callbacks\": callbacks},\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 功能齐全的示例\n\n在本示例中，我们将解锁 `PromptLayer` 的更多强大功能。\n\nPromptLayer 允许您以可视化的方式创建、版本化和跟踪提示模板。使用 [Prompt Registry](https://docs.promptlayer.com/features/prompt-registry)，我们可以以编程方式获取名为 `example` 的提示模板。\n\n我们还定义了一个 `pl_id_callback` 函数，该函数接收 `promptlayer_request_id` 并记录分数、元数据以及链接所使用的提示模板。在[我们的文档](https://docs.promptlayer.com/features/prompt-history/request-id)中阅读有关跟踪的更多信息。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAI\n",
        "\n",
        "\n",
        "def pl_id_callback(promptlayer_request_id):\n",
        "    print(\"prompt layer id \", promptlayer_request_id)\n",
        "    promptlayer.track.score(\n",
        "        request_id=promptlayer_request_id, score=100\n",
        "    )  # score is an integer 0-100\n",
        "    promptlayer.track.metadata(\n",
        "        request_id=promptlayer_request_id, metadata={\"foo\": \"bar\"}\n",
        "    )  # metadata is a dictionary of key value pairs that is tracked on PromptLayer\n",
        "    promptlayer.track.prompt(\n",
        "        request_id=promptlayer_request_id,\n",
        "        prompt_name=\"example\",\n",
        "        prompt_input_variables={\"product\": \"toasters\"},\n",
        "        version=1,\n",
        "    )  # link the request to a prompt template\n",
        "\n",
        "\n",
        "openai_llm = OpenAI(\n",
        "    model_name=\"gpt-3.5-turbo-instruct\",\n",
        "    callbacks=[PromptLayerCallbackHandler(pl_id_callback=pl_id_callback)],\n",
        ")\n",
        "\n",
        "example_prompt = promptlayer.prompts.get(\"example\", version=1, langchain=True)\n",
        "openai_llm.invoke(example_prompt.format(product=\"toasters\"))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "就是这样！设置完成后，您的所有请求都会显示在 PromptLayer 仪表板上。\n此回调也适用于 LangChain 上实现的任何 LLM。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "c4fe2cd85a8d9e8baaec5340ce66faff1c77581a9f43e6c45e85e09b6fced008"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}