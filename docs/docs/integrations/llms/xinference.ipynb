{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Xorbits 推理 (Xinference)\n\n[Xinference](https://github.com/xorbitsai/inference) 是一个强大且通用的库，旨在为 LLM、语音识别模型和多模态模型提供服务，即使在你的笔记本电脑上也能运行。它支持多种与 GGML 兼容的模型，例如 chatglm、baichuan、whisper、vicuna、orca 等等。本教程演示了如何将 Xinference 与 LangChain 结合使用。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 安装\n\n通过 PyPI 安装 `Xinference`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet  \"xinference[all]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 在本地或分布式集群中部署 Xinference。\n\n本地部署，运行 `xinference`。\n\n要在集群中部署 Xinference，首先使用 `xinference-supervisor` 启动一个 Xinference supervisor。您还可以使用 `-p` 参数指定端口，`-H` 参数指定主机。默认端口为 9997。\n\n然后，在您希望运行 worker 的每个服务器上使用 `xinference-worker` 启动 Xinference workers。\n\n您可以查阅 [Xinference](https://github.com/xorbitsai/inference) 的 README 文件以获取更多信息。\n## Wrapper\n\n要将 Xinference 与 LangChain 一起使用，您首先需要启动一个模型。您可以使用命令行界面 (CLI) 来执行此操作："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model uid: 7167b2b0-2a04-11ee-83f0-d29396a3f064\n"
          ]
        }
      ],
      "source": [
        "!xinference launch -n vicuna-v1.3 -f ggmlv3 -q q4_0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "现在您可以使用 Xinference 的 LangChain 了：模型 UID 将会返回供您使用。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' You can visit the Eiffel Tower, Notre-Dame Cathedral, the Louvre Museum, and many other historical sites in Paris, the capital of France.'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_community.llms import Xinference\n",
        "\n",
        "llm = Xinference(\n",
        "    server_url=\"http://0.0.0.0:9997\", model_uid=\"7167b2b0-2a04-11ee-83f0-d29396a3f064\"\n",
        ")\n",
        "\n",
        "llm(\n",
        "    prompt=\"Q: where can we visit in the capital of France? A:\",\n",
        "    generate_config={\"max_tokens\": 1024, \"stream\": True},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 与 LLMChain 集成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "A: You can visit many places in Paris, such as the Eiffel Tower, the Louvre Museum, Notre-Dame Cathedral, the Champs-Elysées, Montmartre, Sacré-Cœur, and the Palace of Versailles.\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "template = \"Where can we visit in the capital of {country}?\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "generated = llm_chain.run(country=\"France\")\n",
        "print(generated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "最后，当您不再需要该模型时，请终止它："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "!xinference terminate --model-uid \"7167b2b0-2a04-11ee-83f0-d29396a3f064\""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "myenv3.9",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}