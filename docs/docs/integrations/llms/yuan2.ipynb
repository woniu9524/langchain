{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Yuan2.0\n\n[Yuan2.0](https://github.com/IEIT-Yuan/Yuan-2.0) 是由 IEIT System 开发的新一代基础大语言模型。我们已经发布了 Yuan 2.0-102B、Yuan 2.0-51B 和 Yuan 2.0-2B 这三个模型。我们还为其他开发者提供了相关的预训练、微调和推理服务脚本。Yuan2.0 基于 Yuan1.0，利用更广泛的高质量预训练数据和指令微调数据集，以增强模型在语义、数学、推理、代码、知识等方面的理解能力。\n\n本示例将介绍如何使用 LangChain 与 `Yuan2.0`(2B/51B/102B) 推理进行交互以实现文本生成。\n\nYuan2.0 设置了推理服务，用户只需请求推理 API 即可获得结果，具体介绍请参见 [Yuan2.0 Inference-Server](https://github.com/IEIT-Yuan/Yuan-2.0/blob/main/docs/inference_server.md)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain_community.llms.yuan2 import Yuan2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# default infer_api for a local deployed Yuan2.0 inference server\n",
        "infer_api = \"http://127.0.0.1:8000/yuan\"\n",
        "\n",
        "# direct access endpoint in a proxied environment\n",
        "# import os\n",
        "# os.environ[\"no_proxy\"]=\"localhost,127.0.0.1,::1\"\n",
        "\n",
        "yuan_llm = Yuan2(\n",
        "    infer_api=infer_api,\n",
        "    max_tokens=2048,\n",
        "    temp=1.0,\n",
        "    top_p=0.9,\n",
        "    use_history=False,\n",
        ")\n",
        "\n",
        "# turn on use_history only when you want the Yuan2.0 to keep track of the conversation history\n",
        "# and send the accumulated context to the backend model api, which make it stateful. By default it is stateless.\n",
        "# llm.use_history = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "question = \"请介绍一下中国。\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "print(yuan_llm.invoke(question))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langchain-dev",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}