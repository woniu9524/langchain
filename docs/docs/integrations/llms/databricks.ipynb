{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Databricks\n\n> [Databricks](https://www.databricks.com/) Lakehouse 平台在一个平台上统一了数据、分析和人工智能。\n\n\n本笔记本提供了 Databricks [LLM 模型](https://python.langchain.com/docs/concepts/text_llms)的入门快速概述。有关所有功能和配置的详细文档，请访问[API 参考](https://python.community.llms.databricks.Databricks.html)。\n\n## 概述\n\n`Databricks` LLM 类封装了一个完成端点，该端点托管为以下两种端点类型之一：\n\n* [Databricks Model Serving](https://docs.databricks.com/en/machine-learning/model-serving/index.html)，推荐用于生产和开发，\n* Cluster driver proxy app，推荐用于交互式开发。\n\n本示例笔记本展示了如何封装您的 LLM 端点并将其用作 LangChain 应用程序中的 LLM。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 局限性\n\n`Databricks` LLM 类是*遗留*实现，在功能兼容性方面存在一些局限性。\n\n* 仅支持同步调用。不支持流式或异步 API。\n* 不支持 `batch` API。\n\n要使用这些功能，请改用新的 [ChatDatabricks](https://python.langchain.com/docs/integrations/chat/databricks) 类。`ChatDatabricks` 支持 `ChatModel` 的所有 API，包括流式、异步、批量等。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 设置\n\n要访问 Databricks 模型，您需要创建 Databricks 账户，设置凭证（仅当您在 Databricks 工作区外部时），并安装所需的包。\n\n### 凭证（仅当您在 Databricks 外部时）\n\n如果您在 Databricks 内运行 LangChain 应用，则可以跳过此步骤。\n\n否则，您需要将 Databricks 工作区主机名和个人访问令牌分别手动设置为 `DATABRICKS_HOST` 和 `DATABRICKS_TOKEN` 环境变量。有关如何获取访问令牌的更多信息，请参阅 [身份验证文档](https://docs.databricks.com/en/dev-tools/auth/index.html#databricks-personal-access-tokens) 。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"DATABRICKS_HOST\"] = \"https://your-workspace.cloud.databricks.com\"\n",
        "if \"DATABRICKS_TOKEN\" not in os.environ:\n",
        "    os.environ[\"DATABRICKS_TOKEN\"] = getpass.getpass(\n",
        "        \"Enter your Databricks access token: \"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "或者，您可以在初始化 `Databricks` 类时传递这些参数。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.llms import Databricks\n",
        "\n",
        "databricks = Databricks(\n",
        "    host=\"https://your-workspace.cloud.databricks.com\",\n",
        "    # We strongly recommend NOT to hardcode your access token in your code, instead use secret management tools\n",
        "    # or environment variables to store your access token securely. The following example uses Databricks Secrets\n",
        "    # to retrieve the access token that is available within the Databricks notebook.\n",
        "    token=dbutils.secrets.get(scope=\"YOUR_SECRET_SCOPE\", key=\"databricks-token\"),  # noqa: F821\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 安装\n\nLangChain Databricks 集成位于 `langchain-community` 包中。此外，运行此笔记本中的代码需要 `mlflow >= 2.9`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -qU langchain-community mlflow>=2.9.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 封装模型服务终结点\n\n### 先决条件：\n\n* 已注册一个 LLM 并将其部署到 [Databricks 服务终结点](https://docs.databricks.com/machine-learning/model-serving/index.html)。\n* 您拥有该终结点的 [\"Can Query\" 权限](https://docs.databricks.com/security/auth-authz/access-control/serving-endpoint-acl.html)。\n\n预期的 MLflow 模型签名是：\n\n  * inputs: `[{\"name\": \"prompt\", \"type\": \"string\"}, {\"name\": \"stop\", \"type\": \"list[string]\"}]`\n  * outputs: `[{\"type\": \"string\"}]`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 调用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'I am happy to hear that you are in good health and as always, you are appreciated.'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_community.llms import Databricks\n",
        "\n",
        "llm = Databricks(endpoint_name=\"YOUR_ENDPOINT_NAME\")\n",
        "llm.invoke(\"How are you?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Good'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.invoke(\"How are you?\", stop=[\".\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 转换输入和输出\n\n有时您可能需要包装一个服务接口，该接口的模型签名不兼容，或者您想插入额外的配置。您可以使用 `transform_input_fn` 和 `transform_output_fn` 参数来定义额外的预处理/后处理。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'I AM DOING GREAT THANK YOU.'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Use `transform_input_fn` and `transform_output_fn` if the serving endpoint\n",
        "# expects a different input schema and does not return a JSON string,\n",
        "# respectively, or you want to apply a prompt template on top.\n",
        "\n",
        "\n",
        "def transform_input(**request):\n",
        "    full_prompt = f\"\"\"{request[\"prompt\"]}\n",
        "    Be Concise.\n",
        "    \"\"\"\n",
        "    request[\"prompt\"] = full_prompt\n",
        "    return request\n",
        "\n",
        "\n",
        "def transform_output(response):\n",
        "    return response.upper()\n",
        "\n",
        "\n",
        "llm = Databricks(\n",
        "    endpoint_name=\"YOUR_ENDPOINT_NAME\",\n",
        "    transform_input_fn=transform_input,\n",
        "    transform_output_fn=transform_output,\n",
        ")\n",
        "\n",
        "llm.invoke(\"How are you?\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}