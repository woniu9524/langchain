{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Petals\n\n`Petals` 以 BitTorrent 的方式，在家中运行 100B+ 的语言模型。\n\n本教程将介绍如何将 Langchain 与 [Petals](https://github.com/bigscience-workshop/petals) 结合使用。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 安装 petals\n\n需要 `petals` 包才能使用 Petals API。使用 `pip3 install petals` 安装 `petals`。\n\nApple Silicon (M1/M2) 用户请遵循此指南 [https://github.com/bigscience-workshop/petals/issues/147#issuecomment-1365379642](https://github.com/bigscience-workshop/petals/issues/147#issuecomment-1365379642) 来安装 petals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install petals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_community.llms import Petals\n",
        "from langchain_core.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 设置环境变量 API 密钥\n请确保从 Huggingface 获取[你的 API 密钥](https://huggingface.co/docs/api-inference/quicktour#get-your-api-token)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ········\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "\n",
        "HUGGINGFACE_API_KEY = getpass()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"HUGGINGFACE_API_KEY\"] = HUGGINGFACE_API_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 创建 Petals 实例\n您可以指定不同的参数，如模型名称、最大新令牌数、温度等。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading:   1%|▏                        | 40.8M/7.19G [00:24<15:44, 7.57MB/s]"
          ]
        }
      ],
      "source": [
        "# this can take several minutes to download big files!\n",
        "\n",
        "llm = Petals(model_name=\"bigscience/bloom-petals\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 创建提示模板\n我们将创建一个用于问答的提示模板。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "template = \"\"\"Question: {question}\n",
        "\n",
        "Answer: Let's think step by step.\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 初始化 LLMChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "llm_chain = LLMChain(prompt=prompt, llm=llm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 运行 LLMChain\n提供一个问题并运行 LLMChain。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "question = \"What NFL team won the Super Bowl in the year Justin Beiber was born?\"\n",
        "\n",
        "llm_chain.run(question)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "a0a0263b650d907a3bfe41c0f8d6a63a071b884df3cfdc1579f00cdc1aed6b03"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}