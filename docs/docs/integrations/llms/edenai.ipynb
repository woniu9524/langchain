{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Eden AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Eden AI 通过整合顶尖的 AI 供应商，正在革新 AI 领域，赋能用户解锁无限可能，挖掘人工智能的真正潜力。它提供了一个集成化、全面且无忧的平台，让用户能够闪电般地将 AI 功能部署到生产环境中，通过单一 API 轻松访问所有广泛的 AI 能力。 (网站：https://edenai.co/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "本示例将介绍如何使用 LangChain 与 Eden AI 模型进行交互"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "访问 EDENAI 的 API 需要一个 API 密钥，\n\n你可以通过创建账户 https://app.edenai.run/user/register 并前往 https://app.edenai.run/admin/account/settings 获取。\n\n获得密钥后，我们需要将其设置为环境变量，运行以下命令：\n\n```bash\nexport EDENAI_API_KEY=\"...\"\n```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "如果您不希望设置环境变量，可以直接通过 `edenai_api_key` 命名参数传递密钥，在初始化 EdenAI LLM 类时："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.llms import EdenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "llm = EdenAI(edenai_api_key=\"...\", provider=\"openai\", temperature=0.2, max_tokens=250)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 调用模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "EdenAI API 汇集了各种提供商，每个提供商都提供多种模型。\n\n要访问特定模型，您只需在实例化时添加 'model' 即可。\n\n例如，让我们探索 OpenAI 提供的模型，例如 GPT3.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 文本生成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "llm = EdenAI(\n",
        "    feature=\"text\",\n",
        "    provider=\"openai\",\n",
        "    model=\"gpt-3.5-turbo-instruct\",\n",
        "    temperature=0.2,\n",
        "    max_tokens=250,\n",
        ")\n",
        "\n",
        "prompt = \"\"\"\n",
        "User: Answer the following yes/no question by reasoning step by step. Can a dog drive a car?\n",
        "Assistant:\n",
        "\"\"\"\n",
        "\n",
        "llm(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 图像生成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import base64\n",
        "from io import BytesIO\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def print_base64_image(base64_string):\n",
        "    # Decode the base64 string into binary data\n",
        "    decoded_data = base64.b64decode(base64_string)\n",
        "\n",
        "    # Create an in-memory stream to read the binary data\n",
        "    image_stream = BytesIO(decoded_data)\n",
        "\n",
        "    # Open the image using PIL\n",
        "    image = Image.open(image_stream)\n",
        "\n",
        "    # Display the image\n",
        "    image.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text2image = EdenAI(feature=\"image\", provider=\"openai\", resolution=\"512x512\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_output = text2image(\"A cat riding a motorcycle by Picasso\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print_base64_image(image_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 使用回调进行文本生成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.llms import EdenAI\n",
        "from langchain_core.callbacks import StreamingStdOutCallbackHandler\n",
        "\n",
        "llm = EdenAI(\n",
        "    callbacks=[StreamingStdOutCallbackHandler()],\n",
        "    feature=\"text\",\n",
        "    provider=\"openai\",\n",
        "    temperature=0.2,\n",
        "    max_tokens=250,\n",
        ")\n",
        "prompt = \"\"\"\n",
        "User: Answer the following yes/no question by reasoning step by step. Can a dog drive a car?\n",
        "Assistant:\n",
        "\"\"\"\n",
        "print(llm.invoke(prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chaining Calls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chains import LLMChain, SimpleSequentialChain\n",
        "from langchain_core.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "llm = EdenAI(feature=\"text\", provider=\"openai\", temperature=0.2, max_tokens=250)\n",
        "text2image = EdenAI(feature=\"image\", provider=\"openai\", resolution=\"512x512\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"product\"],\n",
        "    template=\"What is a good name for a company that makes {product}?\",\n",
        ")\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "second_prompt = PromptTemplate(\n",
        "    input_variables=[\"company_name\"],\n",
        "    template=\"Write a description of a logo for this company: {company_name}, the logo should not contain text at all \",\n",
        ")\n",
        "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "third_prompt = PromptTemplate(\n",
        "    input_variables=[\"company_logo_description\"],\n",
        "    template=\"{company_logo_description}\",\n",
        ")\n",
        "chain_three = LLMChain(llm=text2image, prompt=third_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the chain specifying only the input variable for the first chain.\n",
        "overall_chain = SimpleSequentialChain(\n",
        "    chains=[chain, chain_two, chain_three], verbose=True\n",
        ")\n",
        "output = overall_chain.run(\"hats\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print the image\n",
        "print_base64_image(output)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}