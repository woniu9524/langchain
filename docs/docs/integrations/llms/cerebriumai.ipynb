{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CerebriumAI\n\n`Cerebrium` 是 AWS Sagemaker 的替代品。它还提供对 [多个 LLM 模型](https://docs.cerebrium.ai/cerebrium/prebuilt-models/deployment) 的 API 访问。\n\n本 Notebook 将介绍如何将 Langchain 与 [CerebriumAI](https://docs.cerebrium.ai/introduction) 结合使用。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 安装 cerebrium\n要使用 `CerebriumAI` API，需要 `cerebrium` 包。使用 `pip3 install cerebrium` 安装 `cerebrium`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install the package\n",
        "!pip3 install cerebrium"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_community.llms import CerebriumAI\n",
        "from langchain_core.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 设置环境 API 密钥\n请确保从 CerebriumAI 获取您的 API 密钥。请参见 [这里](https://dashboard.cerebrium.ai/login)。您将获得 1 小时的免费无服务器 GPU 计算时间来测试不同的模型。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"CEREBRIUMAI_API_KEY\"] = \"YOUR_KEY_HERE\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 创建 CerebriumAI 实例\n您可以指定不同的参数，例如模型端点 URL、最大长度、温度等。您必须提供一个端点 URL。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "llm = CerebriumAI(endpoint_url=\"YOUR ENDPOINT URL HERE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 创建一个 Prompt 模板\n我们将为问答创建一个 Prompt 模板。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "template = \"\"\"Question: {question}\n",
        "\n",
        "Answer: Let's think step by step.\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 初始化 LLMChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "llm_chain = LLMChain(prompt=prompt, llm=llm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 运行 LLMChain\n提供一个问题并运行 LLMChain。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "question = \"What NFL team won the Super Bowl in the year Justin Beiber was born?\"\n",
        "\n",
        "llm_chain.run(question)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "a0a0263b650d907a3bfe41c0f8d6a63a071b884df3cfdc1579f00cdc1aed6b03"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}