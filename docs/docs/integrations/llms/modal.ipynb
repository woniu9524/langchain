{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modal\n\n[Modal 云平台](https://modal.com/docs/guide)提供便捷的按需访问功能，让您能够从本地计算机上的 Python 脚本获得无服务器云计算能力。\n使用 `modal` 来运行您自己的定制 LLM 模型，而不是依赖 LLM API。\n\n本示例将介绍如何使用 LangChain 与 `modal` 的 HTTPS [Web 端点](https://modal.com/docs/guide/webhooks)进行交互。\n\n[_使用 LangChain 进行问答_](https://modal.com/docs/guide/ex/potus_speech_qanda) 是另一个展示如何与 `Modal` 一同使用 LangChain 的示例。在该示例中，Modal 端到端地运行 LangChain 应用程序，并使用 OpenAI 作为其 LLM API。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet  modal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Launching login page in your browser window...\n",
            "If this is not showing up, please copy this URL into your web browser manually:\n",
            "https://modal.com/token-flow/tf-Dzm3Y01234mqmm1234Vcu3\n"
          ]
        }
      ],
      "source": [
        "# Register an account with Modal and get a new token.\n",
        "\n",
        "!modal token new"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`langchain.llms.modal.Modal` 集成类要求您部署一个 Modal 应用，该应用需要有一个符合以下 JSON 接口的 Web 端点：\n\n1. LLM 的提示作为键为 `\"prompt\"` 的 `str` 值接收。\n2. LLM 的响应作为键为 `\"prompt\"` 的 `str` 值返回。\n\n**示例请求 JSON：**\n\n```json\n{\n    \"prompt\": \"Identify yourself, bot!\",\n    \"extra\": \"args are allowed\",\n}\n```\n\n**示例响应 JSON：**\n\n```json\n{\n    \"prompt\": \"This is the LLM speaking\",\n}\n```\n\n一个满足此接口的示例“虚拟”Modal Web 端点函数如下：\n\n```python\n...\n...\n\nclass Request(BaseModel):\n    prompt: str\n\n@stub.function()\n@modal.web_endpoint(method=\"POST\")\ndef web(request: Request):\n    _ = request  # ignore input\n    return {\"prompt\": \"hello world\"}\n```\n\n* 有关设置符合此接口的端点的基础知识，请参阅 Modal 的 [Web 端点](https://modal.com/docs/guide/webhooks#passing-arguments-to-web-endpoints) 指南。\n* 将 Modal 的 ['运行 Falcon-40B 配合 AutoGPTQ'](https://modal.com/docs/guide/ex/falcon_gptq) 开源 LLM 示例作为自定义 LLM 的起点！"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "一旦你部署了一个 Modal web endpoint，你就可以将它的 URL 传递给 `langchain.llms.modal.Modal` LLM 类。这个类随后就可以在你构建的链式结构中作为一个构建模块来使用。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain_community.llms import Modal\n",
        "from langchain_core.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "template = \"\"\"Question: {question}\n",
        "\n",
        "Answer: Let's think step by step.\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "endpoint_url = \"https://ecorp--custom-llm-endpoint.modal.run\"  # REPLACE ME with your deployed Modal web endpoint's URL\n",
        "llm = Modal(endpoint_url=endpoint_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "llm_chain = LLMChain(prompt=prompt, llm=llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "question = \"What NFL team won the Super Bowl in the year Justin Beiber was born?\"\n",
        "\n",
        "llm_chain.run(question)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "a0a0263b650d907a3bfe41c0f8d6a63a071b884df3cfdc1579f00cdc1aed6b03"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}