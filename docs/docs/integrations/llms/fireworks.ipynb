{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cc6caafa",
      "metadata": {},
      "source": [
        "# Fireworks\n\n:::caution\n您目前正在查看记录如何将 Fireworks 模型用作 [文本补全模型](/docs/concepts/text_llms) 的页面。许多流行的 Fireworks 模型是 [聊天补全模型](/docs/concepts/chat_models)。\n\n您可能在寻找 [此页面](/docs/integrations/chat/fireworks/)。\n:::\n\n>[Fireworks](https://app.fireworks.ai/) 通过创建创新的 AI 实验和生产平台，加速生成式 AI 产品开发。\n\n本示例将介绍如何使用 LangChain 与 `Fireworks` 模型进行交互。\n\n## 概览\n### 集成详情\n\n| 类 | 包 | 本地 | 可序列化 | [JS 支持](https://js.langchain.com/v0.1/docs/integrations/llms/fireworks/) | 包下载 | 包最新版本 |\n| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\n| [Fireworks](https://python.langchain.com/api_reference/fireworks/llms/langchain_fireworks.llms.Fireworks.html#langchain_fireworks.llms.Fireworks) | [langchain_fireworks](https://python.langchain.com/api_reference/fireworks/index.html) | ❌ | ❌ | ✅ | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain_fireworks?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain_fireworks?style=flat-square&label=%20) |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccff689e",
      "metadata": {},
      "source": [
        "## 设置\n\n### 凭证\n\n登录 [Fireworks AI](http://fireworks.ai) 获取 API 密钥以访问我们的模型，并确保将其设置为 `FIREWORKS_API_KEY` 环境变量。\n3. 使用模型 ID 设置您的模型。如果未设置模型，则默认模型为 fireworks-llama-v2-7b-chat。有关完整且最新的模型列表，请参阅 [fireworks.ai](https://fireworks.ai)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9ca87a2e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"FIREWORKS_API_KEY\" not in os.environ:\n",
        "    os.environ[\"FIREWORKS_API_KEY\"] = getpass.getpass(\"Fireworks API Key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e42ced7e",
      "metadata": {},
      "source": [
        "### 安装\n\n您需要安装 `langchain_fireworks` Python 包，才能使其余的 Notebook 生效。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ca824723",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -qU langchain-fireworks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acc24d0c",
      "metadata": {},
      "source": [
        "## 实例化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d285fd7f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_fireworks import Fireworks\n",
        "\n",
        "# Initialize a Fireworks model\n",
        "llm = Fireworks(\n",
        "    model=\"accounts/fireworks/models/llama-v3p1-8b-instruct\",\n",
        "    base_url=\"https://api.fireworks.ai/inference/v1/completions\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4c29f7b",
      "metadata": {},
      "source": [
        "## 调用\n\n您可以通过字符串提示直接调用模型来获取补全。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bf0a425c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " If Manningville Station, Lions rookie EJ Manuel's\n"
          ]
        }
      ],
      "source": [
        "output = llm.invoke(\"Who's the best quarterback in the NFL?\")\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0283343",
      "metadata": {},
      "source": [
        "### 使用多个提示进行调用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "afc7de6f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[Generation(text=\" We're not just asking, we've done some research. We'\")], [Generation(text=' The conversation is dominated by Kobe Bryant, Dwyane Wade,')]]\n"
          ]
        }
      ],
      "source": [
        "# Calling multiple prompts\n",
        "output = llm.generate(\n",
        "    [\n",
        "        \"Who's the best cricket player in 2016?\",\n",
        "        \"Who's the best basketball player in the league?\",\n",
        "    ]\n",
        ")\n",
        "print(output.generations)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f18f5717",
      "metadata": {},
      "source": [
        "### 使用附加参数调用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b801c20d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "December is a cold month in Kansas City, with temperatures of \n"
          ]
        }
      ],
      "source": [
        "# Setting additional parameters: temperature, max_tokens, top_p\n",
        "llm = Fireworks(\n",
        "    model=\"accounts/fireworks/models/llama-v3p1-8b-instruct\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=15,\n",
        "    top_p=1.0,\n",
        ")\n",
        "print(llm.invoke(\"What's the weather like in Kansas City in December?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "137662a6",
      "metadata": {},
      "source": [
        "## 链接"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79efa62d",
      "metadata": {},
      "source": [
        "您可以使用 LangChain Expression Language (LCEL) 来创建包含非聊天模型的简单链。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd2c6bc1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " What do you call a bear with no teeth? A gummy bear!\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_fireworks import Fireworks\n",
        "\n",
        "llm = Fireworks(\n",
        "    model=\"accounts/fireworks/models/llama-v3p1-8b-instruct\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=15,\n",
        "    top_p=1.0,\n",
        ")\n",
        "prompt = PromptTemplate.from_template(\"Tell me a joke about {topic}?\")\n",
        "chain = prompt | llm\n",
        "\n",
        "print(chain.invoke({\"topic\": \"bears\"}))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0a29826",
      "metadata": {},
      "source": [
        "## 流式输出\n\n如果您愿意，可以进行流式输出。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f644ff28",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Why do bears hate shoes so much? They like to run around in their"
          ]
        }
      ],
      "source": [
        "for token in chain.stream({\"topic\": \"bears\"}):\n",
        "    print(token, end=\"\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "692c5e76",
      "metadata": {},
      "source": [
        "## API 参考\n\n如需 `Fireworks` LLM 功能和配置的详细文档，请访问 API 参考：https://python.langchain.com/api_reference/fireworks/llms/langchain_fireworks.llms.Fireworks.html#langchain_fireworks.llms.Fireworks"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}