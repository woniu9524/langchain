{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "70996d8a",
      "metadata": {},
      "source": [
        "# IBM watsonx.ai\n\n>[WatsonxLLM](https://ibm.github.io/watsonx-ai-python-sdk/fm_extensions.html#langchain) 是 IBM [watsonx.ai](https://www.ibm.com/products/watsonx-ai) 基础模型的封装器。\n\n此示例展示了如何使用 `LangChain` 与 `watsonx.ai` 模型进行通信。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b8d9390",
      "metadata": {},
      "source": [
        "## 概述\n\n### 集成详情\n| 类 | 包 | 本地 | 可序列化 | [JS 支持](https://js.langchain.com/docs/integrations/llms/ibm/) | 包下载量 | 最新包 |\n| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\n| [WatsonxLLM](https://python.langchain.com/api_reference/ibm/llms/langchain_ibm.llms.WatsonxLLM.html) | [langchain-ibm](https://python.langchain.com/api_reference/ibm/index.html) | ❌ | ❌ | ✅ | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-ibm?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-ibm?style=flat-square&label=%20) |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea35b2b7",
      "metadata": {},
      "source": [
        "## 设置\n\n要访问 IBM watsonx.ai 模型，您需要创建 IBM watsonx.ai 帐户、获取 API 密钥，并安装 `langchain-ibm` 集成软件包。\n\n### 凭证\n\n下面的单元格定义了使用 watsonx Foundation Model 推理所需的凭证。\n\n**操作：** 提供 IBM Cloud 用户 API 密钥。有关详细信息，请参阅\n[管理用户 API 密钥](https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "11d572a1",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "watsonx_api_key = getpass()\n",
        "os.environ[\"WATSONX_APIKEY\"] = watsonx_api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c59782a7",
      "metadata": {},
      "source": [
        "此外，您还可以将其他 Secret 作为环境变量传递。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f98c573c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"WATSONX_URL\"] = \"your service instance url\"\n",
        "os.environ[\"WATSONX_TOKEN\"] = \"your token for accessing the CPD cluster\"\n",
        "os.environ[\"WATSONX_PASSWORD\"] = \"your password for accessing the CPD cluster\"\n",
        "os.environ[\"WATSONX_USERNAME\"] = \"your username for accessing the CPD cluster\"\n",
        "os.environ[\"WATSONX_INSTANCE_ID\"] = \"your instance_id for accessing the CPD cluster\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f918d229",
      "metadata": {},
      "source": [
        "### 安装\n\nLangChain IBM 集成位于 `langchain-ibm` 包中："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f925c9aa",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -qU langchain-ibm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e36acbef",
      "metadata": {},
      "source": [
        "## 实例化\n\n您可能需要为不同的模型或任务调整模型 `parameters`。有关详细信息，请参阅 [文档](https://ibm.github.io/watsonx-ai-python-sdk/fm_model.html#metanames.GenTextParamsMetaNames)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "407cd500",
      "metadata": {},
      "outputs": [],
      "source": [
        "parameters = {\n",
        "    \"decoding_method\": \"sample\",\n",
        "    \"max_new_tokens\": 100,\n",
        "    \"min_new_tokens\": 1,\n",
        "    \"temperature\": 0.5,\n",
        "    \"top_k\": 50,\n",
        "    \"top_p\": 1,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b586538",
      "metadata": {},
      "source": [
        "使用先前设置的参数初始化 `WatsonxLLM` 类。\n\n\n**注意**:\n\n- 要为 API 调用提供上下文，必须添加 `project_id` 或 `space_id`。更多信息请参阅[文档](https://www.ibm.com/docs/en/watsonx-as-a-service?topic=projects)。\n- 根据您预配的服务实例的区域，使用此处描述的其中一个 URL ([documentation](https://ibm.github.io/watsonx-ai-python-sdk/setup_cloud.html#authentication))。\n\n在此示例中，我们将使用 `project_id` 和 Dallas URL。\n\n\n您需要指定将用于推理的 `model_id`。所有可用模型均可在[文档](https://ibm.github.io/watsonx-ai-python-sdk/fm_model.html#TextModels)中找到。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "359898de",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_ibm import WatsonxLLM\n",
        "\n",
        "watsonx_llm = WatsonxLLM(\n",
        "    model_id=\"ibm/granite-13b-instruct-v2\",\n",
        "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
        "    project_id=\"PASTE YOUR PROJECT_ID HERE\",\n",
        "    params=parameters,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2202f4e0",
      "metadata": {},
      "source": [
        "或者，您也可以使用 Cloud Pak for Data 凭据。有关详细信息，请参阅[文档](https://ibm.github.io/watsonx-ai-python-sdk/setup_cpd.html)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "243ecccb",
      "metadata": {},
      "outputs": [],
      "source": [
        "watsonx_llm = WatsonxLLM(\n",
        "    model_id=\"ibm/granite-13b-instruct-v2\",\n",
        "    url=\"PASTE YOUR URL HERE\",\n",
        "    username=\"PASTE YOUR USERNAME HERE\",\n",
        "    password=\"PASTE YOUR PASSWORD HERE\",\n",
        "    instance_id=\"openshift\",\n",
        "    version=\"4.8\",\n",
        "    project_id=\"PASTE YOUR PROJECT_ID HERE\",\n",
        "    params=parameters,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96ed13d4",
      "metadata": {},
      "source": [
        "除了 `model_id`，你也可以传入先前微调模型的 `deployment_id`。模型微调的完整流程请参阅 [Working with TuneExperiment and PromptTuner](https://ibm.github.io/watsonx-ai-python-sdk/pt_tune_experiment_run.html)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08e66c88",
      "metadata": {},
      "outputs": [],
      "source": [
        "watsonx_llm = WatsonxLLM(\n",
        "    deployment_id=\"PASTE YOUR DEPLOYMENT_ID HERE\",\n",
        "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
        "    project_id=\"PASTE YOUR PROJECT_ID HERE\",\n",
        "    params=parameters,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4a1e0f1",
      "metadata": {},
      "source": [
        "对于某些需求，可以选择将 IBM 的 [`APIClient`](https://ibm.github.io/watsonx-ai-python-sdk/base.html#apiclient) 对象传递到 `WatsonxLLM` 类中。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b28afc1",
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai import APIClient\n",
        "\n",
        "api_client = APIClient(...)\n",
        "\n",
        "watsonx_llm = WatsonxLLM(\n",
        "    model_id=\"ibm/granite-13b-instruct-v2\",\n",
        "    watsonx_client=api_client,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c4a632b",
      "metadata": {},
      "source": [
        "你也可以将 IBM 的 [`ModelInference`](https://ibm.github.io/watsonx-ai-python-sdk/fm_model_inference.html) 对象传递给 `WatsonxLLM` 类。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5335b148",
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai.foundation_models import ModelInference\n",
        "\n",
        "model = ModelInference(...)\n",
        "\n",
        "watsonx_llm = WatsonxLLM(watsonx_model=model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f571001d",
      "metadata": {},
      "source": [
        "## 调用方式\n要获取补全结果，您可以使用字符串提示直接调用模型。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "beea2b5b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Man's best friend is his dog. Dogs are man's best friend because they are always there for you, they never judge you, and they love you unconditionally. Dogs are also great companions and can help reduce stress levels. \""
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calling a single prompt\n",
        "\n",
        "watsonx_llm.invoke(\"Who is man's best friend?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8ab1a25a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LLMResult(generations=[[Generation(text='The fastest dog in the world is the greyhound. Greyhounds can run up to 45 mph, which is about the same speed as a Usain Bolt.', generation_info={'finish_reason': 'eos_token'})], [Generation(text='The Labrador Retriever is a breed of retriever that was bred for hunting. They are a very smart breed and are very easy to train. They are also very loyal and will make great companions. ', generation_info={'finish_reason': 'eos_token'})]], llm_output={'token_usage': {'generated_token_count': 82, 'input_token_count': 13}, 'model_id': 'ibm/granite-13b-instruct-v2', 'deployment_id': None}, run=[RunInfo(run_id=UUID('750b8a0f-8846-456d-93d0-e039e95b1276')), RunInfo(run_id=UUID('aa4c2a1c-5b08-4fcf-87aa-50228de46db5'))], type='LLMResult')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calling multiple prompts\n",
        "\n",
        "watsonx_llm.generate(\n",
        "    [\n",
        "        \"The fastest dog in the world?\",\n",
        "        \"Describe your chosen dog breed\",\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2c9da33",
      "metadata": {},
      "source": [
        "## 流式传输模型输出\n\n您可以流式传输模型输出。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3f63166a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "My favorite breed of dog is a Labrador Retriever. They are my favorite breed because they are my favorite color, yellow. They are also very smart and easy to train. "
          ]
        }
      ],
      "source": [
        "for chunk in watsonx_llm.stream(\n",
        "    \"Describe your favorite breed of dog and why it is your favorite.\"\n",
        "):\n",
        "    print(chunk, end=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fc88fdd",
      "metadata": {},
      "source": [
        "## 链式调用\n创建 `PromptTemplate` 对象，它们将负责生成随机问题。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ad63fa27",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "template = \"Generate a random question about {topic}: Question: \"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "677699db",
      "metadata": {},
      "source": [
        "提供一个主题并运行链。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "868af75c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'What is the origin of the name \"Pomeranian\"?'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm_chain = prompt | watsonx_llm\n",
        "\n",
        "topic = \"dog\"\n",
        "\n",
        "llm_chain.invoke(topic)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59480270",
      "metadata": {},
      "source": [
        "## API 参考\n\n如需了解 `WatsonxLLM` 所有功能和配置的详细文档，请访问 [API 参考](https://python.langchain.com/api_reference/ibm/llms/langchain_ibm.llms.WatsonxLLM.html)。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langchain_ibm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}