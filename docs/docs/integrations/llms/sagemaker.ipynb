{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SageMakerEndpoint\n\n[Amazon SageMaker](https://aws.amazon.com/sagemaker/) 是一个系统，可使用完全托管的基础设施、工具和工作流为任何用例构建、训练和部署机器学习 (ML) 模型。\n\n本笔记本将介绍如何使用托管在 `SageMaker endpoint` 上的 LLM。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "!pip3 install langchain boto3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 设置"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "你需要为 `SagemakerEndpoint` 调用设置以下必需参数：\n- `endpoint_name`：已部署的 Sagemaker 模型端点的名称。\n    在 AWS 区域内必须是唯一的。\n- `credentials_profile_name`：`~/.aws/credentials` 或 `~/.aws/config` 文件中配置文件的名称，\n    其中指定了访问密钥或角色信息。\n    如果未指定，将使用默认凭证配置文件，或者如果在 EC2 实例上，\n    将使用来自 IMDS 的凭证。\n    参见：https://boto3.amazonaws.com/v1/documentation/api/latest/guide/credentials.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 示例"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "from langchain_core.documents import Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "example_doc_1 = \"\"\"\n",
        "Peter and Elizabeth took a taxi to attend the night party in the city. While in the party, Elizabeth collapsed and was rushed to the hospital.\n",
        "Since she was diagnosed with a brain injury, the doctor told Peter to stay besides her until she gets well.\n",
        "Therefore, Peter stayed with her at the hospital for 3 days without leaving.\n",
        "\"\"\"\n",
        "\n",
        "docs = [\n",
        "    Document(\n",
        "        page_content=example_doc_1,\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 使用外部 boto3 会话进行初始化的示例\n\n### 跨账户场景"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from typing import Dict\n",
        "\n",
        "import boto3\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain_aws.llms import SagemakerEndpoint\n",
        "from langchain_aws.llms.sagemaker_endpoint import LLMContentHandler\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "query = \"\"\"How long was Elizabeth hospitalized?\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "Answer:\"\"\"\n",
        "PROMPT = PromptTemplate(\n",
        "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n",
        "roleARN = \"arn:aws:iam::123456789:role/cross-account-role\"\n",
        "sts_client = boto3.client(\"sts\")\n",
        "response = sts_client.assume_role(\n",
        "    RoleArn=roleARN, RoleSessionName=\"CrossAccountSession\"\n",
        ")\n",
        "\n",
        "client = boto3.client(\n",
        "    \"sagemaker-runtime\",\n",
        "    region_name=\"us-west-2\",\n",
        "    aws_access_key_id=response[\"Credentials\"][\"AccessKeyId\"],\n",
        "    aws_secret_access_key=response[\"Credentials\"][\"SecretAccessKey\"],\n",
        "    aws_session_token=response[\"Credentials\"][\"SessionToken\"],\n",
        ")\n",
        "\n",
        "\n",
        "class ContentHandler(LLMContentHandler):\n",
        "    content_type = \"application/json\"\n",
        "    accepts = \"application/json\"\n",
        "\n",
        "    def transform_input(self, prompt: str, model_kwargs: Dict) -> bytes:\n",
        "        input_str = json.dumps({\"inputs\": prompt, \"parameters\": model_kwargs})\n",
        "        return input_str.encode(\"utf-8\")\n",
        "\n",
        "    def transform_output(self, output: bytes) -> str:\n",
        "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
        "        return response_json[0][\"generated_text\"]\n",
        "\n",
        "\n",
        "content_handler = ContentHandler()\n",
        "\n",
        "chain = load_qa_chain(\n",
        "    llm=SagemakerEndpoint(\n",
        "        endpoint_name=\"endpoint-name\",\n",
        "        client=client,\n",
        "        model_kwargs={\"temperature\": 1e-10},\n",
        "        content_handler=content_handler,\n",
        "    ),\n",
        "    prompt=PROMPT,\n",
        ")\n",
        "\n",
        "chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from typing import Dict\n",
        "\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain_aws.llms import SagemakerEndpoint\n",
        "from langchain_aws.llms.sagemaker_endpoint import LLMContentHandler\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "query = \"\"\"How long was Elizabeth hospitalized?\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "Answer:\"\"\"\n",
        "PROMPT = PromptTemplate(\n",
        "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n",
        "\n",
        "class ContentHandler(LLMContentHandler):\n",
        "    content_type = \"application/json\"\n",
        "    accepts = \"application/json\"\n",
        "\n",
        "    def transform_input(self, prompt: str, model_kwargs: Dict) -> bytes:\n",
        "        input_str = json.dumps({\"inputs\": prompt, \"parameters\": model_kwargs})\n",
        "        return input_str.encode(\"utf-8\")\n",
        "\n",
        "    def transform_output(self, output: bytes) -> str:\n",
        "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
        "        return response_json[0][\"generated_text\"]\n",
        "\n",
        "\n",
        "content_handler = ContentHandler()\n",
        "\n",
        "chain = load_qa_chain(\n",
        "    llm=SagemakerEndpoint(\n",
        "        endpoint_name=\"endpoint-name\",\n",
        "        credentials_profile_name=\"credentials-profile-name\",\n",
        "        region_name=\"us-west-2\",\n",
        "        model_kwargs={\"temperature\": 1e-10},\n",
        "        content_handler=content_handler,\n",
        "    ),\n",
        "    prompt=PROMPT,\n",
        ")\n",
        "\n",
        "chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}