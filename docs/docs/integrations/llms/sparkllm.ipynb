{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SparkLLM\n[SparkLLM](https://xinghuo.xfyun.cn/spark) 是科大讯飞自主研发的超大规模认知模型。\n它通过学习海量的文本、代码和图像，具备跨领域知识和语言理解能力。\n它可以理解并执行基于自然对话的任务。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 先决条件\n- 从 [iFlyTek SparkLLM API 控制台](https://console.xfyun.cn/services/bm3) 获取 SparkLLM 的 app_id、api_key 和 api_secret（有关更多信息，请参阅 [iFlyTek SparkLLM 简介](https://xinghuo.xfyun.cn/sparkapi)），然后设置环境变量 `IFLYTEK_SPARK_APP_ID`、`IFLYTEK_SPARK_API_KEY` 和 `IFLYTEK_SPARK_API_SECRET`，或者在创建 `ChatSparkLLM` 时传递参数，如上面的演示所示。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 使用 SparkLLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"IFLYTEK_SPARK_APP_ID\"] = \"app_id\"\n",
        "os.environ[\"IFLYTEK_SPARK_API_KEY\"] = \"api_key\"\n",
        "os.environ[\"IFLYTEK_SPARK_API_SECRET\"] = \"api_secret\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/liugddx/code/langchain/libs/core/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "My name is iFLYTEK Spark. How can I assist you today?\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.llms import SparkLLM\n",
        "\n",
        "# Load the model\n",
        "llm = SparkLLM()\n",
        "\n",
        "res = llm.invoke(\"What's your name?\")\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-18T13:04:29.305856Z",
          "start_time": "2024-02-18T13:04:28.085715Z"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LLMResult(generations=[[Generation(text='Hello! How can I assist you today?')]], llm_output=None, run=[RunInfo(run_id=UUID('d8cdcd41-a698-4cbf-a28d-e74f9cd2037b'))])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res = llm.generate(prompts=[\"hello!\"])\n",
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-18T13:05:44.640035Z",
          "start_time": "2024-02-18T13:05:43.244126Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello! How can I assist you today?\n"
          ]
        }
      ],
      "source": [
        "for res in llm.stream(\"foo:\"):\n",
        "    print(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}