{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# OCI 数据科学模型部署端点\n\n[OCI 数据科学](https://docs.oracle.com/en-us/iaas/data-science/using/home.htm) 是一个完全托管的无服务器平台，供数据科学团队在 Oracle Cloud Infrastructure 中构建、训练和管理机器学习模型。\n\n> 有关最新更新、示例和实验性功能，请参阅 [ADS LangChain 集成](https://accelerated-data-science.readthedocs.io/en/latest/user_guide/large_language_model/langchain_models.html)。\n\n本 notebook 将介绍如何使用托管在 [OCI 数据科学模型部署](https://docs.oracle.com/en-us/iaas/data-science/using/model-dep-about.htm) 上的 LLM。\n\n为了进行身份验证，我们将使用 [oracle-ads](https://accelerated-data-science.readthedocs.io/en/latest/user_guide/cli/authentication.html) 库自动加载调用端点所需的凭据。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install oracle-ads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 先决条件\n\n### 部署模型\n您可以使用 OCI Data Science 的 [AI Quick Actions](https://docs.oracle.com/en-us/iaas/data-science/using/ai-quick-actions.htm) 轻松部署、微调和评估基础模型。有关其他部署示例，请访问 [Oracle GitHub 示例仓库](https://github.com/oracle-samples/oci-data-science-ai-samples/blob/main/ai-quick-actions/llama3-with-smc.md)。\n\n### 策略\n请确保您拥有访问 OCI Data Science 模型部署端点所需的[策略](https://docs.oracle.com/en-us/iaas/data-science/using/model-dep-policies-auth.htm#model_dep_policies_auth__predict-endpoint)。\n\n## 设置\n\n部署模型后，您需要设置调用所需的以下参数：\n\n- **`endpoint`**: 来自已部署模型的模型 HTTP 端点，例如 `https://modeldeployment.<region>.oci.customer-oci.com/<md_ocid>/predict`。\n\n### 身份验证\n您可以通过 ads 或环境变量设置身份验证。当您在 OCI Data Science Notebook Session 中工作时，可以利用资源主体来访问其他 OCI 资源。请在此处查看[更多选项](https://accelerated-data-science.readthedocs.io/en/latest/user_guide/cli/authentication.html)。\n\n## 示例"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ads\n",
        "from langchain_community.llms import OCIModelDeploymentLLM\n",
        "\n",
        "# Set authentication through ads\n",
        "# Use resource principal are operating within a\n",
        "# OCI service that has resource principal based\n",
        "# authentication configured\n",
        "ads.set_auth(\"resource_principal\")\n",
        "\n",
        "# Create an instance of OCI Model Deployment Endpoint\n",
        "# Replace the endpoint uri and model name with your own\n",
        "# Using generic class as entry point, you will be able\n",
        "# to pass model parameters through model_kwargs during\n",
        "# instantiation.\n",
        "llm = OCIModelDeploymentLLM(\n",
        "    endpoint=\"https://modeldeployment.<region>.oci.customer-oci.com/<md_ocid>/predict\",\n",
        "    model=\"odsc-llm\",\n",
        ")\n",
        "\n",
        "# Run the LLM\n",
        "llm.invoke(\"Who is the first president of United States?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ads\n",
        "from langchain_community.llms import OCIModelDeploymentVLLM\n",
        "\n",
        "# Set authentication through ads\n",
        "# Use resource principal are operating within a\n",
        "# OCI service that has resource principal based\n",
        "# authentication configured\n",
        "ads.set_auth(\"resource_principal\")\n",
        "\n",
        "# Create an instance of OCI Model Deployment Endpoint\n",
        "# Replace the endpoint uri and model name with your own\n",
        "# Using framework specific class as entry point, you will\n",
        "# be able to pass model parameters in constructor.\n",
        "llm = OCIModelDeploymentVLLM(\n",
        "    endpoint=\"https://modeldeployment.<region>.oci.customer-oci.com/<md_ocid>/predict\",\n",
        ")\n",
        "\n",
        "# Run the LLM\n",
        "llm.invoke(\"Who is the first president of United States?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from langchain_community.llms import OCIModelDeploymentTGI\n",
        "\n",
        "# Set authentication through environment variables\n",
        "# Use API Key setup when you are working from a local\n",
        "# workstation or on platform which does not support\n",
        "# resource principals.\n",
        "os.environ[\"OCI_IAM_TYPE\"] = \"api_key\"\n",
        "os.environ[\"OCI_CONFIG_PROFILE\"] = \"default\"\n",
        "os.environ[\"OCI_CONFIG_LOCATION\"] = \"~/.oci\"\n",
        "\n",
        "# Set endpoint through environment variables\n",
        "# Replace the endpoint uri with your own\n",
        "os.environ[\"OCI_LLM_ENDPOINT\"] = (\n",
        "    \"https://modeldeployment.<region>.oci.customer-oci.com/<md_ocid>/predict\"\n",
        ")\n",
        "\n",
        "# Create an instance of OCI Model Deployment Endpoint\n",
        "# Using framework specific class as entry point, you will\n",
        "# be able to pass model parameters in constructor.\n",
        "llm = OCIModelDeploymentTGI()\n",
        "\n",
        "# Run the LLM\n",
        "llm.invoke(\"Who is the first president of United States?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 异步调用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "await llm.ainvoke(\"Tell me a joke.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 流式通话"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for chunk in llm.stream(\"Tell me a joke.\"):\n",
        "    print(chunk, end=\"\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## API 参考\n\n有关所有功能和配置的详细信息，请参阅每个类的 API 参考文档：\n\n* [OCIModelDeploymentLLM](https://python.langchain.com/api_reference/community/llms/langchain_community.llms.oci_data_science_model_deployment_endpoint.OCIModelDeploymentLLM.html)\n* [OCIModelDeploymentVLLM](https://python.langchain.com/api_reference/community/llms/langchain_community.llms.oci_data_science_model_deployment_endpoint.OCIModelDeploymentVLLM.html)\n* [OCIModelDeploymentTGI](https://python.langchain.com/api_reference/community/llms/langchain_community.llms.oci_data_science_model_deployment_endpoint.OCIModelDeploymentTGI.html)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langchain",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}