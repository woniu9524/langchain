{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a9ab2a39-7c2d-4119-9dc7-8035fdfba3cb",
      "metadata": {},
      "source": [
        "# LangSmith 聊天数据集\n\n本笔记本演示了一个简单的方法来加载 LangSmith 聊天数据集并在此数据上微调模型。\n该过程很简单，包含 3 个步骤。\n\n1. 创建聊天数据集。\n2. 使用 `LangSmithDatasetChatLoader` 加载示例。\n3. 微调模型。\n\n然后，您可以在 LangChain 应用中使用微调后的模型。\n\n在深入研究之前，让我们先安装所需的依赖项。\n\n## 先决条件\n\n请确保您已安装 `langchain` >= 0.0.311，并已将环境配置为您的 LangSmith API 密钥。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef488003-514a-48b4-93f1-7de4417abf5d",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet  langchain langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9fba5c30-9e72-48aa-9535-80f2b3d18ead",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import uuid\n",
        "\n",
        "uid = uuid.uuid4().hex[:6]\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = \"YOUR API KEY\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8533ab63-d437-492a-aaec-ccca31167bf2",
      "metadata": {},
      "source": [
        "## 1. 选择一个数据集\n\n此笔记本直接在选择要微调的运行上进行微调。通常，您会从跟踪的运行中精心挑选。您可以在文档 [docs](https://docs.smith.langchain.com/evaluation/concepts#datasets) 中了解有关 LangSmith 数据集的更多信息。\n\n在本教程中，我们将在此处上传一个现有的数据集供您使用。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "462515e0-872a-446e-abbd-6166d73d7414",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langsmith.client import Client\n",
        "\n",
        "client = Client()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d384e4ac-5e8f-42a2-8bb5-7d3c9a8a540d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/langchain-ai/langchain/master/docs/docs/integrations/chat_loaders/example_data/langsmith_chat_dataset.json\"\n",
        "response = requests.get(url)\n",
        "response.raise_for_status()\n",
        "data = response.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b0d8ae47-2d3f-4b01-b15f-da58bd750fb4",
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_name = f\"Extraction Fine-tuning Dataset {uid}\"\n",
        "ds = client.create_dataset(dataset_name=dataset_name, data_type=\"chat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "87f085b7-71e1-4ff4-a622-e4e1248aa94a",
      "metadata": {},
      "outputs": [],
      "source": [
        "_ = client.create_examples(\n",
        "    inputs=[e[\"inputs\"] for e in data],\n",
        "    outputs=[e[\"outputs\"] for e in data],\n",
        "    dataset_id=ds.id,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f365a359-52f7-47ff-8c36-aadc1070b409",
      "metadata": {},
      "source": [
        "## 2. 准备数据\n现在我们可以创建一个 LangSmithRunChatLoader 实例，并使用其 lazy_load() 方法加载聊天会话。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "817bc077-c18a-473b-94a4-a7d810d583a8",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.chat_loaders.langsmith import LangSmithDatasetChatLoader\n",
        "\n",
        "loader = LangSmithDatasetChatLoader(dataset_name=dataset_name)\n",
        "\n",
        "chat_sessions = loader.lazy_load()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f21a3bbd-1ed4-481b-9640-206b8bf0d751",
      "metadata": {},
      "source": [
        "#### 加载会话后，将其转换为适合微调的格式。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9e5ac127-b094-4584-9159-5a6d3d7315c7",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.adapters.openai import convert_messages_for_finetuning\n",
        "\n",
        "training_data = convert_messages_for_finetuning(chat_sessions)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "188c4978-d85e-4984-a008-a50f6cd6bb84",
      "metadata": {},
      "source": [
        "## 3. 微调模型\n现在，使用 OpenAI 库启动微调过程。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "11d19e28-be49-4801-8065-1a58d13cd192",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Status=[running]... 429.55s. 46.34s\r"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import time\n",
        "from io import BytesIO\n",
        "\n",
        "import openai\n",
        "\n",
        "my_file = BytesIO()\n",
        "for dialog in training_data:\n",
        "    my_file.write((json.dumps({\"messages\": dialog}) + \"\\n\").encode(\"utf-8\"))\n",
        "\n",
        "my_file.seek(0)\n",
        "training_file = openai.files.create(file=my_file, purpose=\"fine-tune\")\n",
        "\n",
        "job = openai.fine_tuning.jobs.create(\n",
        "    training_file=training_file.id,\n",
        "    model=\"gpt-3.5-turbo\",\n",
        ")\n",
        "\n",
        "# Wait for the fine-tuning to complete (this may take some time)\n",
        "status = openai.fine_tuning.jobs.retrieve(job.id).status\n",
        "start_time = time.time()\n",
        "while status != \"succeeded\":\n",
        "    print(f\"Status=[{status}]... {time.time() - start_time:.2f}s\", end=\"\\r\", flush=True)\n",
        "    time.sleep(5)\n",
        "    status = openai.fine_tuning.jobs.retrieve(job.id).status\n",
        "\n",
        "# Now your model is fine-tuned!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54c4cead-500d-41dd-8333-2defde634396",
      "metadata": {},
      "source": [
        "## 4. 在 LangChain 中使用\n\n微调完成后，将生成的模型 ID 与 LangChain 应用中的 ChatOpenAI 模型类一起使用。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3f472ca4-fa9b-485d-bd37-8ce3c59c44db",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the fine-tuned model ID\n",
        "job = openai.fine_tuning.jobs.retrieve(job.id)\n",
        "model_id = job.fine_tuned_model\n",
        "\n",
        "# Use the fine-tuned model in LangChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(\n",
        "    model=model_id,\n",
        "    temperature=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7d3b5845-6385-42d1-9f7d-5ea798dc2cd9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='[{\"s\": \"There were three ravens\", \"object\": \"tree\", \"relation\": \"sat on\"}, {\"s\": \"three ravens\", \"object\": \"a tree\", \"relation\": \"sat on\"}]')"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.invoke(\"There were three ravens sat on a tree.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b8c2c79-ce27-4f37-b1b2-5977db8c4e84",
      "metadata": {},
      "source": [
        "您现在已经成功地使用来自 LangSmith LLM 运行的数据微调了一个模型！"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}