{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "683953b3",
      "metadata": {},
      "source": [
        "# Faiss (Async)\n\n>[Facebook AI Similarity Search (Faiss)](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/) 是一个用于高效相似性搜索和密集向量聚类的库。它包含在任何大小的向量集中进行搜索的算法，直至那些可能不适合放入 RAM 的向量。此外，它还包括用于评估和参数调优的配套代码。\n>\n>请参阅 [The FAISS Library](https://arxiv.org/pdf/2401.08281) 论文。\n\n[Faiss 文档](https://faiss.ai/)。\n\n您需要安装 `langchain-community` (`pip install -qU langchain-community`) 才能使用此集成\n\n本 Notebook 展示了如何使用与 `FAISS` 向量数据库相关的功能，并利用 `asyncio`。\nLangChain 已实现同步和异步向量存储函数。\n\n请通过[此处](/docs/integrations/vectorstores/faiss)查看`同步`版本。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "497fcd89-e832-46a7-a74a-c71199666206",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet  faiss-gpu # For CUDA 7.5+ Supported GPU's.\n",
        "# OR\n",
        "%pip install --upgrade --quiet  faiss-cpu # For CPU Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38237514-b3fa-44a4-9cff-30cd6bf50073",
      "metadata": {},
      "source": [
        "我们要使用 OpenAIEmbeddings，所以我们必须获取 OpenAI API 密钥。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "971a172a-2d87-4eec-be92-87aa174fec30",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
        "\n",
        "# Uncomment the following line if you need to initialize FAISS with no AVX2 optimization\n",
        "# os.environ['FAISS_NO_AVX2'] = '1'\n",
        "\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "\n",
        "loader = TextLoader(\"../../../extras/modules/state_of_the_union.txt\")\n",
        "documents = loader.load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "db = await FAISS.afrom_documents(docs, embeddings)\n",
        "\n",
        "query = \"What did the president say about Ketanji Brown Jackson\"\n",
        "docs = await db.asimilarity_search(query)\n",
        "\n",
        "print(docs[0].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f13473b5",
      "metadata": {},
      "source": [
        "## 相似度搜索及评分\n\n有些 FAISS 特有的方法。其中一个就是 `similarity_search_with_score`，它允许你不仅返回文档，还能返回查询与这些文档的距离评分。返回的距离评分是 L2 距离。因此，评分越低越好。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30bf7c85-a273-45dc-ae9e-f138e330b42e",
      "metadata": {},
      "outputs": [],
      "source": [
        "docs_and_scores = await db.asimilarity_search_with_score(query)\n",
        "\n",
        "docs_and_scores[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f34420cf",
      "metadata": {},
      "source": [
        "也可以使用 `similarity_search_by_vector` 对给定嵌入向量的文档进行搜索，该方法接受一个嵌入向量作为参数，而不是字符串。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b558ebb7",
      "metadata": {},
      "outputs": [],
      "source": [
        "embedding_vector = await embeddings.aembed_query(query)\n",
        "docs_and_scores = await db.asimilarity_search_by_vector(embedding_vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31bda7fd",
      "metadata": {},
      "source": [
        "## 保存和加载\n你也可以保存和加载 FAISS 索引。这样做的好处是你不需要每次使用它时都重新创建它。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88e11f08-1ac8-45aa-8bc0-56439ef87256",
      "metadata": {},
      "outputs": [],
      "source": [
        "db.save_local(\"faiss_index\")\n",
        "\n",
        "new_db = FAISS.load_local(\"faiss_index\", embeddings, asynchronous=True)\n",
        "\n",
        "docs = await new_db.asimilarity_search(query)\n",
        "\n",
        "docs[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30c8f57b",
      "metadata": {},
      "source": [
        "# 序列化和反序列化为字节\n\n您可以通过以下函数来 pickle FAISS 索引。如果您使用的是 90MB 的 embeddings 模型（如 sentence-transformers/all-MiniLM-L6-v2 或其他任何模型），则生成的 pickle 文件大小将超过 90MB。模型的大小也包含在总体大小中。为了克服这个问题，请使用下面的函数。这些函数仅序列化 FAISS 索引，大小会小得多。如果您希望将索引存储在像 sql 这样的数据库中，这将非常有用。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e36e220b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "pkl = db.serialize_to_bytes()  # serializes the faiss index\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "db = FAISS.deserialize_from_bytes(\n",
        "    embeddings=embeddings, serialized=pkl, asynchronous=True\n",
        ")  # Load the index"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57da60d4",
      "metadata": {},
      "source": [
        "## 合并\n你也可以合并两个 FAISS vectorstores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "6dfd2b78",
      "metadata": {},
      "outputs": [],
      "source": [
        "db1 = await FAISS.afrom_texts([\"foo\"], embeddings)\n",
        "db2 = await FAISS.afrom_texts([\"bar\"], embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "29960da7",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'8164a453-9643-4959-87f7-9ba79f9e8fb0': Document(page_content='foo')}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "db1.docstore._dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "83392605",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'4fbcf8a2-e80f-4f65-9308-2f4cb27cb6e7': Document(page_content='bar')}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "db2.docstore._dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "a3fcc1c7",
      "metadata": {},
      "outputs": [],
      "source": [
        "db1.merge_from(db2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "41c51f89",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'8164a453-9643-4959-87f7-9ba79f9e8fb0': Document(page_content='foo'),\n",
              " '4fbcf8a2-e80f-4f65-9308-2f4cb27cb6e7': Document(page_content='bar')}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "db1.docstore._dict"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4294b96",
      "metadata": {},
      "source": [
        "## 带过滤的相似性搜索\nFAISS 向量库也支持过滤，由于 FAISS 本身不支持过滤，所以需要手动实现。这可以通过首先获取比 `k` 更多的结果，然后再进行过滤来实现。你可以根据元数据来过滤文档。调用任何搜索方法时，你还可以设置 `fetch_k` 参数来指定在过滤之前想获取多少个文档。这里有一个简单的例子："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6740107a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Content: foo, Metadata: {'page': 1}, Score: 5.159960813797904e-15\n",
            "Content: foo, Metadata: {'page': 2}, Score: 5.159960813797904e-15\n",
            "Content: foo, Metadata: {'page': 3}, Score: 5.159960813797904e-15\n",
            "Content: foo, Metadata: {'page': 4}, Score: 5.159960813797904e-15\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "list_of_documents = [\n",
        "    Document(page_content=\"foo\", metadata=dict(page=1)),\n",
        "    Document(page_content=\"bar\", metadata=dict(page=1)),\n",
        "    Document(page_content=\"foo\", metadata=dict(page=2)),\n",
        "    Document(page_content=\"barbar\", metadata=dict(page=2)),\n",
        "    Document(page_content=\"foo\", metadata=dict(page=3)),\n",
        "    Document(page_content=\"bar burr\", metadata=dict(page=3)),\n",
        "    Document(page_content=\"foo\", metadata=dict(page=4)),\n",
        "    Document(page_content=\"bar bruh\", metadata=dict(page=4)),\n",
        "]\n",
        "db = FAISS.from_documents(list_of_documents, embeddings)\n",
        "results_with_scores = db.similarity_search_with_score(\"foo\")\n",
        "for doc, score in results_with_scores:\n",
        "    print(f\"Content: {doc.page_content}, Metadata: {doc.metadata}, Score: {score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d33c126",
      "metadata": {},
      "source": [
        "现在我们发出相同的查询调用，但将筛选条件设为仅 `page = 1`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "83159330",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Content: foo, Metadata: {'page': 1}, Score: 5.159960813797904e-15\n",
            "Content: bar, Metadata: {'page': 1}, Score: 0.3131446838378906\n"
          ]
        }
      ],
      "source": [
        "results_with_scores = await db.asimilarity_search_with_score(\"foo\", filter=dict(page=1))\n",
        "for doc, score in results_with_scores:\n",
        "    print(f\"Content: {doc.page_content}, Metadata: {doc.metadata}, Score: {score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0be136e0",
      "metadata": {},
      "source": [
        "同样的事情也可以用 `max_marginal_relevance_search` 来完成。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "432c6980",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Content: foo, Metadata: {'page': 1}\n",
            "Content: bar, Metadata: {'page': 1}\n"
          ]
        }
      ],
      "source": [
        "results = await db.amax_marginal_relevance_search(\"foo\", filter=dict(page=1))\n",
        "for doc in results:\n",
        "    print(f\"Content: {doc.page_content}, Metadata: {doc.metadata}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b4ecd86",
      "metadata": {},
      "source": [
        "以下是调用 `similarity_search` 时如何设置 `fetch_k` 参数的示例。通常情况下，你希望 `fetch_k` 参数 >> `k` 参数。这是因为 `fetch_k` 参数是指在过滤之前将要获取的文档数量。如果你将 `fetch_k` 设置为一个较低的数字，你可能无法获得足够的文档来进行过滤。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1fd60fd1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Content: foo, Metadata: {'page': 1}\n"
          ]
        }
      ],
      "source": [
        "results = await db.asimilarity_search(\"foo\", filter=dict(page=1), k=1, fetch_k=4)\n",
        "for doc in results:\n",
        "    print(f\"Content: {doc.page_content}, Metadata: {doc.metadata}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dead085",
      "metadata": {},
      "source": [
        "一些 [MongoDB 查询和投影运算符](https://www.mongodb.com/docs/manual/reference/operator/query/) 支持更高级的元数据过滤。当前支持的运算符列表如下：\n- `$eq` (等于)\n- `$neq` (不等于)\n- `$gt` (大于)\n- `$lt` (小于)\n- `$gte` (大于或等于)\n- `$lte` (小于或等于)\n- `$in` (在列表中)\n- `$nin` (不在列表中)\n- `$and` (所有条件必须匹配)\n- `$or` (任何条件必须匹配)\n- `$not` (条件否定)\n\n使用上面相同的相似性搜索并结合高级元数据过滤，可以执行如下操作："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af47c6f9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Content: foo, Metadata: {'page': 1}\n"
          ]
        }
      ],
      "source": [
        "results = await db.asimilarity_search(\n",
        "    \"foo\", filter={\"page\": {\"$eq\": 1}}, k=1, fetch_k=4\n",
        ")\n",
        "for doc in results:\n",
        "    print(f\"Content: {doc.page_content}, Metadata: {doc.metadata}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1becca53",
      "metadata": {},
      "source": [
        "## 删除\n\n你也可以删除 id。注意要删除的 id 应该是 docstore 中的 id。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1408b870",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "db.delete([db.index_to_docstore_id[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d13daf33",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Is now missing\n",
        "0 in db.index_to_docstore_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30ace43e",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}