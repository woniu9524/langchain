{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Aerospike\n\n[Aerospike Vector Search](https://aerospike.com/docs/vector) (AVS) 是 Aerospike 数据库的一个扩展，能够跨存储在 Aerospike 中的超大数据集执行搜索。这项新服务独立于 Aerospike 运行，并构建索引来执行这些搜索。\n\n本 Notebook 展示了 [LangChain Aerospike VectorStore 集成](https://github.com/aerospike/langchain-aerospike) 的功能。\n\n## 安装 AVS\n\n在使用本 Notebook 之前，我们需要有一个正在运行的 AVS 实例。请使用[提供的安装方法之一](https://aerospike.com/docs/vector/install)。\n\n完成后，请存储您的 AVS 实例的 IP 地址和端口，以便稍后在此演示中使用："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "AVS_HOST = \"<avs_ip>\"\n",
        "AVS_PORT = 5000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 安装依赖\n\n`sentence-transformers` 依赖较大，此步骤可能需要几分钟才能完成。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --quiet aerospike-vector-search==4.2.0 langchain-aerospike langchain-community sentence-transformers langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 下载名言数据集\n\n我们将下载一个包含约 100,000 条名言的数据集，并从中选取一部分用于语义搜索。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-05-07 21:06:30--  https://github.com/aerospike/aerospike-vector-search-examples/raw/7dfab0fccca0852a511c6803aba46578729694b5/quote-semantic-search/container-volumes/quote-search/data/quotes.csv.tgz\n",
            "Resolving github.com (github.com)... 140.82.116.3\n",
            "Connecting to github.com (github.com)|140.82.116.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://github.com/aerospike/aerospike-vector/raw/7dfab0fccca0852a511c6803aba46578729694b5/quote-semantic-search/container-volumes/quote-search/data/quotes.csv.tgz [following]\n",
            "--2025-05-07 21:06:30--  https://github.com/aerospike/aerospike-vector/raw/7dfab0fccca0852a511c6803aba46578729694b5/quote-semantic-search/container-volumes/quote-search/data/quotes.csv.tgz\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/aerospike/aerospike-vector/7dfab0fccca0852a511c6803aba46578729694b5/quote-semantic-search/container-volumes/quote-search/data/quotes.csv.tgz [following]\n",
            "--2025-05-07 21:06:30--  https://raw.githubusercontent.com/aerospike/aerospike-vector/7dfab0fccca0852a511c6803aba46578729694b5/quote-semantic-search/container-volumes/quote-search/data/quotes.csv.tgz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11597643 (11M) [application/octet-stream]\n",
            "Saving to: ‘quotes.csv.tgz’\n",
            "\n",
            "quotes.csv.tgz      100%[===================>]  11.06M  12.7MB/s    in 0.9s    \n",
            "\n",
            "2025-05-07 21:06:32 (12.7 MB/s) - ‘quotes.csv.tgz’ saved [11597643/11597643]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/aerospike/aerospike-vector-search-examples/raw/7dfab0fccca0852a511c6803aba46578729694b5/quote-semantic-search/container-volumes/quote-search/data/quotes.csv.tgz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 将引用加载到文档中\n\n我们将使用 `CSVLoader` 文档加载器加载我们的引用数据集。在这种情况下，`lazy_load` 返回一个迭代器，以便更有效地摄取我们的引用。在此示例中，我们仅加载 5,000 条引用。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import itertools\n",
        "import os\n",
        "import tarfile\n",
        "\n",
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "\n",
        "filename = \"./quotes.csv\"\n",
        "\n",
        "if not os.path.exists(filename) and os.path.exists(filename + \".tgz\"):\n",
        "    # Untar the file\n",
        "    with tarfile.open(filename + \".tgz\", \"r:gz\") as tar:\n",
        "        tar.extractall(path=os.path.dirname(filename))\n",
        "\n",
        "NUM_QUOTES = 5000\n",
        "documents = CSVLoader(filename, metadata_columns=[\"author\", \"category\"]).lazy_load()\n",
        "documents = list(\n",
        "    itertools.islice(documents, NUM_QUOTES)\n",
        ")  # Allows us to slice an iterator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='quote: I'm selfish, impatient and a little insecure. I make mistakes, I am out of control and at times hard to handle. But if you can't handle me at my worst, then you sure as hell don't deserve me at my best.' metadata={'source': './quotes.csv', 'row': 0, 'author': 'Marilyn Monroe', 'category': 'attributed-no-source, best, life, love, mistakes, out-of-control, truth, worst'}\n"
          ]
        }
      ],
      "source": [
        "print(documents[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 创建你的 Embedder\n\n在此步骤中，我们将使用 HuggingFaceEmbeddings 和 \"all-MiniLM-L6-v2\" 句子转换器模型来嵌入我们的文档，以便执行向量搜索。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/h5/lm2_c1xs3s32kwp11prnpftw0000gp/T/ipykernel_84638/3255399720.py:6: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embedder = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
            "/Users/dwelch/Desktop/everything/projects/langchain/myfork/langchain/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from aerospike_vector_search.types import VectorDistanceMetric\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "MODEL_DIM = 384\n",
        "MODEL_DISTANCE_CALC = VectorDistanceMetric.COSINE\n",
        "embedder = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 创建 Aerospike 索引并嵌入文档\n\n在我们添加文档之前，需要在 Aerospike 数据库中创建一个索引。在下面的示例中，我们使用了一些辅助代码，该代码会检查预期的索引是否已存在。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "quote-miniLM-L6-v2 does not exist. Creating index\n"
          ]
        }
      ],
      "source": [
        "from aerospike_vector_search import Client, HostPort\n",
        "from aerospike_vector_search.types import VectorDistanceMetric\n",
        "from langchain_aerospike.vectorstores import Aerospike\n",
        "\n",
        "# Here we are using the AVS host and port you configured earlier\n",
        "seed = HostPort(host=AVS_HOST, port=AVS_PORT)\n",
        "\n",
        "# The namespace of where to place our vectors. This should match the vector configured in your docstore.conf file.\n",
        "NAMESPACE = \"test\"\n",
        "\n",
        "# The name of our new index.\n",
        "INDEX_NAME = \"quote-miniLM-L6-v2\"\n",
        "\n",
        "# AVS needs to know which metadata key contains our vector when creating the index and inserting documents.\n",
        "VECTOR_KEY = \"vector\"\n",
        "\n",
        "client = Client(seeds=seed)\n",
        "index_exists = False\n",
        "\n",
        "# Check if the index already exists. If not, create it\n",
        "for index in client.index_list():\n",
        "    if index[\"id\"][\"namespace\"] == NAMESPACE and index[\"id\"][\"name\"] == INDEX_NAME:\n",
        "        index_exists = True\n",
        "        print(f\"{INDEX_NAME} already exists. Skipping creation\")\n",
        "        break\n",
        "\n",
        "if not index_exists:\n",
        "    print(f\"{INDEX_NAME} does not exist. Creating index\")\n",
        "    client.index_create(\n",
        "        namespace=NAMESPACE,\n",
        "        name=INDEX_NAME,\n",
        "        vector_field=VECTOR_KEY,\n",
        "        vector_distance_metric=MODEL_DISTANCE_CALC,\n",
        "        dimensions=MODEL_DIM,\n",
        "        index_labels={\n",
        "            \"model\": \"miniLM-L6-v2\",\n",
        "            \"date\": \"05/04/2024\",\n",
        "            \"dim\": str(MODEL_DIM),\n",
        "            \"distance\": \"cosine\",\n",
        "        },\n",
        "    )\n",
        "\n",
        "docstore = Aerospike.from_documents(\n",
        "    documents,\n",
        "    embedder,\n",
        "    client=client,\n",
        "    namespace=NAMESPACE,\n",
        "    vector_key=VECTOR_KEY,\n",
        "    index_name=INDEX_NAME,\n",
        "    distance_strategy=MODEL_DISTANCE_CALC,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 搜索文档\n现在我们已经嵌入了向量，就可以对引文进行向量搜索了。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "~~~~ Document 0 ~~~~\n",
            "auto-generated id: 4984b472-8a32-4552-b3eb-f03b31b68031\n",
            "author:  Carl Sagan, Cosmos\n",
            "quote: The Cosmos is all that is or was or ever will be. Our feeblest contemplations of the Cosmos stir us -- there is a tingling in the spine, a catch in the voice, a faint sensation, as if a distant memory, of falling from a height. We know we are approaching the greatest of mysteries.\n",
            "~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~ Document 1 ~~~~\n",
            "auto-generated id: 486c8d87-8dd7-450d-9008-d7549e680ffb\n",
            "author:  Renee Ahdieh, The Rose & the Dagger\n",
            "quote: From the stars, to the stars.\n",
            "~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~ Document 2 ~~~~\n",
            "auto-generated id: 4b43b309-ce51-498c-b225-5254383b5b4a\n",
            "author:  Elizabeth Gilbert\n",
            "quote: The love that moves the sun and the other stars.\n",
            "~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~ Document 3 ~~~~\n",
            "auto-generated id: af784a10-f498-4570-bf81-2ffdca35440e\n",
            "author:  Dante Alighieri, Paradiso\n",
            "quote: Love, that moves the sun and the other stars\n",
            "~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~ Document 4 ~~~~\n",
            "auto-generated id: b45d5d5e-d818-4206-ae6b-b1d166ea3d43\n",
            "author:  Thich Nhat Hanh, Teachings on Love\n",
            "quote: Through my love for you, I want to express my love for the whole cosmos, the whole of humanity, and all beings. By living with you, I want to learn to love everyone and all species. If I succeed in loving you, I will be able to love everyone and all species on Earth... This is the real message of love.\n",
            "~~~~~~~~~~~~~~~~~~~~\n",
            "\n"
          ]
        }
      ],
      "source": [
        "query = \"A quote about the beauty of the cosmos\"\n",
        "docs = docstore.similarity_search(\n",
        "    query, k=5, index_name=INDEX_NAME, metadata_keys=[\"_id\", \"author\"]\n",
        ")\n",
        "\n",
        "\n",
        "def print_documents(docs):\n",
        "    for i, doc in enumerate(docs):\n",
        "        print(\"~~~~ Document\", i, \"~~~~\")\n",
        "        print(\"auto-generated id:\", doc.metadata[\"_id\"])\n",
        "        print(\"author: \", doc.metadata[\"author\"])\n",
        "        print(doc.page_content)\n",
        "        print(\"~~~~~~~~~~~~~~~~~~~~\\n\")\n",
        "\n",
        "\n",
        "print_documents(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 嵌入附加引用作为文本\n\n我们可以使用 `add_texts` 来嵌入附加引用。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New IDs\n",
            "['adf8064e-9c0e-46e2-b193-169c36432f4c', 'cf65b5ed-a0f4-491a-86ad-dcacc23c2815', '2ef52efd-d9b7-4077-bc14-defdf0b7dd2f']\n"
          ]
        }
      ],
      "source": [
        "docstore = Aerospike(\n",
        "    client,\n",
        "    embedder,\n",
        "    NAMESPACE,\n",
        "    index_name=INDEX_NAME,\n",
        "    vector_key=VECTOR_KEY,\n",
        "    distance_strategy=MODEL_DISTANCE_CALC,\n",
        ")\n",
        "\n",
        "ids = docstore.add_texts(\n",
        "    [\n",
        "        \"quote: Rebellions are built on hope.\",\n",
        "        \"quote: Logic is the beginning of wisdom, not the end.\",\n",
        "        \"quote: If wishes were fishes, we’d all cast nets.\",\n",
        "    ],\n",
        "    metadatas=[\n",
        "        {\"author\": \"Jyn Erso, Rogue One\"},\n",
        "        {\"author\": \"Spock, Star Trek\"},\n",
        "        {\"author\": \"Frank Herbert, Dune\"},\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(\"New IDs\")\n",
        "print(ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 使用最大边际相关性搜索文档\n\n我们可以使用最大边际相关性搜索来查找与我们的查询相似但彼此不相似的向量。在此示例中，我们使用 `as_retriever` 创建一个检索器对象，但这也可以直接调用 `docstore.max_marginal_relevance_search` 来轻松完成。`lambda_mult` 搜索参数决定了我们查询响应的多样性。0 对应最大多样性，1 对应最小多样性。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "~~~~ Document 0 ~~~~\n",
            "auto-generated id: 91e77b39-a528-40c6-a58a-486ae85f991a\n",
            "author:  John Grogan, Marley and Me: Life and Love With the World's Worst Dog\n",
            "quote: Such short little lives our pets have to spend with us, and they spend most of it waiting for us to come home each day. It is amazing how much love and laughter they bring into our lives and even how much closer we become with each other because of them.\n",
            "~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~ Document 1 ~~~~\n",
            "auto-generated id: c585b4ec-92b5-4579-948c-0529373abc2a\n",
            "author:  John Grogan, Marley and Me: Life and Love With the World's Worst Dog\n",
            "quote: Dogs are great. Bad dogs, if you can really call them that, are perhaps the greatest of them all.\n",
            "~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~ Document 2 ~~~~\n",
            "auto-generated id: 5768b31c-fac4-4af7-84b4-fb11bbfcb590\n",
            "author:  Colleen Houck, Tiger's Curse\n",
            "quote: He then put both hands on the door on either side of my head and leaned in close, pinning me against it. I trembled like a downy rabbit caught in the clutches of a wolf. The wolf came closer. He bent his head and began nuzzling my cheek. The problem was…I wanted the wolf to devour me.\n",
            "~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~ Document 3 ~~~~\n",
            "auto-generated id: 94f1b9fb-ad57-4f65-b470-7f49dd6c274c\n",
            "author:  Ray Bradbury\n",
            "quote: Stuff your eyes with wonder,\" he said, \"live as if you'd drop dead in ten seconds. See the world. It's more fantastic than any dream made or paid for in factories. Ask no guarantees, ask for no security, there never was such an animal. And if there were, it would be related to the great sloth which hangs upside down in a tree all day every day, sleeping its life away. To hell with that,\" he said, \"shake the tree and knock the great sloth down on his ass.\n",
            "~~~~~~~~~~~~~~~~~~~~\n",
            "\n"
          ]
        }
      ],
      "source": [
        "query = \"A quote about our favorite four-legged pets\"\n",
        "retriever = docstore.as_retriever(\n",
        "    search_type=\"mmr\", search_kwargs={\"fetch_k\": 20, \"lambda_mult\": 0.7}\n",
        ")\n",
        "matched_docs = retriever.invoke(query)\n",
        "\n",
        "print_documents(matched_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 使用相关性阈值搜索文档\n\n另一个有用的功能是带有相关性阈值的相似性搜索。通常，我们只想要与我们的查询最相似的结果，同时也要在一定的邻近范围内。相关性为 1 表示最相似，相关性为 0 表示最不相似。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "~~~~ Document 0 ~~~~\n",
            "auto-generated id: 6d9e67a6-0427-41e6-9e24-050518120d74\n",
            "author:  Roy T. Bennett, The Light in the Heart\n",
            "quote: Never lose hope. Storms make people stronger and never last forever.\n",
            "~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~ Document 1 ~~~~\n",
            "auto-generated id: 7d426e59-7935-4bcf-a676-cbe8dd4860e7\n",
            "author:  Roy T. Bennett, The Light in the Heart\n",
            "quote: Difficulties and adversities viciously force all their might on us and cause us to fall apart, but they are necessary elements of individual growth and reveal our true potential. We have got to endure and overcome them, and move forward. Never lose hope. Storms make people stronger and never last forever.\n",
            "~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~ Document 2 ~~~~\n",
            "auto-generated id: 6ec05e48-d162-440d-8819-001d2f3712f9\n",
            "author:  Vincent van Gogh, The Letters of Vincent van Gogh\n",
            "quote: There is peace even in the storm\n",
            "~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "~~~~ Document 3 ~~~~\n",
            "auto-generated id: d3c3de59-4da4-4ae6-8f6d-83ed905dd320\n",
            "author:  Edwin Morgan, A Book of Lives\n",
            "quote: Valentine WeatherKiss me with rain on your eyelashes,come on, let us sway together,under the trees, and to hell with thunder.\n",
            "~~~~~~~~~~~~~~~~~~~~\n",
            "\n"
          ]
        }
      ],
      "source": [
        "query = \"A quote about stormy weather\"\n",
        "retriever = docstore.as_retriever(\n",
        "    search_type=\"similarity_score_threshold\",\n",
        "    search_kwargs={\n",
        "        \"score_threshold\": 0.4\n",
        "    },  # A greater value returns items with more relevance\n",
        ")\n",
        "matched_docs = retriever.invoke(query)\n",
        "\n",
        "print_documents(matched_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 清理\n\n我们需要确保关闭客户端以释放资源和清理线程。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "client.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 准备就绪，开始搜索！\n\n既然你已经了解了 Aerospike Vector Search 的 LangChain 集成，你就拥有了 Aerospike 数据库和 LangChain 生态系统的强大能力。祝你开发顺利！"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}