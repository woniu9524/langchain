{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "683953b3",
      "metadata": {},
      "source": [
        "# ApertureDB\n\n[ApertureDB](https://docs.aperturedata.io) 是一个数据库，可存储、索引和管理多模态数据，如文本、图像、视频、边界框和嵌入，及其关联的元数据。\n\n本笔记本将介绍如何使用 ApertureDB 的嵌入功能。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7393beb",
      "metadata": {},
      "source": [
        "## 安装 ApertureDB Python SDK\n\n这将安装用于编写 ApertureDB 客户端代码的 [Python SDK](https://docs.aperturedata.io/category/aperturedb-python-sdk)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a62cff8a-bcf7-4e33-bbbc-76999c2e3e20",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet aperturedb"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fe12f77",
      "metadata": {},
      "source": [
        "## 运行一个 ApertureDB 实例\n\n继续之前，您应该有一个[已启动并运行的 ApertureDB 实例](https://docs.aperturedata.io/HowToGuides/start/Setup)，并配置您的环境来使用它。\n有多种方法可以实现这一点，例如：\n\n```bash\ndocker run --publish 55555:55555 aperturedata/aperturedb-standalone\nadb config create local --active --no-interactive\n```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "667eabca",
      "metadata": {},
      "source": [
        "## 下载一些网页文档\n这里我们将对一个网页进行一次迷你抓取。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0798dfdb",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "# For loading documents from web\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "loader = WebBaseLoader(\"https://docs.aperturedata.io\")\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f077d11",
      "metadata": {},
      "source": [
        "## 选择 embeddings 模型\n\n我们想使用 OllamaEmbeddings，所以需要导入必要的模块。\n\nOllama 可以按照 [文档](https://hub.docker.com/r/ollama/ollama) 中的描述设置为一个 docker 容器，例如：\n```bash\n# 运行服务器\ndocker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama\n# 让服务器加载特定模型\ndocker exec ollama ollama run llama2\n```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8b6ed9cd-81b9-46e5-9c20-5aafca2844d0",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "from langchain_community.embeddings import OllamaEmbeddings\n",
        "\n",
        "embeddings = OllamaEmbeddings()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7b313e6",
      "metadata": {},
      "source": [
        "## 将文档拆分为小节\n\n我们想将单个文档拆分成多个小节。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3c4b7b31",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter()\n",
        "documents = text_splitter.split_documents(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46339d32",
      "metadata": {},
      "source": [
        "## 从文档和嵌入创建向量存储\n\n此代码将在 ApertureDB 实例中创建一个向量存储。\n在实例中，此向量存储表示为一个“[描述符集](https://docs.aperturedata.io/category/descriptorset-commands)”。\n默认情况下，描述符集命名为 `langchain`。以下代码将为每个文档生成嵌入，并将它们作为描述符存储在 ApertureDB 中。由于正在生成嵌入，这需要几秒钟的时间。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "dcf88bdf",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import ApertureDB\n",
        "\n",
        "vector_db = ApertureDB.from_documents(documents, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7672877b",
      "metadata": {},
      "source": [
        "## 选择一个大型语言模型\n\n同样，我们使用为本地处理而设置的 Ollama 服务器。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9a005e4b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.llms import Ollama\n",
        "\n",
        "llm = Ollama(model=\"llama2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd54f2ad",
      "metadata": {},
      "source": [
        "## 构建 RAG 链\n\n现在我们已经拥有了构建 RAG（检索增强生成）链所需的所有组件。此链执行以下操作：\n1. 为用户查询生成嵌入描述符\n2. 使用向量存储查找与用户查询相似的文本片段\n3. 使用提示模板将用户查询和上下文文档传递给 LLM\n4. 返回 LLM 的答案"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a8c513ab",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on the provided context, ApertureDB can store images. In fact, it is specifically designed to manage multimodal data such as images, videos, documents, embeddings, and associated metadata including annotations. So, ApertureDB has the capability to store and manage images.\n"
          ]
        }
      ],
      "source": [
        "# Create prompt\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
        "\n",
        "<context>\n",
        "{context}\n",
        "</context>\n",
        "\n",
        "Question: {input}\"\"\")\n",
        "\n",
        "\n",
        "# Create a chain that passes documents to an LLM\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "document_chain = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "\n",
        "# Treat the vectorstore as a document retriever\n",
        "retriever = vector_db.as_retriever()\n",
        "\n",
        "\n",
        "# Create a RAG chain that connects the retriever to the LLM\n",
        "from langchain.chains import create_retrieval_chain\n",
        "\n",
        "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bc6a882",
      "metadata": {},
      "source": [
        "## 运行 RAG 链\n\n最后，我们将一个问题传递给链，并得到答案。这将花费几秒钟的时间来运行，因为 LLM 会根据查询和上下文文档生成答案。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "020f29f1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on the provided context, ApertureDB can store images in several ways:\n",
            "\n",
            "1. Multimodal data management: ApertureDB offers a unified interface to manage multimodal data such as images, videos, documents, embeddings, and associated metadata including annotations. This means that images can be stored along with other types of data in a single database instance.\n",
            "2. Image storage: ApertureDB provides image storage capabilities through its integration with the public cloud providers or on-premise installations. This allows customers to host their own ApertureDB instances and store images on their preferred cloud provider or on-premise infrastructure.\n",
            "3. Vector database: ApertureDB also offers a vector database that enables efficient similarity search and classification of images based on their semantic meaning. This can be useful for applications where image search and classification are important, such as in computer vision or machine learning workflows.\n",
            "\n",
            "Overall, ApertureDB provides flexible and scalable storage options for images, allowing customers to choose the deployment model that best suits their needs.\n"
          ]
        }
      ],
      "source": [
        "user_query = \"How can ApertureDB store images?\"\n",
        "response = retrieval_chain.invoke({\"input\": user_query})\n",
        "print(response[\"answer\"])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}