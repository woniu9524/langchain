{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SAP HANA Cloud Vector Engine\n\n>[SAP HANA Cloud Vector Engine](https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-vector-engine-guide/sap-hana-cloud-sap-hana-database-vector-engine-guide) 是一个完全集成到 `SAP HANA Cloud` 数据库中的向量数据库。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 安装\n\n安装 `langchain-hana` 外部集成包以及本文档中使用的其他包。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "%pip install -qU langchain-hana"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Credentials\n\n请确保你的 SAP HANA 实例正在运行。从环境变量加载你的凭证并创建连接："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from hdbcli import dbapi\n",
        "\n",
        "load_dotenv()\n",
        "# Use connection settings from the environment\n",
        "connection = dbapi.connect(\n",
        "    address=os.environ.get(\"HANA_DB_ADDRESS\"),\n",
        "    port=os.environ.get(\"HANA_DB_PORT\"),\n",
        "    user=os.environ.get(\"HANA_DB_USER\"),\n",
        "    password=os.environ.get(\"HANA_DB_PASSWORD\"),\n",
        "    autocommit=True,\n",
        "    sslValidateCertificate=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "在[什么是 SAP HANA？](https://www.sap.com/products/data-cloud/hana/what-is-sap-hana.html) 中了解更多关于 SAP HANA 的信息。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 初始化\n要初始化 `HanaDB` 向量存储，你需要数据库连接和嵌入实例。SAP HANA Cloud Vector Engine 支持外部和内部嵌入。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- #### 使用外部嵌入\n\nimport EmbeddingTabs from \"@theme/EmbeddingTabs\";\n\n<EmbeddingTabs/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# | output: false\n",
        "# | echo: false\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- #### 使用内部嵌入"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "您也可以使用其原生 `VECTOR_EMBEDDING()` 函数直接在 SAP HANA 中计算 embeddings。要启用此功能，请使用您的内部模型 ID 创建一个 `HanaInternalEmbeddings` 实例，并将其传递给 `HanaDB`。请注意，`HanaInternalEmbeddings` 实例专门用于 `HanaDB`，不适用于其他向量存储实现。有关内部 embeddings 的更多信息，请参阅 [SAP HANA VECTOR_EMBEDDING Function](https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-vector-engine-guide/vector-embedding-function-vector)。\n\n> **注意：** 请确保在您的 SAP HANA Cloud 实例中启用了 NLP。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_hana import HanaInternalEmbeddings\n",
        "\n",
        "embeddings = HanaInternalEmbeddings(internal_embedding_model_id=\"SAP_NEB.20240715\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "在拥有连接和嵌入实例后，通过将它们与用于存储向量的表名一起传递给 `HanaDB` 来创建向量存储："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_hana import HanaDB\n",
        "\n",
        "db = HanaDB(\n",
        "    embedding=embeddings, connection=connection, table_name=\"STATE_OF_THE_UNION\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 示例"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "加载样本文档 \"state_of_the_union.txt\" 并从中创建块。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-09-09T08:02:25.452472Z",
          "start_time": "2023-09-09T08:02:25.441563Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of document chunks: 88\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_core.documents import Document\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "\n",
        "text_documents = TextLoader(\n",
        "    \"../../how_to/state_of_the_union.txt\", encoding=\"UTF-8\"\n",
        ").load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
        "text_chunks = text_splitter.split_documents(text_documents)\n",
        "print(f\"Number of document chunks: {len(text_chunks)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "将已加载的文档块添加到表中。在此示例中，我们删除表中可能存在的任何先前内容，以防之前运行过。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Delete already existing documents from the table\n",
        "db.delete(filter={})\n",
        "\n",
        "# add the loaded document chunks\n",
        "db.add_documents(text_chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "执行查询，从上一步添加的文档块中检索匹配度最高的两个文档块。\n默认情况下，搜索使用“余弦相似度”。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
            "\n",
            "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\n",
            "--------------------------------------------------------------------------------\n",
            "As I said last year, especially to our younger transgender Americans, I will always have your back as your President, so you can be yourself and reach your God-given potential. \n",
            "\n",
            "While it often appears that we never agree, that isn’t true. I signed 80 bipartisan bills into law last year. From preventing government shutdowns to protecting Asian-Americans from still-too-common hate crimes to reforming military justice.\n"
          ]
        }
      ],
      "source": [
        "query = \"What did the president say about Ketanji Brown Jackson\"\n",
        "docs = db.similarity_search(query, k=2)\n",
        "\n",
        "for doc in docs:\n",
        "    print(\"-\" * 80)\n",
        "    print(doc.page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "用“欧几里得距离”查询相同的内容。结果应该与“余弦相似度”相同。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
            "\n",
            "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\n",
            "--------------------------------------------------------------------------------\n",
            "As I said last year, especially to our younger transgender Americans, I will always have your back as your President, so you can be yourself and reach your God-given potential. \n",
            "\n",
            "While it often appears that we never agree, that isn’t true. I signed 80 bipartisan bills into law last year. From preventing government shutdowns to protecting Asian-Americans from still-too-common hate crimes to reforming military justice.\n"
          ]
        }
      ],
      "source": [
        "from langchain_hana.utils import DistanceStrategy\n",
        "\n",
        "db = HanaDB(\n",
        "    embedding=embeddings,\n",
        "    connection=connection,\n",
        "    distance_strategy=DistanceStrategy.EUCLIDEAN_DISTANCE,\n",
        "    table_name=\"STATE_OF_THE_UNION\",\n",
        ")\n",
        "\n",
        "query = \"What did the president say about Ketanji Brown Jackson\"\n",
        "docs = db.similarity_search(query, k=2)\n",
        "for doc in docs:\n",
        "    print(\"-\" * 80)\n",
        "    print(doc.page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "## 最大化边际相关性搜索 (MMR)\n\n`最大化边际相关性` 优化了与查询的相似性以及所选文档的多样性。最初将从数据库中检索 20 个 (fetch_k) 项目。然后 MMR 算法将找到最佳的 2 个 (k) 匹配项。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-09-09T08:05:23.276819Z",
          "start_time": "2023-09-09T08:05:21.972256Z"
        },
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
            "\n",
            "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\n",
            "--------------------------------------------------------------------------------\n",
            "Groups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland. \n",
            "\n",
            "In this struggle as President Zelenskyy said in his speech to the European Parliament “Light will win over darkness.” The Ukrainian Ambassador to the United States is here tonight. \n",
            "\n",
            "Let each of us here tonight in this Chamber send an unmistakable signal to Ukraine and to the world.\n"
          ]
        }
      ],
      "source": [
        "docs = db.max_marginal_relevance_search(query, k=2, fetch_k=20)\n",
        "for doc in docs:\n",
        "    print(\"-\" * 80)\n",
        "    print(doc.page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 创建 HNSW 向量索引\n\n向量索引可以显著加快向量的 top-k 最近邻查询。用户可以使用 `create_hnsw_index` 函数创建分层可导航小世界 (HNSW) 向量索引。\n\n有关在数据库级别创建索引的更多信息，请参阅 [官方文档](https://help.sap.com/docs/hana-cloud-database/sap-hana-cloud-sap-hana-database-vector-engine-guide/create-vector-index-statement-data-definition)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
            "\n",
            "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\n",
            "--------------------------------------------------------------------------------\n",
            "Groups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland. \n",
            "\n",
            "In this struggle as President Zelenskyy said in his speech to the European Parliament “Light will win over darkness.” The Ukrainian Ambassador to the United States is here tonight. \n",
            "\n",
            "Let each of us here tonight in this Chamber send an unmistakable signal to Ukraine and to the world.\n"
          ]
        }
      ],
      "source": [
        "# HanaDB instance uses cosine similarity as default:\n",
        "db_cosine = HanaDB(\n",
        "    embedding=embeddings, connection=connection, table_name=\"STATE_OF_THE_UNION\"\n",
        ")\n",
        "\n",
        "# Attempting to create the HNSW index with default parameters\n",
        "db_cosine.create_hnsw_index()  # If no other parameters are specified, the default values will be used\n",
        "# Default values: m=64, ef_construction=128, ef_search=200\n",
        "# The default index name will be: STATE_OF_THE_UNION_COSINE_SIMILARITY_IDX (verify this naming pattern in HanaDB class)\n",
        "\n",
        "\n",
        "# Creating a HanaDB instance with L2 distance as the similarity function and defined values\n",
        "db_l2 = HanaDB(\n",
        "    embedding=embeddings,\n",
        "    connection=connection,\n",
        "    table_name=\"STATE_OF_THE_UNION\",\n",
        "    distance_strategy=DistanceStrategy.EUCLIDEAN_DISTANCE,  # Specify L2 distance\n",
        ")\n",
        "\n",
        "# This will create an index based on L2 distance strategy.\n",
        "db_l2.create_hnsw_index(\n",
        "    index_name=\"STATE_OF_THE_UNION_L2_index\",\n",
        "    m=100,  # Max number of neighbors per graph node (valid range: 4 to 1000)\n",
        "    ef_construction=200,  # Max number of candidates during graph construction (valid range: 1 to 100000)\n",
        "    ef_search=500,  # Min number of candidates during the search (valid range: 1 to 100000)\n",
        ")\n",
        "\n",
        "# Use L2 index to perform MMR\n",
        "docs = db_l2.max_marginal_relevance_search(query, k=2, fetch_k=20)\n",
        "for doc in docs:\n",
        "    print(\"-\" * 80)\n",
        "    print(doc.page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**关键点**:\n- **相似度函数**: 索引的相似度函数默认为**余弦相似度**。如果您想使用其他相似度函数（例如 `L2` 距离），则在初始化 `HanaDB` 实例时需要指定。\n- **默认参数**: 在 `create_hnsw_index` 函数中，如果用户未提供 `m`、`ef_construction` 或 `ef_search` 等参数的自定义值，将自动使用默认值（例如 `m=64`、`ef_construction=128`、`ef_search=200`）。这些值可确保在无需用户干预的情况下，以合理的性能创建索引。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 基础向量存储操作"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "db = HanaDB(\n",
        "    connection=connection, embedding=embeddings, table_name=\"LANGCHAIN_DEMO_BASIC\"\n",
        ")\n",
        "\n",
        "# Delete already existing documents from the table\n",
        "db.delete(filter={})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "我们可以向现有表中添加简单的文本文档。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs = [Document(page_content=\"Some text\"), Document(page_content=\"Other docs\")]\n",
        "db.add_documents(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "添加带有元数据的文档。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs = [\n",
        "    Document(\n",
        "        page_content=\"foo\",\n",
        "        metadata={\"start\": 100, \"end\": 150, \"doc_name\": \"foo.txt\", \"quality\": \"bad\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"bar\",\n",
        "        metadata={\"start\": 200, \"end\": 250, \"doc_name\": \"bar.txt\", \"quality\": \"good\"},\n",
        "    ),\n",
        "]\n",
        "db.add_documents(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "查询具有特定元数据的文档。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "foo\n",
            "{'start': 100, 'end': 150, 'doc_name': 'foo.txt', 'quality': 'bad'}\n"
          ]
        }
      ],
      "source": [
        "docs = db.similarity_search(\"foobar\", k=2, filter={\"quality\": \"bad\"})\n",
        "# With filtering on \"quality\"==\"bad\", only one document should be returned\n",
        "for doc in docs:\n",
        "    print(\"-\" * 80)\n",
        "    print(doc.page_content)\n",
        "    print(doc.metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "删除具有特定元数据的文档。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "db.delete(filter={\"quality\": \"bad\"})\n",
        "\n",
        "# Now the similarity search with the same filter will return no results\n",
        "docs = db.similarity_search(\"foobar\", k=2, filter={\"quality\": \"bad\"})\n",
        "print(len(docs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 高级筛选\n除了基本的基于值的筛选功能外，还可以使用更高级的筛选。\n下表显示了可用的筛选运算符。\n\n| 运算符 | 语义                 |\n|----------|-------------------------|\n| `$eq`    | 等于 (==)           |\n| `$ne`    | 不等于 (!=)         |\n| `$lt`    | 小于 (&lt;)           |\n| `$lte`   | 小于等于 (&lt;=) |\n| `$gt`    | 大于 (>)        |\n| `$gte`   | 大于等于 (>=) |\n| `$in`    | 包含在给定值集合中 (in)    |\n| `$nin`   | 不包含在给定值集合中 (not in)  |\n| `$between` | 在两个边界值范围内 |\n| `$like`  | 基于 SQL 中的 \"LIKE\" 语义进行文本相等性匹配 (使用 \"%\" 作为通配符)  |\n| `$contains` | 筛选包含特定关键字的文档 |\n| `$and`   | 逻辑 \"与\"，支持 2 个或更多操作数 |\n| `$or`    | 逻辑 \"或\"，支持 2 个或更多操作数 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare some test documents\n",
        "docs = [\n",
        "    Document(\n",
        "        page_content=\"First\",\n",
        "        metadata={\"name\": \"Adam Smith\", \"is_active\": True, \"id\": 1, \"height\": 10.0},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Second\",\n",
        "        metadata={\"name\": \"Bob Johnson\", \"is_active\": False, \"id\": 2, \"height\": 5.7},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Third\",\n",
        "        metadata={\"name\": \"Jane Doe\", \"is_active\": True, \"id\": 3, \"height\": 2.4},\n",
        "    ),\n",
        "]\n",
        "\n",
        "db = HanaDB(\n",
        "    connection=connection,\n",
        "    embedding=embeddings,\n",
        "    table_name=\"LANGCHAIN_DEMO_ADVANCED_FILTER\",\n",
        ")\n",
        "\n",
        "# Delete already existing documents from the table\n",
        "db.delete(filter={})\n",
        "db.add_documents(docs)\n",
        "\n",
        "\n",
        "# Helper function for printing filter results\n",
        "def print_filter_result(result):\n",
        "    if len(result) == 0:\n",
        "        print(\"<empty result>\")\n",
        "    for doc in result:\n",
        "        print(doc.metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "使用 `$ne`, `$gt`, `$gte`, `$lt`, `$lte` 进行过滤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filter: {'id': {'$ne': 1}}\n",
            "{'name': 'Jane Doe', 'is_active': True, 'id': 3, 'height': 2.4}\n",
            "{'name': 'Bob Johnson', 'is_active': False, 'id': 2, 'height': 5.7}\n",
            "Filter: {'id': {'$gt': 1}}\n",
            "{'name': 'Jane Doe', 'is_active': True, 'id': 3, 'height': 2.4}\n",
            "{'name': 'Bob Johnson', 'is_active': False, 'id': 2, 'height': 5.7}\n",
            "Filter: {'id': {'$gte': 1}}\n",
            "{'name': 'Adam Smith', 'is_active': True, 'id': 1, 'height': 10.0}\n",
            "{'name': 'Jane Doe', 'is_active': True, 'id': 3, 'height': 2.4}\n",
            "{'name': 'Bob Johnson', 'is_active': False, 'id': 2, 'height': 5.7}\n",
            "Filter: {'id': {'$lt': 1}}\n",
            "<empty result>\n",
            "Filter: {'id': {'$lte': 1}}\n",
            "{'name': 'Adam Smith', 'is_active': True, 'id': 1, 'height': 10.0}\n"
          ]
        }
      ],
      "source": [
        "advanced_filter = {\"id\": {\"$ne\": 1}}\n",
        "print(f\"Filter: {advanced_filter}\")\n",
        "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))\n",
        "\n",
        "advanced_filter = {\"id\": {\"$gt\": 1}}\n",
        "print(f\"Filter: {advanced_filter}\")\n",
        "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))\n",
        "\n",
        "advanced_filter = {\"id\": {\"$gte\": 1}}\n",
        "print(f\"Filter: {advanced_filter}\")\n",
        "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))\n",
        "\n",
        "advanced_filter = {\"id\": {\"$lt\": 1}}\n",
        "print(f\"Filter: {advanced_filter}\")\n",
        "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))\n",
        "\n",
        "advanced_filter = {\"id\": {\"$lte\": 1}}\n",
        "print(f\"Filter: {advanced_filter}\")\n",
        "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "使用 `$between`、`$in` 和 `$nin` 进行筛选"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filter: {'id': {'$between': (1, 2)}}\n",
            "{'name': 'Adam Smith', 'is_active': True, 'id': 1, 'height': 10.0}\n",
            "{'name': 'Bob Johnson', 'is_active': False, 'id': 2, 'height': 5.7}\n",
            "Filter: {'name': {'$in': ['Adam Smith', 'Bob Johnson']}}\n",
            "{'name': 'Adam Smith', 'is_active': True, 'id': 1, 'height': 10.0}\n",
            "{'name': 'Bob Johnson', 'is_active': False, 'id': 2, 'height': 5.7}\n",
            "Filter: {'name': {'$nin': ['Adam Smith', 'Bob Johnson']}}\n",
            "{'name': 'Jane Doe', 'is_active': True, 'id': 3, 'height': 2.4}\n"
          ]
        }
      ],
      "source": [
        "advanced_filter = {\"id\": {\"$between\": (1, 2)}}\n",
        "print(f\"Filter: {advanced_filter}\")\n",
        "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))\n",
        "\n",
        "advanced_filter = {\"name\": {\"$in\": [\"Adam Smith\", \"Bob Johnson\"]}}\n",
        "print(f\"Filter: {advanced_filter}\")\n",
        "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))\n",
        "\n",
        "advanced_filter = {\"name\": {\"$nin\": [\"Adam Smith\", \"Bob Johnson\"]}}\n",
        "print(f\"Filter: {advanced_filter}\")\n",
        "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "使用 `$like` 进行文本过滤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filter: {'name': {'$like': 'a%'}}\n",
            "<empty result>\n",
            "Filter: {'name': {'$like': '%a%'}}\n",
            "{'name': 'Adam Smith', 'is_active': True, 'id': 1, 'height': 10.0}\n",
            "{'name': 'Jane Doe', 'is_active': True, 'id': 3, 'height': 2.4}\n"
          ]
        }
      ],
      "source": [
        "advanced_filter = {\"name\": {\"$like\": \"a%\"}}\n",
        "print(f\"Filter: {advanced_filter}\")\n",
        "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))\n",
        "\n",
        "advanced_filter = {\"name\": {\"$like\": \"%a%\"}}\n",
        "print(f\"Filter: {advanced_filter}\")\n",
        "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "使用 `$contains` 进行文本过滤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filter: {'name': {'$contains': 'bob'}}\n",
            "{'name': 'Bob Johnson', 'is_active': False, 'id': 2, 'height': 5.7}\n",
            "Filter: {'name': {'$contains': 'bo'}}\n",
            "<empty result>\n",
            "Filter: {'name': {'$contains': 'Adam Johnson'}}\n",
            "<empty result>\n",
            "Filter: {'name': {'$contains': 'Adam Smith'}}\n",
            "{'name': 'Adam Smith', 'is_active': True, 'id': 1, 'height': 10.0}\n"
          ]
        }
      ],
      "source": [
        "advanced_filter = {\"name\": {\"$contains\": \"bob\"}}\n",
        "print(f\"Filter: {advanced_filter}\")\n",
        "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))\n",
        "\n",
        "advanced_filter = {\"name\": {\"$contains\": \"bo\"}}\n",
        "print(f\"Filter: {advanced_filter}\")\n",
        "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))\n",
        "\n",
        "advanced_filter = {\"name\": {\"$contains\": \"Adam Johnson\"}}\n",
        "print(f\"Filter: {advanced_filter}\")\n",
        "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))\n",
        "\n",
        "advanced_filter = {\"name\": {\"$contains\": \"Adam Smith\"}}\n",
        "print(f\"Filter: {advanced_filter}\")\n",
        "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "结合使用 `$and` 和 `$or` 进行筛选"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filter: {'$or': [{'id': 1}, {'name': 'bob'}]}\n",
            "{'name': 'Adam Smith', 'is_active': True, 'id': 1, 'height': 10.0}\n",
            "Filter: {'$and': [{'id': 1}, {'id': 2}]}\n",
            "<empty result>\n",
            "Filter: {'$or': [{'id': 1}, {'id': 2}, {'id': 3}]}\n",
            "{'name': 'Adam Smith', 'is_active': True, 'id': 1, 'height': 10.0}\n",
            "{'name': 'Jane Doe', 'is_active': True, 'id': 3, 'height': 2.4}\n",
            "{'name': 'Bob Johnson', 'is_active': False, 'id': 2, 'height': 5.7}\n",
            "Filter: {'$and': [{'name': {'$contains': 'bob'}}, {'name': {'$contains': 'johnson'}}]}\n",
            "{'name': 'Bob Johnson', 'is_active': False, 'id': 2, 'height': 5.7}\n"
          ]
        }
      ],
      "source": [
        "advanced_filter = {\"$or\": [{\"id\": 1}, {\"name\": \"bob\"}]}\n",
        "print(f\"Filter: {advanced_filter}\")\n",
        "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))\n",
        "\n",
        "advanced_filter = {\"$and\": [{\"id\": 1}, {\"id\": 2}]}\n",
        "print(f\"Filter: {advanced_filter}\")\n",
        "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))\n",
        "\n",
        "advanced_filter = {\"$or\": [{\"id\": 1}, {\"id\": 2}, {\"id\": 3}]}\n",
        "print(f\"Filter: {advanced_filter}\")\n",
        "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))\n",
        "\n",
        "advanced_filter = {\n",
        "    \"$and\": [{\"name\": {\"$contains\": \"bob\"}}, {\"name\": {\"$contains\": \"johnson\"}}]\n",
        "}\n",
        "print(f\"Filter: {advanced_filter}\")\n",
        "print_filter_result(db.similarity_search(\"just testing\", k=5, filter=advanced_filter))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 将 VectorStore 用作链中的检索器，实现检索增强生成 (RAG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Access the vector DB with a new table\n",
        "db = HanaDB(\n",
        "    connection=connection,\n",
        "    embedding=embeddings,\n",
        "    table_name=\"LANGCHAIN_DEMO_RETRIEVAL_CHAIN\",\n",
        ")\n",
        "\n",
        "# Delete already existing entries from the table\n",
        "db.delete(filter={})\n",
        "\n",
        "# add the loaded document chunks from the \"State Of The Union\" file\n",
        "db.add_documents(text_chunks)\n",
        "\n",
        "# Create a retriever instance of the vector store\n",
        "retriever = db.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "定义提示。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "You are an expert in state of the union topics. You are provided multiple context items that are related to the prompt you have to answer.\n",
        "Use the following pieces of context to answer the question at the end.\n",
        "\n",
        "'''\n",
        "{context}\n",
        "'''\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "PROMPT = PromptTemplate(\n",
        "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "chain_type_kwargs = {\"prompt\": PROMPT}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "创建 ConversationalRetrievalChain，它负责处理聊天记录以及检索相似文档块以添加到 prompt 中。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "memory = ConversationBufferMemory(\n",
        "    memory_key=\"chat_history\", output_key=\"answer\", return_messages=True\n",
        ")\n",
        "qa_chain = ConversationalRetrievalChain.from_llm(\n",
        "    llm,\n",
        "    db.as_retriever(search_kwargs={\"k\": 5}),\n",
        "    return_source_documents=True,\n",
        "    memory=memory,\n",
        "    verbose=False,\n",
        "    combine_docs_chain_kwargs={\"prompt\": PROMPT},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "提第一个问题（并验证使用了多少文本块）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer from LLM:\n",
            "================\n",
            "The United States has set up joint patrols with Mexico and Guatemala to catch more human traffickers at the border. This collaborative effort aims to improve border security and combat illegal activities such as human trafficking.\n",
            "================\n",
            "Number of used source document chunks: 5\n"
          ]
        }
      ],
      "source": [
        "question = \"What about Mexico and Guatemala?\"\n",
        "\n",
        "result = qa_chain.invoke({\"question\": question})\n",
        "print(\"Answer from LLM:\")\n",
        "print(\"================\")\n",
        "print(result[\"answer\"])\n",
        "\n",
        "source_docs = result[\"source_documents\"]\n",
        "print(\"================\")\n",
        "print(f\"Number of used source document chunks: {len(source_docs)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "请提供需要翻译的英文 MDX 内容。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for doc in source_docs:\n",
        "    print(\"-\" * 80)\n",
        "    print(doc.page_content)\n",
        "    print(doc.metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "在同一会话链中提出另一个问题。答案应与之前给出的答案相关。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer from LLM:\n",
            "================\n",
            "Countries like Mexico and Guatemala are participating in joint patrols to catch human traffickers. The United States is also working with partners in South and Central America to host more refugees and secure their borders. Additionally, the U.S. is working with twenty-seven members of the European Union, as well as countries like France, Germany, Italy, the United Kingdom, Canada, Japan, Korea, Australia, New Zealand, and Switzerland.\n"
          ]
        }
      ],
      "source": [
        "question = \"How many casualties were reported after that?\"\n",
        "\n",
        "result = qa_chain.invoke({\"question\": question})\n",
        "print(\"Answer from LLM:\")\n",
        "print(\"================\")\n",
        "print(result[\"answer\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 标准表与包含向量数据的“自定义”表"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "作为默认行为，embeddings 表将创建 3 列：\n\n- `VEC_TEXT` 列，包含 Document 的文本\n- `VEC_META` 列，包含 Document 的元数据\n- `VEC_VECTOR` 列，包含 Document 文本的 embedding 向量"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Access the vector DB with a new table\n",
        "db = HanaDB(\n",
        "    connection=connection, embedding=embeddings, table_name=\"LANGCHAIN_DEMO_NEW_TABLE\"\n",
        ")\n",
        "\n",
        "# Delete already existing entries from the table\n",
        "db.delete(filter={})\n",
        "\n",
        "# Add a simple document with some metadata\n",
        "docs = [\n",
        "    Document(\n",
        "        page_content=\"A simple document\",\n",
        "        metadata={\"start\": 100, \"end\": 150, \"doc_name\": \"simple.txt\"},\n",
        "    )\n",
        "]\n",
        "db.add_documents(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "显示表格 \"LANGCHAIN_DEMO_NEW_TABLE\" 中的列"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('VEC_META', 'NCLOB')\n",
            "('VEC_TEXT', 'NCLOB')\n",
            "('VEC_VECTOR', 'REAL_VECTOR')\n"
          ]
        }
      ],
      "source": [
        "cur = connection.cursor()\n",
        "cur.execute(\n",
        "    \"SELECT COLUMN_NAME, DATA_TYPE_NAME FROM SYS.TABLE_COLUMNS WHERE SCHEMA_NAME = CURRENT_SCHEMA AND TABLE_NAME = 'LANGCHAIN_DEMO_NEW_TABLE'\"\n",
        ")\n",
        "rows = cur.fetchall()\n",
        "for row in rows:\n",
        "    print(row)\n",
        "cur.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "在三列中显示插入文档的值"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cur = connection.cursor()\n",
        "cur.execute(\n",
        "    \"SELECT VEC_TEXT, VEC_META, TO_NVARCHAR(VEC_VECTOR) FROM LANGCHAIN_DEMO_NEW_TABLE LIMIT 1\"\n",
        ")\n",
        "rows = cur.fetchall()\n",
        "print(rows[0][0])  # The text\n",
        "print(rows[0][1])  # The metadata\n",
        "print(rows[0][2])  # The vector\n",
        "cur.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "自定义表必须至少包含三个符合标准表语义的列：\n\n- 一列类型为 `NCLOB` 或 `NVARCHAR`，用于存储嵌入的文本/上下文\n- 一列类型为 `NCLOB` 或 `NVARCHAR`，用于存储元数据\n- 一列类型为 `REAL_VECTOR`，用于存储嵌入向量\n\n该表还可以包含额外的列。当新 Document 插入表中时，这些额外列必须允许 NULL 值。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "Some other text\n",
            "{\"start\": 400, \"end\": 450, \"doc_name\": \"other.txt\"}\n",
            "<memory at 0x110f856c0>\n"
          ]
        }
      ],
      "source": [
        "# Create a new table \"MY_OWN_TABLE_ADD\" with three \"standard\" columns and one additional column\n",
        "my_own_table_name = \"MY_OWN_TABLE_ADD\"\n",
        "cur = connection.cursor()\n",
        "cur.execute(\n",
        "    (\n",
        "        f\"CREATE TABLE {my_own_table_name} (\"\n",
        "        \"SOME_OTHER_COLUMN NVARCHAR(42), \"\n",
        "        \"MY_TEXT NVARCHAR(2048), \"\n",
        "        \"MY_METADATA NVARCHAR(1024), \"\n",
        "        \"MY_VECTOR REAL_VECTOR )\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Create a HanaDB instance with the own table\n",
        "db = HanaDB(\n",
        "    connection=connection,\n",
        "    embedding=embeddings,\n",
        "    table_name=my_own_table_name,\n",
        "    content_column=\"MY_TEXT\",\n",
        "    metadata_column=\"MY_METADATA\",\n",
        "    vector_column=\"MY_VECTOR\",\n",
        ")\n",
        "\n",
        "# Add a simple document with some metadata\n",
        "docs = [\n",
        "    Document(\n",
        "        page_content=\"Some other text\",\n",
        "        metadata={\"start\": 400, \"end\": 450, \"doc_name\": \"other.txt\"},\n",
        "    )\n",
        "]\n",
        "db.add_documents(docs)\n",
        "\n",
        "# Check if data has been inserted into our own table\n",
        "cur.execute(f\"SELECT * FROM {my_own_table_name} LIMIT 1\")\n",
        "rows = cur.fetchall()\n",
        "print(rows[0][0])  # Value of column \"SOME_OTHER_DATA\". Should be NULL/None\n",
        "print(rows[0][1])  # The text\n",
        "print(rows[0][2])  # The metadata\n",
        "print(rows[0][3])  # The vector\n",
        "\n",
        "cur.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "添加另一个文档并对自定义表执行相似性搜索。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Some more text\n",
            "--------------------------------------------------------------------------------\n",
            "Some other text\n"
          ]
        }
      ],
      "source": [
        "docs = [\n",
        "    Document(\n",
        "        page_content=\"Some more text\",\n",
        "        metadata={\"start\": 800, \"end\": 950, \"doc_name\": \"more.txt\"},\n",
        "    )\n",
        "]\n",
        "db.add_documents(docs)\n",
        "\n",
        "query = \"What's up?\"\n",
        "docs = db.similarity_search(query, k=2)\n",
        "for doc in docs:\n",
        "    print(\"-\" * 80)\n",
        "    print(doc.page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 自定义列的性能优化过滤"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "为了允许灵活的元数据值，默认情况下所有元数据都以 JSON 格式存储在 metadata 列中。如果已知一些使用的元数据键和值类型，可以通过将目标表的键名作为列名，并将它们通过 specific_metadata_columns 列表传递给 HanaDB 构造函数来将它们存储在其他列中。在插入期间，与这些值匹配的元数据键会被复制到特殊列中。过滤器将使用特殊列而不是 metadata JSON 列来过滤 specific_metadata_columns 列表中的键。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filters on this value are very performant\n",
            "Some other text\n",
            "{\"start\": 400, \"end\": 450, \"doc_name\": \"other.txt\", \"CUSTOMTEXT\": \"Filters on this value are very performant\"}\n",
            "<memory at 0x110f859c0>\n"
          ]
        }
      ],
      "source": [
        "# Create a new table \"PERFORMANT_CUSTOMTEXT_FILTER\" with three \"standard\" columns and one additional column\n",
        "my_own_table_name = \"PERFORMANT_CUSTOMTEXT_FILTER\"\n",
        "cur = connection.cursor()\n",
        "cur.execute(\n",
        "    (\n",
        "        f\"CREATE TABLE {my_own_table_name} (\"\n",
        "        \"CUSTOMTEXT NVARCHAR(500), \"\n",
        "        \"MY_TEXT NVARCHAR(2048), \"\n",
        "        \"MY_METADATA NVARCHAR(1024), \"\n",
        "        \"MY_VECTOR REAL_VECTOR )\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Create a HanaDB instance with the own table\n",
        "db = HanaDB(\n",
        "    connection=connection,\n",
        "    embedding=embeddings,\n",
        "    table_name=my_own_table_name,\n",
        "    content_column=\"MY_TEXT\",\n",
        "    metadata_column=\"MY_METADATA\",\n",
        "    vector_column=\"MY_VECTOR\",\n",
        "    specific_metadata_columns=[\"CUSTOMTEXT\"],\n",
        ")\n",
        "\n",
        "# Add a simple document with some metadata\n",
        "docs = [\n",
        "    Document(\n",
        "        page_content=\"Some other text\",\n",
        "        metadata={\n",
        "            \"start\": 400,\n",
        "            \"end\": 450,\n",
        "            \"doc_name\": \"other.txt\",\n",
        "            \"CUSTOMTEXT\": \"Filters on this value are very performant\",\n",
        "        },\n",
        "    )\n",
        "]\n",
        "db.add_documents(docs)\n",
        "\n",
        "# Check if data has been inserted into our own table\n",
        "cur.execute(f\"SELECT * FROM {my_own_table_name} LIMIT 1\")\n",
        "rows = cur.fetchall()\n",
        "print(\n",
        "    rows[0][0]\n",
        ")  # Value of column \"CUSTOMTEXT\". Should be \"Filters on this value are very performant\"\n",
        "print(rows[0][1])  # The text\n",
        "print(\n",
        "    rows[0][2]\n",
        ")  # The metadata without the \"CUSTOMTEXT\" data, as this is extracted into a sperate column\n",
        "print(rows[0][3])  # The vector\n",
        "\n",
        "cur.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "特殊列对 langchain 接口的其余部分是完全透明的。所有功能正常，只是性能更佳。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Some more text\n",
            "--------------------------------------------------------------------------------\n",
            "Some other text\n"
          ]
        }
      ],
      "source": [
        "docs = [\n",
        "    Document(\n",
        "        page_content=\"Some more text\",\n",
        "        metadata={\n",
        "            \"start\": 800,\n",
        "            \"end\": 950,\n",
        "            \"doc_name\": \"more.txt\",\n",
        "            \"CUSTOMTEXT\": \"Another customtext value\",\n",
        "        },\n",
        "    )\n",
        "]\n",
        "db.add_documents(docs)\n",
        "\n",
        "advanced_filter = {\"CUSTOMTEXT\": {\"$like\": \"%value%\"}}\n",
        "query = \"What's up?\"\n",
        "docs = db.similarity_search(query, k=2, filter=advanced_filter)\n",
        "for doc in docs:\n",
        "    print(\"-\" * 80)\n",
        "    print(doc.page_content)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dev311",
      "language": "python",
      "name": "dev311"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}