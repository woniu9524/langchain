{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Timescale Vector (Postgres)\n\n>[Timescale Vector](https://www.timescale.com/ai?utm_campaign=vectorlaunch&utm_source=langchain&utm_medium=referral) 是专为 AI 应用设计的 `PostgreSQL++` 向量数据库。\n\n本指南将展示如何使用 Postgres 向量数据库 `Timescale Vector`。你将学习如何使用 TimescaleVector 进行 (1) 语义搜索，(2) 基于时间的向量搜索，(3) 自我查询，以及 (4) 如何创建索引以加快查询速度。\n\n## Timescale Vector 是什么？\n\n`Timescale Vector` 使你能够在 `PostgreSQL` 中高效地存储和查询数百万个向量嵌入。\n- 通过基于 `DiskANN` 的索引算法，增强 `pgvector`，实现对 1 亿以上向量的更快、更准确的相似性搜索。\n- 通过自动化的时间分区和索引，实现快速的基于时间的向量搜索。\n- 提供熟悉的 SQL 接口，用于查询向量嵌入和关系数据。\n\n`Timescale Vector` 是面向 AI 的云 `PostgreSQL`，可伴随你从概念验证（POC）扩展到生产环境：\n- 通过允许你在单个数据库中存储关系元数据、向量嵌入和时间序列数据，简化了操作。\n- 受益于坚如磐石的 PostgreSQL 基础，具备流式备份和复制、高可用性以及行级安全性等企业级功能。\n- 通过企业级安全和合规性，带来无忧的使用体验。\n\n## 如何访问 Timescale Vector\n\n`Timescale Vector` 可在云 PostgreSQL 平台 [Timescale](https://www.timescale.com/ai?utm_campaign=vectorlaunch&utm_source=langchain&utm_medium=referral) 上获得。（目前没有自托管版本。）\n\nLangChain 用户可获得 90 天 Timescale Vector 免费试用。\n- 要开始使用，请在 [Timescale 注册](https://console.cloud.timescale.com/signup?utm_campaign=vectorlaunch&utm_source=langchain&utm_medium=referral)并创建一个新数据库，然后按照本指南操作！\n- 有关更多详细信息和性能基准测试，请参阅 [Timescale Vector 解释博客](https://www.timescale.com/blog/how-we-made-postgresql-the-best-vector-database/?utm_campaign=vectorlaunch&utm_source=langchain&utm_medium=referral)。\n- 有关在 Python 中使用 Timescale Vector 的更多详细信息，请参阅 [安装说明](https://github.com/timescale/python-vector)。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 设置\n\n请遵循以下步骤准备开始本教程。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Pip install necessary packages\n",
        "%pip install --upgrade --quiet  timescale-vector\n",
        "%pip install --upgrade --quiet  langchain-openai langchain-community\n",
        "%pip install --upgrade --quiet  tiktoken"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "在此示例中，我们将使用 `OpenAIEmbeddings`，因此请加载您的 OpenAI API 密钥。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Run export OPENAI_API_KEY=sk-YOUR_OPENAI_API_KEY...\n",
        "# Get openAI api key by reading local .env file\n",
        "from dotenv import find_dotenv, load_dotenv\n",
        "\n",
        "_ = load_dotenv(find_dotenv())\n",
        "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the API key and save it as an environment variable\n",
        "# import os\n",
        "# import getpass\n",
        "# os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "from typing import Tuple"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "接下来，我们将导入所需的 Python 库以及 LangChain 中的库。请注意，我们导入了 `timescale-vector` 库以及 TimescaleVector LangChain 向量存储。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta\n",
        "\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_community.document_loaders.json_loader import JSONLoader\n",
        "from langchain_community.vectorstores.timescalevector import TimescaleVector\n",
        "from langchain_core.documents import Document\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_text_splitters import CharacterTextSplitter"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 欧几里得距离（默认）相似性搜索\n\n首先，我们将通过一个对《国情咨文》进行相似性搜索的示例，来查找与给定查询句最相似的句子。我们将使用 [欧几里得距离](https://en.wikipedia.org/wiki/Euclidean_distance) 作为我们的相似性度量。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the text and split it into chunks\n",
        "loader = TextLoader(\"../../../extras/modules/state_of_the_union.txt\")\n",
        "documents = loader.load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n",
        "embeddings = OpenAIEmbeddings()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "接下来，我们将加载 Timescale 数据库的服务 URL。\n\n如果还没有，请先[注册 Timescale](https://console.cloud.timescale.com/signup?utm_campaign=vectorlaunch&utm_source=langchain&utm_medium=referral) 并创建一个新数据库。\n\n然后，要连接到 PostgreSQL 数据库，您需要服务 URI。该 URI 可以在创建新数据库后下载的备忘单或 `.env` 文件中找到。\n\nURI 的格式大致如下：`postgres://tsdbadmin:<password>@<id>.tsdb.cloud.timescale.com:<port>/tsdb?sslmode=require`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Timescale Vector needs the service url to your cloud database. You can see this as soon as you create the\n",
        "# service in the cloud UI or in your credentials.sql file\n",
        "SERVICE_URL = os.environ[\"TIMESCALE_SERVICE_URL\"]\n",
        "\n",
        "# Specify directly if testing\n",
        "# SERVICE_URL = \"postgres://tsdbadmin:<password>@<id>.tsdb.cloud.timescale.com:<port>/tsdb?sslmode=require\"\n",
        "\n",
        "# # You can get also it from an environment variables. We suggest using a .env file.\n",
        "# import os\n",
        "# SERVICE_URL = os.environ.get(\"TIMESCALE_SERVICE_URL\", \"\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "接下来，我们创建一个 TimescaleVector 向量存储。我们指定一个 collection name，这将是我们数据存储的表的名称。\n\n注意：在创建 TimescaleVector 的新实例时，TimescaleVector Module 会尝试创建一个与 collection 名称同名的表。因此，请确保 collection name 是唯一的（即它尚未存在）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The TimescaleVector Module will create a table with the name of the collection.\n",
        "COLLECTION_NAME = \"state_of_the_union_test\"\n",
        "\n",
        "# Create a Timescale Vector instance from the collection of documents\n",
        "db = TimescaleVector.from_documents(\n",
        "    embedding=embeddings,\n",
        "    documents=docs,\n",
        "    collection_name=COLLECTION_NAME,\n",
        "    service_url=SERVICE_URL,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "现在我们已经加载了数据，可以执行相似性搜索了。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = \"What did the president say about Ketanji Brown Jackson\"\n",
        "docs_with_score = db.similarity_search_with_score(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Score:  0.18443380687035138\n",
            "Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. \n",
            "\n",
            "Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n",
            "\n",
            "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
            "\n",
            "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "Score:  0.18452197313308139\n",
            "Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. \n",
            "\n",
            "Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n",
            "\n",
            "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
            "\n",
            "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "Score:  0.21720781018594182\n",
            "A former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she’s been nominated, she’s received a broad range of support—from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n",
            "\n",
            "And if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n",
            "\n",
            "We can do both. At our border, we’ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n",
            "\n",
            "We’ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \n",
            "\n",
            "We’re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \n",
            "\n",
            "We’re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "Score:  0.21724902288621384\n",
            "A former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she’s been nominated, she’s received a broad range of support—from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n",
            "\n",
            "And if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n",
            "\n",
            "We can do both. At our border, we’ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n",
            "\n",
            "We’ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \n",
            "\n",
            "We’re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \n",
            "\n",
            "We’re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for doc, score in docs_with_score:\n",
        "    print(\"-\" * 80)\n",
        "    print(\"Score: \", score)\n",
        "    print(doc.page_content)\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 将 Timescale Vector 用作检索器\n初始化 TimescaleVector 存储后，可以将其用作[检索器](/docs/how_to#retrievers)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use TimescaleVector as a retriever\n",
        "retriever = db.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tags=['TimescaleVector', 'OpenAIEmbeddings'] metadata=None vectorstore=<langchain_community.vectorstores.timescalevector.TimescaleVector object at 0x10fc8d070> search_type='similarity' search_kwargs={}\n"
          ]
        }
      ],
      "source": [
        "print(retriever)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "让我们看一个在 RetrievalQA 链和 stuff documents 链中使用 Timescale Vector 作为检索器的示例。\n\n在这个示例中，我们将问与上面相同的问题，但这次我们将把从 Timescale Vector 返回的相关文档传递给 LLM，作为回答问题的上下文。\n\n首先，我们将创建我们的 stuff 链："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize GPT3.5 model\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(temperature=0.1, model=\"gpt-3.5-turbo-16k\")\n",
        "\n",
        "# Initialize a RetrievalQA class from a stuff chain\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "qa_stuff = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "query = \"What did the president say about Ketanji Brown Jackson?\"\n",
        "response = qa_stuff.run(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The President said that he nominated Circuit Court of Appeals Judge Ketanji Brown Jackson, who is one of our nation's top legal minds and will continue Justice Breyer's legacy of excellence. He also mentioned that since her nomination, she has received a broad range of support from various groups, including the Fraternal Order of Police and former judges appointed by Democrats and Republicans.\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 基于时间的相似性搜索\n\nTimescale Vector 的一个关键用例是高效的基于时间的向量搜索。Timescale Vector 通过自动按时间对向量（及相关元数据）进行分区来实现这一点。这使您能够高效地通过与查询向量的相似性和时间来查询向量。\n\n基于时间的向量搜索功能对于以下应用非常有用：\n- 存储和检索 LLM 响应历史（例如，聊天机器人）\n- 查找与查询向量相似的最新嵌入（例如，最近的新闻）。\n- 将相似性搜索限制在相关的时间范围内（例如，就某个知识库提出基于时间的问题）\n\n为了说明如何使用 TimescaleVector 的基于时间的向量搜索功能，我们将询问有关 TimescaleDB 的 git 日志历史的问题。我们将说明如何添加带有基于时间的 uuid 的文档，以及如何运行带有时间范围过滤器的相似性搜索。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 从 git log JSON 中提取内容和元数据\n首先，我们将 git log 数据加载到 PostgreSQL 数据库的一个名为 `timescale_commits` 的新集合中。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "我们将定义一个辅助函数，根据文档的时间戳为其创建 uuid 以及关联的向量嵌入。我们将使用此函数为每个 git log 条目创建 uuid。\n\n重要提示：如果您正在处理文档，并且希望将当前日期和时间与向量关联以进行基于时间的搜索，则可以跳过此步骤。默认情况下，在摄取文档时会自动生成 uuid。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "from timescale_vector import client\n",
        "\n",
        "\n",
        "# Function to take in a date string in the past and return a uuid v1\n",
        "def create_uuid(date_string: str):\n",
        "    if date_string is None:\n",
        "        return None\n",
        "    time_format = \"%a %b %d %H:%M:%S %Y %z\"\n",
        "    datetime_obj = datetime.strptime(date_string, time_format)\n",
        "    uuid = client.uuid_from_time(datetime_obj)\n",
        "    return str(uuid)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "接下来，我们将定义一个 metadata 函数，用于从 JSON 记录中提取相关的元数据。我们将把这个函数传递给 JSONLoader。有关更多详细信息，请参阅 [JSON 文档加载器文档](/docs/how_to/document_loader_json)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper function to split name and email given an author string consisting of Name Lastname <email>\n",
        "def split_name(input_string: str) -> Tuple[str, str]:\n",
        "    if input_string is None:\n",
        "        return None, None\n",
        "    start = input_string.find(\"<\")\n",
        "    end = input_string.find(\">\")\n",
        "    name = input_string[:start].strip()\n",
        "    email = input_string[start + 1 : end].strip()\n",
        "    return name, email\n",
        "\n",
        "\n",
        "# Helper function to transform a date string into a timestamp_tz string\n",
        "def create_date(input_string: str) -> datetime:\n",
        "    if input_string is None:\n",
        "        return None\n",
        "    # Define a dictionary to map month abbreviations to their numerical equivalents\n",
        "    month_dict = {\n",
        "        \"Jan\": \"01\",\n",
        "        \"Feb\": \"02\",\n",
        "        \"Mar\": \"03\",\n",
        "        \"Apr\": \"04\",\n",
        "        \"May\": \"05\",\n",
        "        \"Jun\": \"06\",\n",
        "        \"Jul\": \"07\",\n",
        "        \"Aug\": \"08\",\n",
        "        \"Sep\": \"09\",\n",
        "        \"Oct\": \"10\",\n",
        "        \"Nov\": \"11\",\n",
        "        \"Dec\": \"12\",\n",
        "    }\n",
        "\n",
        "    # Split the input string into its components\n",
        "    components = input_string.split()\n",
        "    # Extract relevant information\n",
        "    day = components[2]\n",
        "    month = month_dict[components[1]]\n",
        "    year = components[4]\n",
        "    time = components[3]\n",
        "    timezone_offset_minutes = int(components[5])  # Convert the offset to minutes\n",
        "    timezone_hours = timezone_offset_minutes // 60  # Calculate the hours\n",
        "    timezone_minutes = timezone_offset_minutes % 60  # Calculate the remaining minutes\n",
        "    # Create a formatted string for the timestamptz in PostgreSQL format\n",
        "    timestamp_tz_str = (\n",
        "        f\"{year}-{month}-{day} {time}+{timezone_hours:02}{timezone_minutes:02}\"\n",
        "    )\n",
        "    return timestamp_tz_str\n",
        "\n",
        "\n",
        "# Metadata extraction function to extract metadata from a JSON record\n",
        "def extract_metadata(record: dict, metadata: dict) -> dict:\n",
        "    record_name, record_email = split_name(record[\"author\"])\n",
        "    metadata[\"id\"] = create_uuid(record[\"date\"])\n",
        "    metadata[\"date\"] = create_date(record[\"date\"])\n",
        "    metadata[\"author_name\"] = record_name\n",
        "    metadata[\"author_email\"] = record_email\n",
        "    metadata[\"commit_hash\"] = record[\"commit\"]\n",
        "    return metadata"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "接下来，您需要[下载示例数据集](https://s3.amazonaws.com/assets.timescale.com/ai/ts_git_log.json)，并将其放置在与此 Notebook 相同的目录中。\n\n您可以使用以下命令："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "# Download the file using curl and save it as commit_history.csv\n",
        "# Note: Execute this command in your terminal, in the same directory as the notebook\n",
        "!curl -O https://s3.amazonaws.com/assets.timescale.com/ai/ts_git_log.json"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "最后，我们可以初始化 JSON loader 来解析 JSON 记录。为了简化起见，我们还移除了空记录。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define path to the JSON file relative to this notebook\n",
        "# Change this to the path to your JSON file\n",
        "FILE_PATH = \"../../../../../ts_git_log.json\"\n",
        "\n",
        "# Load data from JSON file and extract metadata\n",
        "loader = JSONLoader(\n",
        "    file_path=FILE_PATH,\n",
        "    jq_schema=\".commit_history[]\",\n",
        "    text_content=False,\n",
        "    metadata_func=extract_metadata,\n",
        ")\n",
        "documents = loader.load()\n",
        "\n",
        "# Remove documents with None dates\n",
        "documents = [doc for doc in documents if doc.metadata[\"date\"] is not None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='{\"commit\": \"44e41c12ab25e36c202f58e068ced262eadc8d16\", \"author\": \"Lakshmi Narayanan Sreethar<lakshmi@timescale.com>\", \"date\": \"Tue Sep 5 21:03:21 2023 +0530\", \"change summary\": \"Fix segfault in set_integer_now_func\", \"change details\": \"When an invalid function oid is passed to set_integer_now_func, it finds out that the function oid is invalid but before throwing the error, it calls ReleaseSysCache on an invalid tuple causing a segfault. Fixed that by removing the invalid call to ReleaseSysCache.  Fixes #6037 \"}' metadata={'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/ts_git_log.json', 'seq_num': 1, 'id': '8b407680-4c01-11ee-96a6-b82284ddccc6', 'date': '2023-09-5 21:03:21+0850', 'author_name': 'Lakshmi Narayanan Sreethar', 'author_email': 'lakshmi@timescale.com', 'commit_hash': '44e41c12ab25e36c202f58e068ced262eadc8d16'}\n"
          ]
        }
      ],
      "source": [
        "print(documents[0])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 将文档和元数据加载到 TimescaleVector 向量数据库\n\n既然我们已经准备好了文档，现在就将它们与向量嵌入表示一起处理并加载到我们的 TimescaleVector 向量数据库中。\n\n由于这是一个演示，我们只加载前 500 条记录。在实际应用中，您可以加载任意数量的记录。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "NUM_RECORDS = 500\n",
        "documents = documents[:NUM_RECORDS]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "然后我们使用 `CharacterTextSplitter` 将文档分割成更小的块（如果需要），以便于嵌入。请注意，此分割过程会保留每个文档的元数据。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the documents into chunks for embedding\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        ")\n",
        "docs = text_splitter.split_documents(documents)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "接下来，我们将从先前完成预处理的文档集合中创建一个 Timescale Vector 实例。\n\n首先，我们将定义一个集合名称，它将是我们 PostgreSQL 数据库中的表名。\n\n我们还将定义一个时间间隔（time delta），并将其传递给 `time_partition_interval` 参数，该参数将用于按时间对数据进行分区。每个分区将包含指定时长的时段数据。为简单起见，我们将使用 7 天，但您可以根据您的用例选择任何有意义的值——例如，如果您频繁查询近期向量，您可能希望使用更小的时间间隔，如 1 天；如果您查询跨度长达十年的向量，您可能希望使用更大的时间间隔，如 6 个月或 1 年。\n\n最后，我们将创建 TimescaleVector 实例。我们将 `ids` 参数指定为我们在上述预处理步骤中创建的元数据中的 `uuid` 字段。我们这样做是因为我们希望我们的 UUID 的时间部分反映过去（即提交发生的时间）。但是，如果我们希望当前日期和时间与我们的文档相关联，我们可以删除 `id` 参数，UUID 将自动创建为当前日期和时间。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define collection name\n",
        "COLLECTION_NAME = \"timescale_commits\"\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# Create a Timescale Vector instance from the collection of documents\n",
        "db = TimescaleVector.from_documents(\n",
        "    embedding=embeddings,\n",
        "    ids=[doc.metadata[\"id\"] for doc in docs],\n",
        "    documents=docs,\n",
        "    collection_name=COLLECTION_NAME,\n",
        "    service_url=SERVICE_URL,\n",
        "    time_partition_interval=timedelta(days=7),\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 按时间和相似度查询向量\n\n现在我们已将文档加载到 TimescaleVector 中，可以按时间和相似度进行查询。\n\nTimescaleVector 提供了多种通过相似度搜索并进行基于时间过滤来查询向量的方法。\n\n下面我们来看看每种方法："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Time filter variables\n",
        "start_dt = datetime(2023, 8, 1, 22, 10, 35)  # Start date = 1 August 2023, 22:10:35\n",
        "end_dt = datetime(2023, 8, 30, 22, 10, 35)  # End date = 30 August 2023, 22:10:35\n",
        "td = timedelta(days=7)  # Time delta = 7 days\n",
        "\n",
        "query = \"What's new with TimescaleDB functions?\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "方法 1：在提供的开始日期和结束日期内进行筛选。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Score:  0.17488396167755127\n",
            "Date:  2023-08-29 18:13:24+0320\n",
            "{\"commit\": \" e4facda540286b0affba47ccc63959fefe2a7b26\", \"author\": \"Sven Klemm<sven@timescale.com>\", \"date\": \"Tue Aug 29 18:13:24 2023 +0200\", \"change summary\": \"Add compatibility layer for _timescaledb_internal functions\", \"change details\": \"With timescaledb 2.12 all the functions present in _timescaledb_internal were moved into the _timescaledb_functions schema to improve schema security. This patch adds a compatibility layer so external callers of these internal functions will not break and allow for more flexibility when migrating. \"}\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "Score:  0.18102192878723145\n",
            "Date:  2023-08-20 22:47:10+0320\n",
            "{\"commit\": \" 0a66bdb8d36a1879246bd652e4c28500c4b951ab\", \"author\": \"Sven Klemm<sven@timescale.com>\", \"date\": \"Sun Aug 20 22:47:10 2023 +0200\", \"change summary\": \"Move functions to _timescaledb_functions schema\", \"change details\": \"To increase schema security we do not want to mix our own internal objects with user objects. Since chunks are created in the _timescaledb_internal schema our internal functions should live in a different dedicated schema. This patch make the necessary adjustments for the following functions:  - to_unix_microseconds(timestamptz) - to_timestamp(bigint) - to_timestamp_without_timezone(bigint) - to_date(bigint) - to_interval(bigint) - interval_to_usec(interval) - time_to_internal(anyelement) - subtract_integer_from_now(regclass, bigint) \"}\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "Score:  0.18150119891755445\n",
            "Date:  2023-08-22 12:01:19+0320\n",
            "{\"commit\": \" cf04496e4b4237440274eb25e4e02472fc4e06fc\", \"author\": \"Sven Klemm<sven@timescale.com>\", \"date\": \"Tue Aug 22 12:01:19 2023 +0200\", \"change summary\": \"Move utility functions to _timescaledb_functions schema\", \"change details\": \"To increase schema security we do not want to mix our own internal objects with user objects. Since chunks are created in the _timescaledb_internal schema our internal functions should live in a different dedicated schema. This patch make the necessary adjustments for the following functions:  - generate_uuid() - get_git_commit() - get_os_info() - tsl_loaded() \"}\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "Score:  0.18422493887617963\n",
            "Date:  2023-08-9 15:26:03+0500\n",
            "{\"commit\": \" 44eab9cf9bef34274c88efd37a750eaa74cd8044\", \"author\": \"Konstantina Skovola<konstantina@timescale.com>\", \"date\": \"Wed Aug 9 15:26:03 2023 +0300\", \"change summary\": \"Release 2.11.2\", \"change details\": \"This release contains bug fixes since the 2.11.1 release. We recommend that you upgrade at the next available opportunity.  **Features** * #5923 Feature flags for TimescaleDB features  **Bugfixes** * #5680 Fix DISTINCT query with JOIN on multiple segmentby columns * #5774 Fixed two bugs in decompression sorted merge code * #5786 Ensure pg_config --cppflags are passed * #5906 Fix quoting owners in sql scripts. * #5912 Fix crash in 1-step integer policy creation  **Thanks** * @mrksngl for submitting a PR to fix extension upgrade scripts * @ericdevries for reporting an issue with DISTINCT queries using segmentby columns of compressed hypertable \"}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Method 1: Query for vectors between start_date and end_date\n",
        "docs_with_score = db.similarity_search_with_score(\n",
        "    query, start_date=start_dt, end_date=end_dt\n",
        ")\n",
        "\n",
        "for doc, score in docs_with_score:\n",
        "    print(\"-\" * 80)\n",
        "    print(\"Score: \", score)\n",
        "    print(\"Date: \", doc.metadata[\"date\"])\n",
        "    print(doc.page_content)\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "请注意，此查询仅返回指定日期范围内的结果。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "方法二：在提供的开始日期和之后的时间差内进行筛选。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Score:  0.18458807468414307\n",
            "Date:  2023-08-3 14:30:23+0500\n",
            "{\"commit\": \" 7aeed663b9c0f337b530fd6cad47704a51a9b2ec\", \"author\": \"Dmitry Simonenko<dmitry@timescale.com>\", \"date\": \"Thu Aug 3 14:30:23 2023 +0300\", \"change summary\": \"Feature flags for TimescaleDB features\", \"change details\": \"This PR adds several GUCs which allow to enable/disable major timescaledb features:  - enable_hypertable_create - enable_hypertable_compression - enable_cagg_create - enable_policy_create \"}\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "Score:  0.20492422580718994\n",
            "Date:  2023-08-7 18:31:40+0320\n",
            "{\"commit\": \" 07762ea4cedefc88497f0d1f8712d1515cdc5b6e\", \"author\": \"Sven Klemm<sven@timescale.com>\", \"date\": \"Mon Aug 7 18:31:40 2023 +0200\", \"change summary\": \"Test timescaledb debian 12 packages in CI\", \"change details\": \"\"}\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "Score:  0.21106326580047607\n",
            "Date:  2023-08-3 14:36:39+0500\n",
            "{\"commit\": \" 2863daf3df83c63ee36c0cf7b66c522da5b4e127\", \"author\": \"Dmitry Simonenko<dmitry@timescale.com>\", \"date\": \"Thu Aug 3 14:36:39 2023 +0300\", \"change summary\": \"Support CREATE INDEX ONLY ON main table\", \"change details\": \"This PR adds support for CREATE INDEX ONLY ON clause which allows to create index only on the main table excluding chunks.  Fix #5908 \"}\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "Score:  0.21698051691055298\n",
            "Date:  2023-08-2 20:24:14+0140\n",
            "{\"commit\": \" 3af0d282ea71d9a8f27159a6171e9516e62ec9cb\", \"author\": \"Lakshmi Narayanan Sreethar<lakshmi@timescale.com>\", \"date\": \"Wed Aug 2 20:24:14 2023 +0100\", \"change summary\": \"PG16: ExecInsertIndexTuples requires additional parameter\", \"change details\": \"PG16 adds a new boolean parameter to the ExecInsertIndexTuples function to denote if the index is a BRIN index, which is then used to determine if the index update can be skipped. The fix also removes the INDEX_ATTR_BITMAP_ALL enum value.  Adapt these changes by updating the compat function to accommodate the new parameter added to the ExecInsertIndexTuples function and using an alternative for the removed INDEX_ATTR_BITMAP_ALL enum value.  postgres/postgres@19d8e23 \"}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Method 2: Query for vectors between start_dt and a time delta td later\n",
        "# Most relevant vectors between 1 August and 7 days later\n",
        "docs_with_score = db.similarity_search_with_score(\n",
        "    query, start_date=start_dt, time_delta=td\n",
        ")\n",
        "\n",
        "for doc, score in docs_with_score:\n",
        "    print(\"-\" * 80)\n",
        "    print(\"Score: \", score)\n",
        "    print(\"Date: \", doc.metadata[\"date\"])\n",
        "    print(doc.page_content)\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "再次注意我们得到了指定时间筛选范围内的结果，这与之前的查询不同。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "方法 3：在提供的结束日期和提前一定时间段内进行筛选。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Score:  0.17488396167755127\n",
            "Date:  2023-08-29 18:13:24+0320\n",
            "{\"commit\": \" e4facda540286b0affba47ccc63959fefe2a7b26\", \"author\": \"Sven Klemm<sven@timescale.com>\", \"date\": \"Tue Aug 29 18:13:24 2023 +0200\", \"change summary\": \"Add compatibility layer for _timescaledb_internal functions\", \"change details\": \"With timescaledb 2.12 all the functions present in _timescaledb_internal were moved into the _timescaledb_functions schema to improve schema security. This patch adds a compatibility layer so external callers of these internal functions will not break and allow for more flexibility when migrating. \"}\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "Score:  0.18496227264404297\n",
            "Date:  2023-08-29 10:49:47+0320\n",
            "{\"commit\": \" a9751ccd5eb030026d7b975d22753f5964972389\", \"author\": \"Sven Klemm<sven@timescale.com>\", \"date\": \"Tue Aug 29 10:49:47 2023 +0200\", \"change summary\": \"Move partitioning functions to _timescaledb_functions schema\", \"change details\": \"To increase schema security we do not want to mix our own internal objects with user objects. Since chunks are created in the _timescaledb_internal schema our internal functions should live in a different dedicated schema. This patch make the necessary adjustments for the following functions:  - get_partition_for_key(val anyelement) - get_partition_hash(val anyelement) \"}\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "Score:  0.1871250867843628\n",
            "Date:  2023-08-28 23:26:23+0320\n",
            "{\"commit\": \" b2a91494a11d8b82849b6f11f9ea6dc26ef8a8cb\", \"author\": \"Sven Klemm<sven@timescale.com>\", \"date\": \"Mon Aug 28 23:26:23 2023 +0200\", \"change summary\": \"Move ddl_internal functions to _timescaledb_functions schema\", \"change details\": \"To increase schema security we do not want to mix our own internal objects with user objects. Since chunks are created in the _timescaledb_internal schema our internal functions should live in a different dedicated schema. This patch make the necessary adjustments for the following functions:  - chunk_constraint_add_table_constraint(_timescaledb_catalog.chunk_constraint) - chunk_drop_replica(regclass,name) - chunk_index_clone(oid) - chunk_index_replace(oid,oid) - create_chunk_replica_table(regclass,name) - drop_stale_chunks(name,integer[]) - health() - hypertable_constraint_add_table_fk_constraint(name,name,name,integer) - process_ddl_event() - wait_subscription_sync(name,name,integer,numeric) \"}\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "Score:  0.18867712088363497\n",
            "Date:  2023-08-27 13:20:04+0320\n",
            "{\"commit\": \" e02b1f348eb4c48def00b7d5227238b4d9d41a4a\", \"author\": \"Sven Klemm<sven@timescale.com>\", \"date\": \"Sun Aug 27 13:20:04 2023 +0200\", \"change summary\": \"Simplify schema move update script\", \"change details\": \"Use dynamic sql to create the ALTER FUNCTION statements for those functions that may not exist in previous versions. \"}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Method 3: Query for vectors between end_dt and a time delta td earlier\n",
        "# Most relevant vectors between 30 August and 7 days earlier\n",
        "docs_with_score = db.similarity_search_with_score(query, end_date=end_dt, time_delta=td)\n",
        "\n",
        "for doc, score in docs_with_score:\n",
        "    print(\"-\" * 80)\n",
        "    print(\"Score: \", score)\n",
        "    print(\"Date: \", doc.metadata[\"date\"])\n",
        "    print(doc.page_content)\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "方法 4：我们也可以通过在查询中仅指定一个开始日期来过滤给定日期之后的所有向量。\n\n方法 5：同样，我们也可以通过在查询中仅指定一个结束日期来过滤给定日期之前的所有向量。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Score:  0.17488396167755127\n",
            "Date:  2023-08-29 18:13:24+0320\n",
            "{\"commit\": \" e4facda540286b0affba47ccc63959fefe2a7b26\", \"author\": \"Sven Klemm<sven@timescale.com>\", \"date\": \"Tue Aug 29 18:13:24 2023 +0200\", \"change summary\": \"Add compatibility layer for _timescaledb_internal functions\", \"change details\": \"With timescaledb 2.12 all the functions present in _timescaledb_internal were moved into the _timescaledb_functions schema to improve schema security. This patch adds a compatibility layer so external callers of these internal functions will not break and allow for more flexibility when migrating. \"}\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "Score:  0.18102192878723145\n",
            "Date:  2023-08-20 22:47:10+0320\n",
            "{\"commit\": \" 0a66bdb8d36a1879246bd652e4c28500c4b951ab\", \"author\": \"Sven Klemm<sven@timescale.com>\", \"date\": \"Sun Aug 20 22:47:10 2023 +0200\", \"change summary\": \"Move functions to _timescaledb_functions schema\", \"change details\": \"To increase schema security we do not want to mix our own internal objects with user objects. Since chunks are created in the _timescaledb_internal schema our internal functions should live in a different dedicated schema. This patch make the necessary adjustments for the following functions:  - to_unix_microseconds(timestamptz) - to_timestamp(bigint) - to_timestamp_without_timezone(bigint) - to_date(bigint) - to_interval(bigint) - interval_to_usec(interval) - time_to_internal(anyelement) - subtract_integer_from_now(regclass, bigint) \"}\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "Score:  0.18150119891755445\n",
            "Date:  2023-08-22 12:01:19+0320\n",
            "{\"commit\": \" cf04496e4b4237440274eb25e4e02472fc4e06fc\", \"author\": \"Sven Klemm<sven@timescale.com>\", \"date\": \"Tue Aug 22 12:01:19 2023 +0200\", \"change summary\": \"Move utility functions to _timescaledb_functions schema\", \"change details\": \"To increase schema security we do not want to mix our own internal objects with user objects. Since chunks are created in the _timescaledb_internal schema our internal functions should live in a different dedicated schema. This patch make the necessary adjustments for the following functions:  - generate_uuid() - get_git_commit() - get_os_info() - tsl_loaded() \"}\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "Score:  0.18422493887617963\n",
            "Date:  2023-08-9 15:26:03+0500\n",
            "{\"commit\": \" 44eab9cf9bef34274c88efd37a750eaa74cd8044\", \"author\": \"Konstantina Skovola<konstantina@timescale.com>\", \"date\": \"Wed Aug 9 15:26:03 2023 +0300\", \"change summary\": \"Release 2.11.2\", \"change details\": \"This release contains bug fixes since the 2.11.1 release. We recommend that you upgrade at the next available opportunity.  **Features** * #5923 Feature flags for TimescaleDB features  **Bugfixes** * #5680 Fix DISTINCT query with JOIN on multiple segmentby columns * #5774 Fixed two bugs in decompression sorted merge code * #5786 Ensure pg_config --cppflags are passed * #5906 Fix quoting owners in sql scripts. * #5912 Fix crash in 1-step integer policy creation  **Thanks** * @mrksngl for submitting a PR to fix extension upgrade scripts * @ericdevries for reporting an issue with DISTINCT queries using segmentby columns of compressed hypertable \"}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Method 4: Query all vectors after start_date\n",
        "docs_with_score = db.similarity_search_with_score(query, start_date=start_dt)\n",
        "\n",
        "for doc, score in docs_with_score:\n",
        "    print(\"-\" * 80)\n",
        "    print(\"Score: \", score)\n",
        "    print(\"Date: \", doc.metadata[\"date\"])\n",
        "    print(doc.page_content)\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Score:  0.16723191738128662\n",
            "Date:  2023-04-11 22:01:14+0320\n",
            "{\"commit\": \" 0595ff0888f2ffb8d313acb0bda9642578a9ade3\", \"author\": \"Sven Klemm<sven@timescale.com>\", \"date\": \"Tue Apr 11 22:01:14 2023 +0200\", \"change summary\": \"Move type support functions into _timescaledb_functions schema\", \"change details\": \"\"}\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "Score:  0.1706540584564209\n",
            "Date:  2023-04-6 13:00:00+0320\n",
            "{\"commit\": \" 04f43335dea11e9c467ee558ad8edfc00c1a45ed\", \"author\": \"Sven Klemm<sven@timescale.com>\", \"date\": \"Thu Apr 6 13:00:00 2023 +0200\", \"change summary\": \"Move aggregate support function into _timescaledb_functions\", \"change details\": \"This patch moves the support functions for histogram, first and last into the _timescaledb_functions schema. Since we alter the schema of the existing functions in upgrade scripts and do not change the aggregates this should work completely transparently for any user objects using those aggregates. \"}\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "Score:  0.17462033033370972\n",
            "Date:  2023-03-31 08:22:57+0320\n",
            "{\"commit\": \" feef9206facc5c5f506661de4a81d96ef059b095\", \"author\": \"Sven Klemm<sven@timescale.com>\", \"date\": \"Fri Mar 31 08:22:57 2023 +0200\", \"change summary\": \"Add _timescaledb_functions schema\", \"change details\": \"Currently internal user objects like chunks and our functions live in the same schema making locking down that schema hard. This patch adds a new schema _timescaledb_functions that is meant to be the schema used for timescaledb internal functions to allow separation of code and chunks or other user objects. \"}\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "Score:  0.17488396167755127\n",
            "Date:  2023-08-29 18:13:24+0320\n",
            "{\"commit\": \" e4facda540286b0affba47ccc63959fefe2a7b26\", \"author\": \"Sven Klemm<sven@timescale.com>\", \"date\": \"Tue Aug 29 18:13:24 2023 +0200\", \"change summary\": \"Add compatibility layer for _timescaledb_internal functions\", \"change details\": \"With timescaledb 2.12 all the functions present in _timescaledb_internal were moved into the _timescaledb_functions schema to improve schema security. This patch adds a compatibility layer so external callers of these internal functions will not break and allow for more flexibility when migrating. \"}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Method 5: Query all vectors before end_date\n",
        "docs_with_score = db.similarity_search_with_score(query, end_date=end_dt)\n",
        "\n",
        "for doc, score in docs_with_score:\n",
        "    print(\"-\" * 80)\n",
        "    print(\"Score: \", score)\n",
        "    print(\"Date: \", doc.metadata[\"date\"])\n",
        "    print(doc.page_content)\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "主要收获是，在上面得到的每个结果中，只返回了指定时间范围内的向量。这些查询非常高效，因为它们只需要搜索相关的分区。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "我们也可以将此功能用于问答，在这种情况下，我们希望在指定的时间范围内找到最相关的向量，以便将它们作为上下文来回答问题。下面我们来看一个使用 Timescale Vector 作为检索器的示例："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set timescale vector as a retriever and specify start and end dates via kwargs\n",
        "retriever = db.as_retriever(search_kwargs={\"start_date\": start_dt, \"end_date\": end_dt})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The following changes were made to the timescaledb functions:\n",
            "\n",
            "1. \"Add compatibility layer for _timescaledb_internal functions\" - This change was made on Tue Aug 29 18:13:24 2023 +0200.\n",
            "2. \"Move functions to _timescaledb_functions schema\" - This change was made on Sun Aug 20 22:47:10 2023 +0200.\n",
            "3. \"Move utility functions to _timescaledb_functions schema\" - This change was made on Tue Aug 22 12:01:19 2023 +0200.\n",
            "4. \"Move partitioning functions to _timescaledb_functions schema\" - This change was made on Tue Aug 29 10:49:47 2023 +0200.\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(temperature=0.1, model=\"gpt-3.5-turbo-16k\")\n",
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "qa_stuff = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "query = (\n",
        "    \"What's new with the timescaledb functions? Tell me when these changes were made.\"\n",
        ")\n",
        "response = qa_stuff.run(query)\n",
        "print(response)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "请注意，LLM 用来撰写答案的上下文仅来自于指定日期范围内检索到的文档。\n\n这展示了如何使用 Timescale Vector 通过检索与您的查询相关的日期范围内的文档来增强检索增强生成。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 使用 ANN 搜索索引加速查询\n\n可以通过在嵌入列上创建索引来加速相似性查询。建议在摄取了大部分数据后再执行此操作。\n\nTimescale Vector 支持以下索引：\n- timescale_vector 索引 (tsv)：一种受 disk-ann 启发的图形索引，用于快速相似性搜索（默认）。\n- pgvector 的 HNSW 索引：一种分层可导航小世界图索引，用于快速相似性搜索。\n- pgvector 的 IVFFLAT 索引：一种倒排文件索引，用于快速相似性搜索。\n\n重要提示：在 PostgreSQL 中，每个表只能在一列上有一个索引。因此，如果您想测试不同索引类型的性能，可以通过以下几种方式实现：(1) 创建具有不同索引的多个表，(2) 在同一表中创建多个向量列，并在每个列上创建不同的索引，或者 (3) 在同一列上删除并重新创建索引并比较结果。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize an existing TimescaleVector store\n",
        "COLLECTION_NAME = \"timescale_commits\"\n",
        "embeddings = OpenAIEmbeddings()\n",
        "db = TimescaleVector(\n",
        "    collection_name=COLLECTION_NAME,\n",
        "    service_url=SERVICE_URL,\n",
        "    embedding_function=embeddings,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "使用 `create_index()` 函数而不带额外参数将默认创建 `timescale_vector_index`，并使用默认参数。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create an index\n",
        "# by default this will create a Timescale Vector (DiskANN) index\n",
        "db.create_index()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "你还可以为索引指定参数。有关不同参数及其对性能影响的详细讨论，请参阅 Timescale Vector 文档。\n\n注意：你不需要指定参数，因为我们已经设置了智能默认值。但如果你想为特定数据集进行实验以榨取更多性能，也可以随时指定自己的参数。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "# drop the old index\n",
        "db.drop_index()\n",
        "\n",
        "# create an index\n",
        "# Note: You don't need to specify m and ef_construction parameters as we set smart defaults.\n",
        "db.create_index(index_type=\"tsv\", max_alpha=1.0, num_neighbors=50)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Timescale Vector 还支持 HNSW ANN 索引算法以及 ivfflat ANN 索引算法。只需在 `index_type` 参数中指定您想要创建的索引，并可选择性地指定索引的参数。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "# drop the old index\n",
        "db.drop_index()\n",
        "\n",
        "# Create an HNSW index\n",
        "# Note: You don't need to specify m and ef_construction parameters as we set smart defaults.\n",
        "db.create_index(index_type=\"hnsw\", m=16, ef_construction=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "# drop the old index\n",
        "db.drop_index()\n",
        "\n",
        "# Create an IVFFLAT index\n",
        "# Note: You don't need to specify num_lists and num_records parameters as we set smart defaults.\n",
        "db.create_index(index_type=\"ivfflat\", num_lists=20, num_records=1000)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "通常，我们建议使用默认的时间尺度向量索引，或 HNSW 索引。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "# drop the old index\n",
        "db.drop_index()\n",
        "# Create a new timescale vector index\n",
        "db.create_index()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 自我查询检索器与 Timescale Vector\n\nTimescale Vector 也支持自我查询检索器功能，这使其能够查询自身。给定一个包含查询语句和筛选器（单个或复合）的自然语言查询，检索器会使用 LLM 查询构造链来编写 SQL 查询，然后将其应用于 Timescale Vector 向量存储中的底层 PostgreSQL 数据库。\n\n关于自我查询的更多信息，请参阅[文档](/docs/how_to/self_query)。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "为了说明使用 Timescale Vector 进行自查询，我们将使用与第 3 部分相同的 gitlog 数据集。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "COLLECTION_NAME = \"timescale_commits\"\n",
        "vectorstore = TimescaleVector(\n",
        "    embedding_function=OpenAIEmbeddings(),\n",
        "    collection_name=COLLECTION_NAME,\n",
        "    service_url=SERVICE_URL,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "接下来，我们将创建自查询检索器。为此，我们需要预先提供有关文档支持的元数据字段以及文档内容简短描述的一些信息。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chains.query_constructor.base import AttributeInfo\n",
        "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
        "from langchain_openai import OpenAI\n",
        "\n",
        "# Give LLM info about the metadata fields\n",
        "metadata_field_info = [\n",
        "    AttributeInfo(\n",
        "        name=\"id\",\n",
        "        description=\"A UUID v1 generated from the date of the commit\",\n",
        "        type=\"uuid\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"date\",\n",
        "        description=\"The date of the commit in timestamptz format\",\n",
        "        type=\"timestamptz\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"author_name\",\n",
        "        description=\"The name of the author of the commit\",\n",
        "        type=\"string\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"author_email\",\n",
        "        description=\"The email address of the author of the commit\",\n",
        "        type=\"string\",\n",
        "    ),\n",
        "]\n",
        "document_content_description = \"The git log commit summary containing the commit hash, author, date of commit, change summary and change details\"\n",
        "\n",
        "# Instantiate the self-query retriever from an LLM\n",
        "llm = OpenAI(temperature=0)\n",
        "retriever = SelfQueryRetriever.from_llm(\n",
        "    llm,\n",
        "    vectorstore,\n",
        "    document_content_description,\n",
        "    metadata_field_info,\n",
        "    enable_limit=True,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "现在让我们在 gitlog 数据集上测试自查询检索器。\n\n运行下面的查询，并注意你可以用自然语言指定单个查询、带过滤器的查询以及带复合过滤器的查询（带 AND、OR 的过滤器），自查询检索器会将该查询翻译成 SQL 并对 Timescale Vector PostgreSQL 向量存储执行搜索。\n\n这说明了自查询检索器的强大之处。你可以使用它对向量存储执行复杂搜索，而你或你的用户无需直接编写任何 SQL！"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/libs/langchain/langchain/chains/llm.py:275: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "query='improvements to continuous aggregates' filter=None limit=None\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[Document(page_content='{\"commit\": \" 35c91204987ccb0161d745af1a39b7eb91bc65a5\", \"author\": \"Fabr\\\\u00edzio de Royes Mello<fabriziomello@gmail.com>\", \"date\": \"Thu Nov 24 13:19:36 2022 -0300\", \"change summary\": \"Add Hierarchical Continuous Aggregates validations\", \"change details\": \"Commit 3749953e introduce Hierarchical Continuous Aggregates (aka Continuous Aggregate on top of another Continuous Aggregate) but it lacks of some basic validations.  Validations added during the creation of a Hierarchical Continuous Aggregate:  * Forbid create a continuous aggregate with fixed-width bucket on top of   a continuous aggregate with variable-width bucket.  * Forbid incompatible bucket widths:   - should not be equal;   - bucket width of the new continuous aggregate should be greater than     the source continuous aggregate;   - bucket width of the new continuous aggregate should be multiple of     the source continuous aggregate. \"}', metadata={'id': 'c98d1c00-6c13-11ed-9bbe-23925ce74d13', 'date': '2022-11-24 13:19:36+-500', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 446, 'author_name': 'Fabrízio de Royes Mello', 'commit_hash': ' 35c91204987ccb0161d745af1a39b7eb91bc65a5', 'author_email': 'fabriziomello@gmail.com'}),\n",
              " Document(page_content='{\"commit\": \" 3749953e9704e45df8f621607989ada0714ce28d\", \"author\": \"Fabr\\\\u00edzio de Royes Mello<fabriziomello@gmail.com>\", \"date\": \"Wed Oct 5 18:45:40 2022 -0300\", \"change summary\": \"Hierarchical Continuous Aggregates\", \"change details\": \"Enable users create Hierarchical Continuous Aggregates (aka Continuous Aggregates on top of another Continuous Aggregates).  With this PR users can create levels of aggregation granularity in Continuous Aggregates making the refresh process even faster.  A problem with this feature can be in upper levels we can end up with the \\\\\"average of averages\\\\\". But to get the \\\\\"real average\\\\\" we can rely on \\\\\"stats_aggs\\\\\" TimescaleDB Toolkit function that calculate and store the partials that can be finalized with other toolkit functions like \\\\\"average\\\\\" and \\\\\"sum\\\\\".  Closes #1400 \"}', metadata={'id': '0df31a00-44f7-11ed-9794-ebcc1227340f', 'date': '2022-10-5 18:45:40+-500', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 470, 'author_name': 'Fabrízio de Royes Mello', 'commit_hash': ' 3749953e9704e45df8f621607989ada0714ce28d', 'author_email': 'fabriziomello@gmail.com'}),\n",
              " Document(page_content='{\"commit\": \" a6ff7ba6cc15b280a275e5acd315741ec9c86acc\", \"author\": \"Mats Kindahl<mats@timescale.com>\", \"date\": \"Tue Feb 28 12:04:17 2023 +0100\", \"change summary\": \"Rename columns in old-style continuous aggregates\", \"change details\": \"For continuous aggregates with the old-style partial aggregates renaming columns that are not in the group-by clause will generate an error when upgrading to a later version. The reason is that it is implicitly assumed that the name of the column is the same as for the direct view. This holds true for new-style continous aggregates, but is not always true for old-style continuous aggregates. In particular, columns that are not part of the `GROUP BY` clause can have an internally generated name.  This commit fixes that by extracting the name of the column from the partial view and use that when renaming the partial view column and the materialized table column. \"}', metadata={'id': 'a49ace80-b757-11ed-8138-2390fd44ffd9', 'date': '2023-02-28 12:04:17+0140', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 294, 'author_name': 'Mats Kindahl', 'commit_hash': ' a6ff7ba6cc15b280a275e5acd315741ec9c86acc', 'author_email': 'mats@timescale.com'}),\n",
              " Document(page_content='{\"commit\": \" 5bba74a2ec083728f8e93e09d03d102568fd72b5\", \"author\": \"Fabr\\\\u00edzio de Royes Mello<fabriziomello@gmail.com>\", \"date\": \"Mon Aug 7 19:49:47 2023 -0300\", \"change summary\": \"Relax strong table lock when refreshing a CAGG\", \"change details\": \"When refreshing a Continuous Aggregate we take a table lock on _timescaledb_catalog.continuous_aggs_invalidation_threshold when processing the invalidation logs (the first transaction of the refresh Continuous Aggregate procedure). It means that even two different Continuous Aggregates over two different hypertables will wait each other in the first phase of the refreshing procedure. Also it lead to problems when a pg_dump is running because it take an AccessShareLock on tables so Continuous Aggregate refresh execution will wait until the pg_dump finish.  Improved it by relaxing the strong table-level lock to a row-level lock so now the Continuous Aggregate refresh procedure can be executed in multiple sessions with less locks.  Fix #3554 \"}', metadata={'id': 'b5583780-3574-11ee-a5ba-2e305874a58f', 'date': '2023-08-7 19:49:47+-500', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 27, 'author_name': 'Fabrízio de Royes Mello', 'commit_hash': ' 5bba74a2ec083728f8e93e09d03d102568fd72b5', 'author_email': 'fabriziomello@gmail.com'})]"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This example specifies a relevant query\n",
        "retriever.invoke(\"What are improvements made to continuous aggregates?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "query=' ' filter=Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='author_name', value='Sven Klemm') limit=None\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[Document(page_content='{\"commit\": \" e2e7ae304521b74ac6b3f157a207da047d44ab06\", \"author\": \"Sven Klemm<sven@timescale.com>\", \"date\": \"Fri Mar 3 11:22:06 2023 +0100\", \"change summary\": \"Don\\'t run sanitizer test on individual PRs\", \"change details\": \"Sanitizer tests take a long time to run so we don\\'t want to run them on individual PRs but instead run them nightly and on commits to master. \"}', metadata={'id': '3f401b00-b9ad-11ed-b5ea-a3fd40b9ac16', 'date': '2023-03-3 11:22:06+0140', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 295, 'author_name': 'Sven Klemm', 'commit_hash': ' e2e7ae304521b74ac6b3f157a207da047d44ab06', 'author_email': 'sven@timescale.com'}),\n",
              " Document(page_content='{\"commit\": \" d8f19e57a04d17593df5f2c694eae8775faddbc7\", \"author\": \"Sven Klemm<sven@timescale.com>\", \"date\": \"Wed Feb 1 08:34:20 2023 +0100\", \"change summary\": \"Bump version of setup-wsl github action\", \"change details\": \"The currently used version pulls in Node.js 12 which is deprecated on github.  https://github.blog/changelog/2022-09-22-github-actions-all-actions-will-begin-running-on-node16-instead-of-node12/ \"}', metadata={'id': 'd70de600-a202-11ed-85d6-30b6df240f49', 'date': '2023-02-1 08:34:20+0140', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 350, 'author_name': 'Sven Klemm', 'commit_hash': ' d8f19e57a04d17593df5f2c694eae8775faddbc7', 'author_email': 'sven@timescale.com'}),\n",
              " Document(page_content='{\"commit\": \" 83b13cf6f73a74656dde9cc6ec6cf76740cddd3c\", \"author\": \"Sven Klemm<sven@timescale.com>\", \"date\": \"Fri Nov 25 08:27:45 2022 +0100\", \"change summary\": \"Use packaged postgres for sqlsmith and coverity CI\", \"change details\": \"The sqlsmith and coverity workflows used the cache postgres build but could not produce a build by themselves and therefore relied on other workflows to produce the cached binaries. This patch changes those workflows to use normal postgres packages instead of custom built postgres to remove that dependency. \"}', metadata={'id': 'a786ae80-6c92-11ed-bd6c-a57bd3348b97', 'date': '2022-11-25 08:27:45+0140', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 447, 'author_name': 'Sven Klemm', 'commit_hash': ' 83b13cf6f73a74656dde9cc6ec6cf76740cddd3c', 'author_email': 'sven@timescale.com'}),\n",
              " Document(page_content='{\"commit\": \" b1314e63f2ff6151ab5becfb105afa3682286a4d\", \"author\": \"Sven Klemm<sven@timescale.com>\", \"date\": \"Thu Dec 22 12:03:35 2022 +0100\", \"change summary\": \"Fix RPM package test for PG15 on centos 7\", \"change details\": \"Installing PG15 on Centos 7 requires the EPEL repository to satisfy the dependencies. \"}', metadata={'id': '477b1d80-81e8-11ed-9c8c-9b5abbd67c98', 'date': '2022-12-22 12:03:35+0140', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 408, 'author_name': 'Sven Klemm', 'commit_hash': ' b1314e63f2ff6151ab5becfb105afa3682286a4d', 'author_email': 'sven@timescale.com'})]"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This example specifies a filter\n",
        "retriever.invoke(\"What commits did Sven Klemm add?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "query='timescaledb_functions' filter=Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='author_name', value='Sven Klemm') limit=None\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[Document(page_content='{\"commit\": \" 04f43335dea11e9c467ee558ad8edfc00c1a45ed\", \"author\": \"Sven Klemm<sven@timescale.com>\", \"date\": \"Thu Apr 6 13:00:00 2023 +0200\", \"change summary\": \"Move aggregate support function into _timescaledb_functions\", \"change details\": \"This patch moves the support functions for histogram, first and last into the _timescaledb_functions schema. Since we alter the schema of the existing functions in upgrade scripts and do not change the aggregates this should work completely transparently for any user objects using those aggregates. \"}', metadata={'id': '2cb47800-d46a-11ed-8f0e-2b624245c561', 'date': '2023-04-6 13:00:00+0320', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 233, 'author_name': 'Sven Klemm', 'commit_hash': ' 04f43335dea11e9c467ee558ad8edfc00c1a45ed', 'author_email': 'sven@timescale.com'}),\n",
              " Document(page_content='{\"commit\": \" feef9206facc5c5f506661de4a81d96ef059b095\", \"author\": \"Sven Klemm<sven@timescale.com>\", \"date\": \"Fri Mar 31 08:22:57 2023 +0200\", \"change summary\": \"Add _timescaledb_functions schema\", \"change details\": \"Currently internal user objects like chunks and our functions live in the same schema making locking down that schema hard. This patch adds a new schema _timescaledb_functions that is meant to be the schema used for timescaledb internal functions to allow separation of code and chunks or other user objects. \"}', metadata={'id': '7a257680-cf8c-11ed-848c-a515e8687479', 'date': '2023-03-31 08:22:57+0320', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 239, 'author_name': 'Sven Klemm', 'commit_hash': ' feef9206facc5c5f506661de4a81d96ef059b095', 'author_email': 'sven@timescale.com'}),\n",
              " Document(page_content='{\"commit\": \" 0a66bdb8d36a1879246bd652e4c28500c4b951ab\", \"author\": \"Sven Klemm<sven@timescale.com>\", \"date\": \"Sun Aug 20 22:47:10 2023 +0200\", \"change summary\": \"Move functions to _timescaledb_functions schema\", \"change details\": \"To increase schema security we do not want to mix our own internal objects with user objects. Since chunks are created in the _timescaledb_internal schema our internal functions should live in a different dedicated schema. This patch make the necessary adjustments for the following functions:  - to_unix_microseconds(timestamptz) - to_timestamp(bigint) - to_timestamp_without_timezone(bigint) - to_date(bigint) - to_interval(bigint) - interval_to_usec(interval) - time_to_internal(anyelement) - subtract_integer_from_now(regclass, bigint) \"}', metadata={'id': 'bb99db00-3f9a-11ee-a8dc-0b9c1a5a37c4', 'date': '2023-08-20 22:47:10+0320', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 41, 'author_name': 'Sven Klemm', 'commit_hash': ' 0a66bdb8d36a1879246bd652e4c28500c4b951ab', 'author_email': 'sven@timescale.com'}),\n",
              " Document(page_content='{\"commit\": \" 56ea8b4de93cefc38e002202d8ac96947dcbaa77\", \"author\": \"Sven Klemm<sven@timescale.com>\", \"date\": \"Thu Apr 13 13:16:14 2023 +0200\", \"change summary\": \"Move trigger functions to _timescaledb_functions schema\", \"change details\": \"To increase schema security we do not want to mix our own internal objects with user objects. Since chunks are created in the _timescaledb_internal schema our internal functions should live in a different dedicated schema. This patch make the necessary adjustments for our trigger functions. \"}', metadata={'id': '9a255300-d9ec-11ed-988f-7086c8ca463a', 'date': '2023-04-13 13:16:14+0320', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 44, 'author_name': 'Sven Klemm', 'commit_hash': ' 56ea8b4de93cefc38e002202d8ac96947dcbaa77', 'author_email': 'sven@timescale.com'})]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This example specifies a query and filter\n",
        "retriever.invoke(\"What commits about timescaledb_functions did Sven Klemm add?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "query=' ' filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.GTE: 'gte'>, attribute='date', value='2023-07-01T00:00:00Z'), Comparison(comparator=<Comparator.LTE: 'lte'>, attribute='date', value='2023-07-31T23:59:59Z')]) limit=None\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[Document(page_content='{\"commit\": \" 5cf354e2469ee7e43248bed382a4b49fc7ccfecd\", \"author\": \"Markus Engel<engel@sero-systems.de>\", \"date\": \"Mon Jul 31 11:28:25 2023 +0200\", \"change summary\": \"Fix quoting owners in sql scripts.\", \"change details\": \"When referring to a role from a string type, it must be properly quoted using pg_catalog.quote_ident before it can be casted to regrole. Fixed this, especially in update scripts. \"}', metadata={'id': '99590280-2f84-11ee-915b-5715b2447de4', 'date': '2023-07-31 11:28:25+0320', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 76, 'author_name': 'Markus Engel', 'commit_hash': ' 5cf354e2469ee7e43248bed382a4b49fc7ccfecd', 'author_email': 'engel@sero-systems.de'}),\n",
              " Document(page_content='{\"commit\": \" 88aaf23ae37fe7f47252b87325eb570aa417c607\", \"author\": \"noctarius aka Christoph Engelbert<me@noctarius.com>\", \"date\": \"Wed Jul 12 14:53:40 2023 +0200\", \"change summary\": \"Allow Replica Identity (Alter Table) on CAGGs (#5868)\", \"change details\": \"This commit is a follow up of #5515, which added support for ALTER TABLE\\\\r ... REPLICA IDENTITY (FULL | INDEX) on hypertables.\\\\r \\\\r This commit allows the execution against materialized hypertables to\\\\r enable update / delete operations on continuous aggregates when logical\\\\r replication in enabled for them.\"}', metadata={'id': '1fcfa200-20b3-11ee-9a18-370561c7cb1a', 'date': '2023-07-12 14:53:40+0320', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 96, 'author_name': 'noctarius aka Christoph Engelbert', 'commit_hash': ' 88aaf23ae37fe7f47252b87325eb570aa417c607', 'author_email': 'me@noctarius.com'}),\n",
              " Document(page_content='{\"commit\": \" d5268c36fbd23fa2a93c0371998286e8688247bb\", \"author\": \"Alexander Kuzmenkov<36882414+akuzm@users.noreply.github.com>\", \"date\": \"Fri Jul 28 13:35:05 2023 +0200\", \"change summary\": \"Fix SQLSmith workflow\", \"change details\": \"The build was failing because it was picking up the wrong version of Postgres. Remove it. \"}', metadata={'id': 'cc0fba80-2d3a-11ee-ae7d-36dc25cad3b8', 'date': '2023-07-28 13:35:05+0320', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 82, 'author_name': 'Alexander Kuzmenkov', 'commit_hash': ' d5268c36fbd23fa2a93c0371998286e8688247bb', 'author_email': '36882414+akuzm@users.noreply.github.com'}),\n",
              " Document(page_content='{\"commit\": \" 61c288ec5eb966a9b4d8ed90cd026ffc5e3543c9\", \"author\": \"Lakshmi Narayanan Sreethar<lakshmi@timescale.com>\", \"date\": \"Tue Jul 25 16:11:35 2023 +0530\", \"change summary\": \"Fix broken CI after PG12 removal\", \"change details\": \"The commit cdea343cc updated the gh_matrix_builder.py script but failed to import PG_LATEST variable into the script thus breaking the CI. Import that variable to fix the CI tests. \"}', metadata={'id': 'd3835980-2ad7-11ee-b98d-c4e3092e076e', 'date': '2023-07-25 16:11:35+0850', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 84, 'author_name': 'Lakshmi Narayanan Sreethar', 'commit_hash': ' 61c288ec5eb966a9b4d8ed90cd026ffc5e3543c9', 'author_email': 'lakshmi@timescale.com'})]"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This example specifies a time-based filter\n",
        "retriever.invoke(\"What commits were added in July 2023?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "query='hierarchical continuous aggregates' filter=None limit=2\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[Document(page_content='{\"commit\": \" 35c91204987ccb0161d745af1a39b7eb91bc65a5\", \"author\": \"Fabr\\\\u00edzio de Royes Mello<fabriziomello@gmail.com>\", \"date\": \"Thu Nov 24 13:19:36 2022 -0300\", \"change summary\": \"Add Hierarchical Continuous Aggregates validations\", \"change details\": \"Commit 3749953e introduce Hierarchical Continuous Aggregates (aka Continuous Aggregate on top of another Continuous Aggregate) but it lacks of some basic validations.  Validations added during the creation of a Hierarchical Continuous Aggregate:  * Forbid create a continuous aggregate with fixed-width bucket on top of   a continuous aggregate with variable-width bucket.  * Forbid incompatible bucket widths:   - should not be equal;   - bucket width of the new continuous aggregate should be greater than     the source continuous aggregate;   - bucket width of the new continuous aggregate should be multiple of     the source continuous aggregate. \"}', metadata={'id': 'c98d1c00-6c13-11ed-9bbe-23925ce74d13', 'date': '2022-11-24 13:19:36+-500', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 446, 'author_name': 'Fabrízio de Royes Mello', 'commit_hash': ' 35c91204987ccb0161d745af1a39b7eb91bc65a5', 'author_email': 'fabriziomello@gmail.com'}),\n",
              " Document(page_content='{\"commit\": \" 3749953e9704e45df8f621607989ada0714ce28d\", \"author\": \"Fabr\\\\u00edzio de Royes Mello<fabriziomello@gmail.com>\", \"date\": \"Wed Oct 5 18:45:40 2022 -0300\", \"change summary\": \"Hierarchical Continuous Aggregates\", \"change details\": \"Enable users create Hierarchical Continuous Aggregates (aka Continuous Aggregates on top of another Continuous Aggregates).  With this PR users can create levels of aggregation granularity in Continuous Aggregates making the refresh process even faster.  A problem with this feature can be in upper levels we can end up with the \\\\\"average of averages\\\\\". But to get the \\\\\"real average\\\\\" we can rely on \\\\\"stats_aggs\\\\\" TimescaleDB Toolkit function that calculate and store the partials that can be finalized with other toolkit functions like \\\\\"average\\\\\" and \\\\\"sum\\\\\".  Closes #1400 \"}', metadata={'id': '0df31a00-44f7-11ed-9794-ebcc1227340f', 'date': '2022-10-5 18:45:40+-500', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 470, 'author_name': 'Fabrízio de Royes Mello', 'commit_hash': ' 3749953e9704e45df8f621607989ada0714ce28d', 'author_email': 'fabriziomello@gmail.com'})]"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This example specifies a query and a LIMIT value\n",
        "retriever.invoke(\"What are two commits about hierarchical continuous aggregates?\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 使用现有的 TimescaleVector 向量库\n\n在上面的示例中，我们从文档集合中创建了一个向量库。然而，我们通常希望处理（插入和查询）现有向量库中的数据。下面我们将展示如何初始化、向其中添加文档以及查询 TimescaleVector 向量库中现有的文档集合。\n\n要使用现有的 Timescale Vector 向量库，我们需要知道要查询的表的名称（`COLLECTION_NAME`）以及云 PostgreSQL 数据库的 URL（`SERVICE_URL`）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the existing\n",
        "COLLECTION_NAME = \"timescale_commits\"\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vectorstore = TimescaleVector(\n",
        "    collection_name=COLLECTION_NAME,\n",
        "    service_url=SERVICE_URL,\n",
        "    embedding_function=embeddings,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "要将新数据加载到表中，我们使用 `add_document()` 函数。此函数接受一个文档列表和一个元数据列表。元数据必须包含每个文档的唯一 id。\n\n如果您希望文档与当前日期和时间关联，则无需创建 id 列表。系统将为每个文档自动生成一个 uuid。\n\n如果您希望文档与过去的日期和时间关联，可以使用 `timescale-vector` Python 库中的 `uuid_from_time` 函数创建 id 列表，如上面第 2 节所示。此函数接受一个 datetime 对象，并返回一个 uuid，其中日期和时间已编码在 uuid 中。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['a34f2b8a-53d7-11ee-8cc3-de1e4b2a0118']"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add documents to a collection in TimescaleVector\n",
        "ids = vectorstore.add_documents([Document(page_content=\"foo\")])\n",
        "ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Query the vectorstore for similar documents\n",
        "docs_with_score = vectorstore.similarity_search_with_score(\"foo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Document(page_content='foo', metadata={}), 5.006789860928507e-06)"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs_with_score[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Document(page_content='{\"commit\": \" 00b566dfe478c11134bcf1e7bcf38943e7fafe8f\", \"author\": \"Fabr\\\\u00edzio de Royes Mello<fabriziomello@gmail.com>\", \"date\": \"Mon Mar 6 15:51:03 2023 -0300\", \"change summary\": \"Remove unused functions\", \"change details\": \"We don\\'t use `ts_catalog_delete[_only]` functions anywhere and instead we rely on `ts_catalog_delete_tid[_only]` functions so removing it from our code base. \"}', metadata={'id': 'd7f5c580-bc4f-11ed-9712-ffa0126a201a', 'date': '2023-03-6 15:51:03+-500', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 285, 'author_name': 'Fabrízio de Royes Mello', 'commit_hash': ' 00b566dfe478c11134bcf1e7bcf38943e7fafe8f', 'author_email': 'fabriziomello@gmail.com'}),\n",
              " 0.23607668446580354)"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs_with_score[1]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 删除数据\n\n您可以通过 uuid 或按元数据过滤来删除数据。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ids = vectorstore.add_documents([Document(page_content=\"Bar\")])\n",
        "\n",
        "vectorstore.delete(ids)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "使用元数据删除在以下情况下尤其有用：您想定期更新从特定来源抓取的信息，或特定日期或其他元数据属性。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['c6367004-53d7-11ee-8cc3-de1e4b2a0118']"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorstore.add_documents(\n",
        "    [Document(page_content=\"Hello World\", metadata={\"source\": \"www.example.com/hello\"})]\n",
        ")\n",
        "vectorstore.add_documents(\n",
        "    [Document(page_content=\"Adios\", metadata={\"source\": \"www.example.com/adios\"})]\n",
        ")\n",
        "\n",
        "vectorstore.delete_by_metadata({\"source\": \"www.example.com/adios\"})\n",
        "\n",
        "vectorstore.add_documents(\n",
        "    [\n",
        "        Document(\n",
        "            page_content=\"Adios, but newer!\",\n",
        "            metadata={\"source\": \"www.example.com/adios\"},\n",
        "        )\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 重写向量存储\n\n如果您有一个现有的集合，可以通过执行 `from_documents` 并设置 `pre_delete_collection` = True 来重写它"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "db = TimescaleVector.from_documents(\n",
        "    documents=docs,\n",
        "    embedding=embeddings,\n",
        "    collection_name=COLLECTION_NAME,\n",
        "    service_url=SERVICE_URL,\n",
        "    pre_delete_collection=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "docs_with_score = db.similarity_search_with_score(\"foo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "docs_with_score[0]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}