{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "671e9ec1-fa00-4c92-a2fb-ceb142168ea9",
      "metadata": {},
      "source": [
        "# Jaguar 向量数据库\n\n1. 这是一个分布式向量数据库\n2. JaguarDB 的“ZeroMove”功能可实现即时水平扩展\n3. 多模态：嵌入、文本、图像、视频、PDF、音频、时间序列和地理空间\n4. 全主节点（All-masters）：支持并行读写\n5. 异常检测能力\n6. RAG 支持：将大型语言模型（LLM）与专有和实时数据相结合\n7. 共享元数据：跨多个向量索引共享元数据\n8. 距离度量：欧氏距离、余弦距离、内积、曼哈顿距离、切比雪夫距离、汉明距离、杰卡德距离、闵可夫斯基距离"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a87dc28-1344-4003-b31a-13e4cb71bf48",
      "metadata": {},
      "source": [
        "## 先决条件\n\n运行此文件中的示例有两个要求。\n1. 您必须安装并设置 JaguarDB 服务器及其 HTTP 网关服务器。\n   请参考以下说明：\n   [www.jaguardb.com](http://www.jaguardb.com)\n   在 Docker 环境中快速设置：\n   docker pull jaguardb/jaguardb_with_http\n   docker run -d -p 8888:8888 -p 8080:8080 --name jaguardb_with_http  jaguardb/jaguardb_with_http\n\n2. 您必须安装适用于 JaguarDB 的 HTTP 客户端包：\n   ```\n       pip install -U jaguardb-http-client\n   ```\n   \n3. 您需要安装 `langchain-community` (`pip install -qU langchain-community`) 才能使用此集成。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7d56993-4809-4e42-a409-94d3a7305ad8",
      "metadata": {},
      "source": [
        "## Langchain 结合 RAG\n\n本节将演示如何在 Langchain 软件栈中，与 LLM（大型语言模型）以及 Jaguar 进行对话。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d62c2393-5c7c-4bb6-8367-c4389fa36a4e",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_community.vectorstores.jaguar import Jaguar\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI, OpenAI, OpenAIEmbeddings\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "\n",
        "\"\"\" \n",
        "Load a text file into a set of documents \n",
        "\"\"\"\n",
        "loader = TextLoader(\"../../how_to/state_of_the_union.txt\")\n",
        "documents = loader.load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=300)\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n",
        "\"\"\"\n",
        "Instantiate a Jaguar vector store\n",
        "\"\"\"\n",
        "### Jaguar HTTP endpoint\n",
        "url = \"http://192.168.5.88:8080/fwww/\"\n",
        "\n",
        "### Use OpenAI embedding model\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "### Pod is a database for vectors\n",
        "pod = \"vdb\"\n",
        "\n",
        "### Vector store name\n",
        "store = \"langchain_rag_store\"\n",
        "\n",
        "### Vector index name\n",
        "vector_index = \"v\"\n",
        "\n",
        "### Type of the vector index\n",
        "# cosine: distance metric\n",
        "# fraction: embedding vectors are decimal numbers\n",
        "# float: values stored with floating-point numbers\n",
        "vector_type = \"cosine_fraction_float\"\n",
        "\n",
        "### Dimension of each embedding vector\n",
        "vector_dimension = 1536\n",
        "\n",
        "### Instantiate a Jaguar store object\n",
        "vectorstore = Jaguar(\n",
        "    pod, store, vector_index, vector_type, vector_dimension, url, embeddings\n",
        ")\n",
        "\n",
        "\"\"\"\n",
        "Login must be performed to authorize the client.\n",
        "The environment variable JAGUAR_API_KEY or file $HOME/.jagrc\n",
        "should contain the API key for accessing JaguarDB servers.\n",
        "\"\"\"\n",
        "vectorstore.login()\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Create vector store on the JaguarDB database server.\n",
        "This should be done only once.\n",
        "\"\"\"\n",
        "# Extra metadata fields for the vector store\n",
        "metadata = \"category char(16)\"\n",
        "\n",
        "# Number of characters for the text field of the store\n",
        "text_size = 4096\n",
        "\n",
        "#  Create a vector store on the server\n",
        "vectorstore.create(metadata, text_size)\n",
        "\n",
        "\"\"\"\n",
        "Add the texts from the text splitter to our vectorstore\n",
        "\"\"\"\n",
        "vectorstore.add_documents(docs)\n",
        "# or tag the documents:\n",
        "# vectorstore.add_documents(more_docs, text_tag=\"tags to these documents\")\n",
        "\n",
        "\"\"\" Get the retriever object \"\"\"\n",
        "retriever = vectorstore.as_retriever()\n",
        "# retriever = vectorstore.as_retriever(search_kwargs={\"where\": \"m1='123' and m2='abc'\"})\n",
        "\n",
        "template = \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
        "Question: {question}\n",
        "Context: {context}\n",
        "Answer:\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "\"\"\" Obtain a Large Language Model \"\"\"\n",
        "LLM = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "\"\"\" Create a chain for the RAG flow \"\"\"\n",
        "rag_chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | LLM\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "resp = rag_chain.invoke(\"What did the president say about Justice Breyer?\")\n",
        "print(resp)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11178867-d143-4a10-93bf-278f5f10dc1a",
      "metadata": {},
      "source": [
        "## 与 Jaguar 向量数据库的交互\n\n用户可以直接与 Jaguar 向量数据库进行交互，以进行相似性搜索和异常检测。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9a53cb5-e298-4125-9ace-0d851198869a",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores.jaguar import Jaguar\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# Instantiate a Jaguar vector store object\n",
        "url = \"http://192.168.3.88:8080/fwww/\"\n",
        "pod = \"vdb\"\n",
        "store = \"langchain_test_store\"\n",
        "vector_index = \"v\"\n",
        "vector_type = \"cosine_fraction_float\"\n",
        "vector_dimension = 10\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vectorstore = Jaguar(\n",
        "    pod, store, vector_index, vector_type, vector_dimension, url, embeddings\n",
        ")\n",
        "\n",
        "# Login for authorization\n",
        "vectorstore.login()\n",
        "\n",
        "# Create the vector store with two metadata fields\n",
        "# This needs to be run only once.\n",
        "metadata_str = \"author char(32), category char(16)\"\n",
        "vectorstore.create(metadata_str, 1024)\n",
        "\n",
        "# Add a list of texts\n",
        "texts = [\"foo\", \"bar\", \"baz\"]\n",
        "metadatas = [\n",
        "    {\"author\": \"Adam\", \"category\": \"Music\"},\n",
        "    {\"author\": \"Eve\", \"category\": \"Music\"},\n",
        "    {\"author\": \"John\", \"category\": \"History\"},\n",
        "]\n",
        "ids = vectorstore.add_texts(texts=texts, metadatas=metadatas)\n",
        "\n",
        "#  Search similar text\n",
        "output = vectorstore.similarity_search(\n",
        "    query=\"foo\",\n",
        "    k=1,\n",
        "    metadatas=[\"author\", \"category\"],\n",
        ")\n",
        "assert output[0].page_content == \"foo\"\n",
        "assert output[0].metadata[\"author\"] == \"Adam\"\n",
        "assert output[0].metadata[\"category\"] == \"Music\"\n",
        "assert len(output) == 1\n",
        "\n",
        "# Search with filtering (where)\n",
        "where = \"author='Eve'\"\n",
        "output = vectorstore.similarity_search(\n",
        "    query=\"foo\",\n",
        "    k=3,\n",
        "    fetch_k=9,\n",
        "    where=where,\n",
        "    metadatas=[\"author\", \"category\"],\n",
        ")\n",
        "assert output[0].page_content == \"bar\"\n",
        "assert output[0].metadata[\"author\"] == \"Eve\"\n",
        "assert output[0].metadata[\"category\"] == \"Music\"\n",
        "assert len(output) == 1\n",
        "\n",
        "# Anomaly detection\n",
        "result = vectorstore.is_anomalous(\n",
        "    query=\"dogs can jump high\",\n",
        ")\n",
        "assert result is False\n",
        "\n",
        "# Remove all data in the store\n",
        "vectorstore.clear()\n",
        "assert vectorstore.count() == 0\n",
        "\n",
        "# Remove the store completely\n",
        "vectorstore.drop()\n",
        "\n",
        "# Logout\n",
        "vectorstore.logout()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}