{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f70e6118",
      "metadata": {},
      "source": [
        "# 图片\n\n本节内容介绍如何将图片加载到文档格式中，以便下游 LangChain 模块使用。\n\n它使用 [Unstructured](https://unstructured.io/) 来处理各种图片格式，例如 `.jpg` 和 `.png`。请参阅[本指南](/docs/integrations/providers/unstructured/)，了解更多关于在本地设置 Unstructured 的说明，包括设置所需的系统依赖项。"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09d64998",
      "metadata": {},
      "source": [
        "## 使用非结构化数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db8e56db-2e66-443b-8a0b-ef69fa5fae9a",
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --quiet \"unstructured[all-docs]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0cc0cd42",
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content='2021\\n\\n2103.15348v2 [cs.CV] 21 Jun\\n\\narXiv\\n\\nLayoutParser: A Unified Toolkit for Deep Learning Based Document Image Analysis\\n\\nZejiang Shen! (&4), Ruochen Zhang?, Melissa Dell?, Benjamin Charles Germain Lee*, Jacob Carlson?, and Weining Li?\\n\\n1\\n\\nAllen Institute for AI shannons@allenai.org ? Brown University ruochen_zhang@brown. edu 3 Harvard University {melissadell, jacob_carlson}@fas.harvard.edu 4 University of Washington begl@cs.washington.edu 5 University of Waterloo w4221i@uwaterloo.ca\\n\\nAbstract. Recent advances in document image analysis (DIA) have been primarily driven by the application of neural networks. Ideally, research outcomes could be easily deployed in production and extended for further investigation. However, various factors like loosely organized codebases and sophisticated model configurations complicate the easy reuse of im- portant innovations by a wide audience. Though there have been on-going efforts to improve reusability and simplify deep learning (DL) model development in disciplines like natural language processing and computer vision, none of them are optimized for challenges in the domain of DIA. This represents a major gap in the existing toolkit, as DIA is central to academic research across a wide range of disciplines in the social sciences and humanities. This paper introduces LayoutParser, an open-source library for streamlining the usage of DL in DIA research and applica- tions. The core LayoutParser library comes with a set of simple and intuitive interfaces for applying and customizing DL models for layout de- tection, character recognition, and many other document processing tasks. To promote extensibility, LayoutParser also incorporates a community platform for sharing both pre-trained models and full document digiti- zation pipelines. We demonstrate that LayoutParser is helpful for both lightweight and large-scale digitization pipelines in real-word use cases. The library is publicly available at https: //layout-parser.github. io.\\n\\nKeywords: Document Image Analysis - Deep Learning - Layout Analysis - Character Recognition - Open Source library - Toolkit.\\n\\n1 Introduction\\n\\nDeep Learning(DL)-based approaches are the state-of-the-art for a wide range of document image analysis (DIA) tasks including document image classification [11,', metadata={'source': './example_data/layout-parser-paper-screenshot.png'})"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_community.document_loaders.image import UnstructuredImageLoader\n",
        "\n",
        "loader = UnstructuredImageLoader(\"./example_data/layout-parser-paper-screenshot.png\")\n",
        "\n",
        "data = loader.load()\n",
        "\n",
        "data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09957371",
      "metadata": {},
      "source": [
        "### 保留元素\n\n在底层，Unstructured 会为不同的文本块创建不同的“元素”。默认情况下，我们会将它们合并在一起，但您可以通过指定 `mode=\"elements\"` 来保持这种分离。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0fab833b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content='2021', metadata={'source': './example_data/layout-parser-paper-screenshot.png', 'coordinates': {'points': ((47.0, 492.0), (47.0, 591.0), (83.0, 591.0), (83.0, 492.0)), 'system': 'PixelSpace', 'layout_width': 1624, 'layout_height': 1920}, 'last_modified': '2024-07-01T10:38:29', 'filetype': 'PNG', 'languages': ['eng'], 'page_number': 1, 'file_directory': './example_data', 'filename': 'layout-parser-paper-screenshot.png', 'category': 'UncategorizedText'})"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loader = UnstructuredImageLoader(\n",
        "    \"./example_data/layout-parser-paper-screenshot.png\", mode=\"elements\"\n",
        ")\n",
        "\n",
        "data = loader.load()\n",
        "\n",
        "data[0]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}