{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Docling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[Docling](https://github.com/DS4SD/docling) 能将 PDF、DOCX、PPTX、HTML 等格式解析为丰富的统一表示，包括文档布局、表格等，使其能够用于 RAG 等生成式 AI 工作流。\n\n此集成通过 `DoclingLoader` 文档加载器提供了 Docling 的功能。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 概述\n\n<!-- \n### 集成详情\n\n| 类 | 包 | 本地 | 可序列化 | JS 支持 |\n| :--- | :--- | :---: | :---: |  :---: |\n| langchain_docling.DoclingLoader | langchain-docling | ✅ | ❌ | ❌ | \n\n### 加载器特性\n| 来源 | 文档延迟加载 | 原生异步支持\n| :---: | :---: | :---: | \n| DoclingLoader | ✅ | ❌ | \n -->\n\n`DoclingLoader` 组件使您能够：\n- 轻松快速地在 LLM 应用中使用各种文档类型，并且\n- 利用 Docling 的丰富格式进行高级的、文档原生的归因。\n\n`DoclingLoader` 支持两种不同的导出模式：\n- `ExportType.DOC_CHUNKS` (默认)：如果您希望将每个输入文档分块，然后将每个独立的块捕获为下游单独的 LangChain Document，或者\n- `ExportType.MARKDOWN`：如果您希望将每个输入文档捕获为单独的 LangChain Document\n\n该示例通过参数 `EXPORT_TYPE` 允许探索这两种模式；根据设置的值，相应地设置示例管道。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 设置"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -qU langchain-docling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> 为获得最佳转换速度，请尽可能使用 GPU 加速；例如，如果在 Colab 上运行，请使用支持 GPU 的运行时。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 初始化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "基本初始化如下所示："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_docling import DoclingLoader\n",
        "\n",
        "FILE_PATH = \"https://arxiv.org/pdf/2408.09869\"\n",
        "\n",
        "loader = DoclingLoader(file_path=FILE_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "对于高级用法，`DoclingLoader` 具有以下参数：\n- `file_path`: 源文件为单个字符串 (URL 或本地文件) 或其可迭代对象\n- `converter` (可选): 要使用的任何特定 Docling 转换器实例\n- `convert_kwargs` (可选): 用于转换执行的任何特定关键字参数\n- `export_type` (可选): 要使用的导出模式：`ExportType.DOC_CHUNKS` (默认) 或\n    `ExportType.MARKDOWN`\n- `md_export_kwargs` (可选): 任何特定的 Markdown 导出关键字参数 (用于 Markdown 模式)\n- `chunker` (可选): 要使用的任何特定 Docling 分块器实例 (用于文档分块模式)\n- `meta_extractor` (可选): 要使用的任何特定元数据提取器"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 加载"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ],
      "source": [
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> 注意：忽略显示 `\"Token indices sequence length is longer than the specified\nmaximum sequence length...\"` 的消息是可以接受的——更多详情请点击[此处](https://github.com/DS4SD/docling-core/issues/119#issuecomment-2577418826)。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "检查一些示例文档："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- d.page_content='arXiv:2408.09869v5  [cs.CL]  9 Dec 2024'\n",
            "- d.page_content='Docling Technical Report\\nVersion 1.0\\nChristoph Auer Maksym Lysak Ahmed Nassar Michele Dolfi Nikolaos Livathinos Panos Vagenas Cesar Berrospi Ramis Matteo Omenetti Fabian Lindlbauer Kasper Dinkla Lokesh Mishra Yusik Kim Shubham Gupta Rafael Teixeira de Lima Valery Weber Lucas Morin Ingmar Meijer Viktor Kuropiatnyk Peter W. J. Staar\\nAI4K Group, IBM Research R¨uschlikon, Switzerland'\n",
            "- d.page_content='Abstract\\nThis technical report introduces Docling , an easy to use, self-contained, MITlicensed open-source package for PDF document conversion. It is powered by state-of-the-art specialized AI models for layout analysis (DocLayNet) and table structure recognition (TableFormer), and runs efficiently on commodity hardware in a small resource budget. The code interface allows for easy extensibility and addition of new features and models.'\n"
          ]
        }
      ],
      "source": [
        "for d in docs[:3]:\n",
        "    print(f\"- {d.page_content=}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 懒加载\n\n文档也可以以懒加载的方式加载："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "doc_iter = loader.lazy_load()\n",
        "for doc in doc_iter:\n",
        "    pass  # you can operate on `doc` here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 端到端示例"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# https://github.com/huggingface/transformers/issues/5486:\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> - 以下示例管道使用了 HuggingFace 的推理 API；为了增加 LLM 配额，可以通过环境变量 `HF_TOKEN` 提供令牌。\n> - 此管道的依赖项可以按如下方式安装（`--no-warn-conflicts` 用于 Colab 预先填充的 Python 环境；在更严格的用法下可以随时移除）："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -q --progress-bar off --no-warn-conflicts langchain-core langchain-huggingface langchain_milvus langchain python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "定义管道参数："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from tempfile import mkdtemp\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_docling.loader import ExportType\n",
        "\n",
        "\n",
        "def _get_env_from_colab_or_os(key):\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "\n",
        "        try:\n",
        "            return userdata.get(key)\n",
        "        except userdata.SecretNotFoundError:\n",
        "            pass\n",
        "    except ImportError:\n",
        "        pass\n",
        "    return os.getenv(key)\n",
        "\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "HF_TOKEN = _get_env_from_colab_or_os(\"HF_TOKEN\")\n",
        "FILE_PATH = [\"https://arxiv.org/pdf/2408.09869\"]  # Docling Technical Report\n",
        "EMBED_MODEL_ID = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "GEN_MODEL_ID = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
        "EXPORT_TYPE = ExportType.DOC_CHUNKS\n",
        "QUESTION = \"Which are the main AI models in Docling?\"\n",
        "PROMPT = PromptTemplate.from_template(\n",
        "    \"Context information is below.\\n---------------------\\n{context}\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {input}\\nAnswer:\\n\",\n",
        ")\n",
        "TOP_K = 3\n",
        "MILVUS_URI = str(Path(mkdtemp()) / \"docling.db\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "现在我们可以实例化加载器并加载文档了："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ],
      "source": [
        "from docling.chunking import HybridChunker\n",
        "from langchain_docling import DoclingLoader\n",
        "\n",
        "loader = DoclingLoader(\n",
        "    file_path=FILE_PATH,\n",
        "    export_type=EXPORT_TYPE,\n",
        "    chunker=HybridChunker(tokenizer=EMBED_MODEL_ID),\n",
        ")\n",
        "\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "确定拆分："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "if EXPORT_TYPE == ExportType.DOC_CHUNKS:\n",
        "    splits = docs\n",
        "elif EXPORT_TYPE == ExportType.MARKDOWN:\n",
        "    from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
        "\n",
        "    splitter = MarkdownHeaderTextSplitter(\n",
        "        headers_to_split_on=[\n",
        "            (\"#\", \"Header_1\"),\n",
        "            (\"##\", \"Header_2\"),\n",
        "            (\"###\", \"Header_3\"),\n",
        "        ],\n",
        "    )\n",
        "    splits = [split for doc in docs for split in splitter.split_text(doc.page_content)]\n",
        "else:\n",
        "    raise ValueError(f\"Unexpected export type: {EXPORT_TYPE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "检查一些示例分割："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- d.page_content='arXiv:2408.09869v5  [cs.CL]  9 Dec 2024'\n",
            "- d.page_content='Docling Technical Report\\nVersion 1.0\\nChristoph Auer Maksym Lysak Ahmed Nassar Michele Dolfi Nikolaos Livathinos Panos Vagenas Cesar Berrospi Ramis Matteo Omenetti Fabian Lindlbauer Kasper Dinkla Lokesh Mishra Yusik Kim Shubham Gupta Rafael Teixeira de Lima Valery Weber Lucas Morin Ingmar Meijer Viktor Kuropiatnyk Peter W. J. Staar\\nAI4K Group, IBM Research R¨uschlikon, Switzerland'\n",
            "- d.page_content='Abstract\\nThis technical report introduces Docling , an easy to use, self-contained, MITlicensed open-source package for PDF document conversion. It is powered by state-of-the-art specialized AI models for layout analysis (DocLayNet) and table structure recognition (TableFormer), and runs efficiently on commodity hardware in a small resource budget. The code interface allows for easy extensibility and addition of new features and models.'\n",
            "...\n"
          ]
        }
      ],
      "source": [
        "for d in splits[:3]:\n",
        "    print(f\"- {d.page_content=}\")\n",
        "print(\"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 摄入"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "from tempfile import mkdtemp\n",
        "\n",
        "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_milvus import Milvus\n",
        "\n",
        "embedding = HuggingFaceEmbeddings(model_name=EMBED_MODEL_ID)\n",
        "\n",
        "milvus_uri = str(Path(mkdtemp()) / \"docling.db\")  # or set as needed\n",
        "vectorstore = Milvus.from_documents(\n",
        "    documents=splits,\n",
        "    embedding=embedding,\n",
        "    collection_name=\"docling_demo\",\n",
        "    connection_args={\"uri\": milvus_uri},\n",
        "    index_params={\"index_type\": \"FLAT\"},\n",
        "    drop_old=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": TOP_K})\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=GEN_MODEL_ID,\n",
        "    huggingfacehub_api_token=HF_TOKEN,\n",
        "    task=\"text-generation\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clip_text(text, threshold=100):\n",
        "    return f\"{text[:threshold]}...\" if len(text) > threshold else text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question:\n",
            "Which are the main AI models in Docling?\n",
            "\n",
            "Answer:\n",
            "The main AI models in Docling are a layout analysis model, which is an accurate object-detector for page elements, and TableFormer, a state-of-the-art table structure recognition model.\n",
            "\n",
            "Source 1:\n",
            "  text: \"3.2 AI models\\nAs part of Docling, we initially release two highly capable AI models to the open-source community, which have been developed and published recently by our team. The first model is a layout analysis model, an accurate object-detector for page elements [13]. The second model is TableFormer [12, 9], a state-of-the-art table structure re...\"\n",
            "  dl_meta: {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/50', 'parent': {'$ref': '#/body'}, 'children': [], 'label': 'text', 'prov': [{'page_no': 3, 'bbox': {'l': 108.0, 't': 405.1419982910156, 'r': 504.00299072265625, 'b': 330.7799987792969, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 608]}]}], 'headings': ['3.2 AI models'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 11465328351749295394, 'filename': '2408.09869v5.pdf'}}\n",
            "  source: https://arxiv.org/pdf/2408.09869\n",
            "\n",
            "Source 2:\n",
            "  text: \"3 Processing pipeline\\nDocling implements a linear pipeline of operations, which execute sequentially on each given document (see Fig. 1). Each document is first parsed by a PDF backend, which retrieves the programmatic text tokens, consisting of string content and its coordinates on the page, and also renders a bitmap image of each page to support ...\"\n",
            "  dl_meta: {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/26', 'parent': {'$ref': '#/body'}, 'children': [], 'label': 'text', 'prov': [{'page_no': 2, 'bbox': {'l': 108.0, 't': 273.01800537109375, 'r': 504.00299072265625, 'b': 176.83799743652344, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 796]}]}], 'headings': ['3 Processing pipeline'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 11465328351749295394, 'filename': '2408.09869v5.pdf'}}\n",
            "  source: https://arxiv.org/pdf/2408.09869\n",
            "\n",
            "Source 3:\n",
            "  text: \"6 Future work and contributions\\nDocling is designed to allow easy extension of the model library and pipelines. In the future, we plan to extend Docling with several more models, such as a figure-classifier model, an equationrecognition model, a code-recognition model and more. This will help improve the quality of conversion for specific types of ...\"\n",
            "  dl_meta: {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/76', 'parent': {'$ref': '#/body'}, 'children': [], 'label': 'text', 'prov': [{'page_no': 5, 'bbox': {'l': 108.0, 't': 322.468994140625, 'r': 504.00299072265625, 'b': 259.0169982910156, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 543]}]}, {'self_ref': '#/texts/77', 'parent': {'$ref': '#/body'}, 'children': [], 'label': 'text', 'prov': [{'page_no': 5, 'bbox': {'l': 108.0, 't': 251.6540069580078, 'r': 504.00299072265625, 'b': 198.99200439453125, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 402]}]}], 'headings': ['6 Future work and contributions'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 11465328351749295394, 'filename': '2408.09869v5.pdf'}}\n",
            "  source: https://arxiv.org/pdf/2408.09869\n"
          ]
        }
      ],
      "source": [
        "question_answer_chain = create_stuff_documents_chain(llm, PROMPT)\n",
        "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
        "resp_dict = rag_chain.invoke({\"input\": QUESTION})\n",
        "\n",
        "clipped_answer = clip_text(resp_dict[\"answer\"], threshold=350)\n",
        "print(f\"Question:\\n{resp_dict['input']}\\n\\nAnswer:\\n{clipped_answer}\")\n",
        "for i, doc in enumerate(resp_dict[\"context\"]):\n",
        "    print()\n",
        "    print(f\"Source {i+1}:\")\n",
        "    print(f\"  text: {json.dumps(clip_text(doc.page_content, threshold=350))}\")\n",
        "    for key in doc.metadata:\n",
        "        if key != \"pk\":\n",
        "            val = doc.metadata.get(key)\n",
        "            clipped_val = clip_text(val) if isinstance(val, str) else val\n",
        "            print(f\"  {key}: {clipped_val}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "请注意，源内容包含丰富的支撑信息，包括段落标题（即部分）、页码和精确的边界框。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## API 参考\n\n- [LangChain Docling 集成 GitHub](https://github.com/docling-project/docling-langchain)\n- [Docling GitHub](https://github.com/docling-project/docling)\n- [Docling 文档](https://docling-project.github.io/docling//)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}