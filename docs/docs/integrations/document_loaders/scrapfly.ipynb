{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[ScrapFly](https://scrapfly.io/) 是一个网络爬虫 API，具有无头浏览器功能、代理和反机器人绕过能力。它允许将网页数据提取为易于访问的 LLM markdown 或文本。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 安装\n使用 pip 安装 ScrapFly Python SDK 和所需的 Langchain 包：\n```shell\npip install scrapfly-sdk langchain langchain-community\n```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 用法"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import ScrapflyLoader\n",
        "\n",
        "scrapfly_loader = ScrapflyLoader(\n",
        "    [\"https://web-scraping.dev/products\"],\n",
        "    api_key=\"Your ScrapFly API key\",  # Get your API key from https://www.scrapfly.io/\n",
        "    continue_on_failure=True,  # Ignore unprocessable web pages and log their exceptions\n",
        ")\n",
        "\n",
        "# Load documents from URLs as markdown\n",
        "documents = scrapfly_loader.load()\n",
        "print(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ScrapflyLoader 也允许传递 ScrapeConfig 对象来自定义抓取请求。请参阅文档了解完整的特性详情及其 API 参数：https://scrapfly.io/docs/scrape-api/getting-started"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import ScrapflyLoader\n",
        "\n",
        "scrapfly_scrape_config = {\n",
        "    \"asp\": True,  # Bypass scraping blocking and antibot solutions, like Cloudflare\n",
        "    \"render_js\": True,  # Enable JavaScript rendering with a cloud headless browser\n",
        "    \"proxy_pool\": \"public_residential_pool\",  # Select a proxy pool (datacenter or residnetial)\n",
        "    \"country\": \"us\",  # Select a proxy location\n",
        "    \"auto_scroll\": True,  # Auto scroll the page\n",
        "    \"js\": \"\",  # Execute custom JavaScript code by the headless browser\n",
        "}\n",
        "\n",
        "scrapfly_loader = ScrapflyLoader(\n",
        "    [\"https://web-scraping.dev/products\"],\n",
        "    api_key=\"Your ScrapFly API key\",  # Get your API key from https://www.scrapfly.io/\n",
        "    continue_on_failure=True,  # Ignore unprocessable web pages and log their exceptions\n",
        "    scrape_config=scrapfly_scrape_config,  # Pass the scrape_config object\n",
        "    scrape_format=\"markdown\",  # The scrape result format, either `markdown`(default) or `text`\n",
        ")\n",
        "\n",
        "# Load documents from URLs as markdown\n",
        "documents = scrapfly_loader.load()\n",
        "print(documents)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}